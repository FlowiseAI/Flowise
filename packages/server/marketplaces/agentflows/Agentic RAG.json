{
    "description": "A self-improving RAG that check for relevance of a document to a user question",
    "framework": ["Langchain"],
    "usecases": ["Reflective Agent"],
    "nodes": [
        {
            "id": "seqLLMNode_0",
            "position": {
                "x": 777.3229608822006,
                "y": 187.06257072665113
            },
            "type": "customNode",
            "data": {
                "id": "seqLLMNode_0",
                "label": "LLM Node",
                "version": 2,
                "name": "seqLLMNode",
                "type": "LLMNode",
                "baseClasses": ["LLMNode"],
                "category": "Sequential Agents",
                "description": "Run Chat Model and return the output",
                "inputParams": [
                    {
                        "label": "Name",
                        "name": "llmNodeName",
                        "type": "string",
                        "placeholder": "LLM",
                        "id": "seqLLMNode_0-input-llmNodeName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_0-input-systemMessagePrompt-string"
                    },
                    {
                        "label": "Human Prompt",
                        "name": "humanMessagePrompt",
                        "type": "string",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_0-input-humanMessagePrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_0-input-promptValues-json"
                    },
                    {
                        "label": "JSON Structured Output",
                        "name": "llmStructuredOutput",
                        "type": "datagrid",
                        "description": "Instruct the LLM to give output in a JSON structured schema",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "type",
                                "headerName": "Type",
                                "type": "singleSelect",
                                "valueOptions": ["String", "String Array", "Number", "Boolean", "Enum"],
                                "editable": true
                            },
                            {
                                "field": "enumValues",
                                "headerName": "Enum Values",
                                "editable": true
                            },
                            {
                                "field": "description",
                                "headerName": "Description",
                                "flex": 1,
                                "editable": true
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_0-input-llmStructuredOutput-datagrid"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "tabs",
                        "tabIdentifier": "selectedUpdateStateMemoryTab",
                        "default": "updateStateMemoryUI",
                        "additionalParams": true,
                        "tabs": [
                            {
                                "label": "Update State (Table)",
                                "name": "updateStateMemoryUI",
                                "type": "datagrid",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                                "datagrid": [
                                    {
                                        "field": "key",
                                        "headerName": "Key",
                                        "type": "asyncSingleSelect",
                                        "loadMethod": "loadStateKeys",
                                        "flex": 0.5,
                                        "editable": true
                                    },
                                    {
                                        "field": "value",
                                        "headerName": "Value",
                                        "type": "freeSolo",
                                        "valueOptions": [
                                            {
                                                "label": "LLM Node Output (string)",
                                                "value": "$flow.output.content"
                                            },
                                            {
                                                "label": "LLM JSON Output Key (string)",
                                                "value": "$flow.output.<replace-with-key>"
                                            },
                                            {
                                                "label": "Global variable (string)",
                                                "value": "$vars.<variable-name>"
                                            },
                                            {
                                                "label": "Input Question (string)",
                                                "value": "$flow.input"
                                            },
                                            {
                                                "label": "Session Id (string)",
                                                "value": "$flow.sessionId"
                                            },
                                            {
                                                "label": "Chat Id (string)",
                                                "value": "$flow.chatId"
                                            },
                                            {
                                                "label": "Chatflow Id (string)",
                                                "value": "$flow.chatflowId"
                                            }
                                        ],
                                        "editable": true,
                                        "flex": 1
                                    }
                                ],
                                "optional": true,
                                "additionalParams": true
                            },
                            {
                                "label": "Update State (Code)",
                                "name": "updateStateMemoryCode",
                                "type": "code",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                                "hideCodeExecute": true,
                                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "seqLLMNode_0-input-updateStateMemory-tabs"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Start | Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Start | Agent | Condition | LLMNode | ToolNode",
                        "list": true,
                        "id": "seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this node",
                        "id": "seqLLMNode_0-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "llmNodeName": "Agent",
                    "systemMessagePrompt": "You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\n\nThe tools available are:\n- search_apple\n- search_tesla\n\nThe current date is: 2024-07-10",
                    "humanMessagePrompt": "{text}",
                    "sequentialNode": ["{{seqStart_0.data.instance}}", "{{seqStart_0.data.instance}}"],
                    "model": "",
                    "promptValues": "{\"text\":\"{{question}}\"}",
                    "llmStructuredOutput": "",
                    "updateStateMemory": "updateStateMemoryUI",
                    "selectedUpdateStateMemoryTab_seqLLMNode_0": "updateStateMemoryUI"
                },
                "outputAnchors": [
                    {
                        "id": "seqLLMNode_0-output-seqLLMNode-LLMNode",
                        "name": "seqLLMNode",
                        "label": "LLMNode",
                        "description": "Run Chat Model and return the output",
                        "type": "LLMNode"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 450,
            "selected": false,
            "positionAbsolute": {
                "x": 777.3229608822006,
                "y": 187.06257072665113
            },
            "dragging": false
        },
        {
            "id": "seqStart_0",
            "position": {
                "x": 438.8554922368403,
                "y": 259.0803221316833
            },
            "type": "customNode",
            "data": {
                "id": "seqStart_0",
                "label": "Start",
                "version": 2,
                "name": "seqStart",
                "type": "Start",
                "baseClasses": ["Start"],
                "category": "Sequential Agents",
                "description": "Starting point of the conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
                        "id": "seqStart_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Agent Memory",
                        "name": "agentMemory",
                        "type": "BaseCheckpointSaver",
                        "description": "Save the state of the agent",
                        "optional": true,
                        "id": "seqStart_0-input-agentMemory-BaseCheckpointSaver"
                    },
                    {
                        "label": "State",
                        "name": "state",
                        "type": "State",
                        "description": "State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.",
                        "optional": true,
                        "id": "seqStart_0-input-state-State"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "seqStart_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "agentMemory": "{{agentMemory_0.data.instance}}",
                    "state": "{{seqState_0.data.instance}}",
                    "inputModeration": ""
                },
                "outputAnchors": [
                    {
                        "id": "seqStart_0-output-seqStart-Start",
                        "name": "seqStart",
                        "label": "Start",
                        "description": "Starting point of the conversation",
                        "type": "Start"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 382,
            "positionAbsolute": {
                "x": 438.8554922368403,
                "y": 259.0803221316833
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "seqConditionAgent_0",
            "position": {
                "x": 1833.6825613005371,
                "y": 50.77506638740766
            },
            "type": "customNode",
            "data": {
                "id": "seqConditionAgent_0",
                "label": "Condition Agent",
                "version": 2,
                "name": "seqConditionAgent",
                "type": "ConditionAgent",
                "baseClasses": ["ConditionAgent"],
                "category": "Sequential Agents",
                "description": "Uses an agent to determine which route to take next",
                "inputParams": [
                    {
                        "label": "Name",
                        "name": "conditionAgentName",
                        "type": "string",
                        "placeholder": "Condition Agent",
                        "id": "seqConditionAgent_0-input-conditionAgentName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are an expert customer support routing system.\nYour job is to detect whether a customer support representative is routing a user to the technical support team, or just responding conversationally.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "seqConditionAgent_0-input-systemMessagePrompt-string"
                    },
                    {
                        "label": "Human Prompt",
                        "name": "humanMessagePrompt",
                        "type": "string",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "rows": 4,
                        "default": "The previous conversation is an interaction between a customer support representative and a user.\nExtract whether the representative is routing the user to the technical support team, or just responding conversationally.\n\nIf representative want to route the user to the technical support team, respond only with the word \"TECHNICAL\".\nOtherwise, respond only with the word \"CONVERSATION\".\n\nRemember, only respond with one of the above words.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "seqConditionAgent_0-input-humanMessagePrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "additionalParams": true,
                        "id": "seqConditionAgent_0-input-promptValues-json"
                    },
                    {
                        "label": "JSON Structured Output",
                        "name": "conditionAgentStructuredOutput",
                        "type": "datagrid",
                        "description": "Instruct the LLM to give output in a JSON structured schema",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "type",
                                "headerName": "Type",
                                "type": "singleSelect",
                                "valueOptions": ["String", "String Array", "Number", "Boolean", "Enum"],
                                "editable": true
                            },
                            {
                                "field": "enumValues",
                                "headerName": "Enum Values",
                                "editable": true
                            },
                            {
                                "field": "description",
                                "headerName": "Description",
                                "flex": 1,
                                "editable": true
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqConditionAgent_0-input-conditionAgentStructuredOutput-datagrid"
                    },
                    {
                        "label": "Condition",
                        "name": "condition",
                        "type": "conditionFunction",
                        "tabIdentifier": "selectedConditionFunctionTab",
                        "tabs": [
                            {
                                "label": "Condition (Table)",
                                "name": "conditionUI",
                                "type": "datagrid",
                                "description": "If a condition is met, the node connected to the respective output will be executed",
                                "optional": true,
                                "datagrid": [
                                    {
                                        "field": "variable",
                                        "headerName": "Variable",
                                        "type": "freeSolo",
                                        "editable": true,
                                        "loadMethod": ["getPreviousMessages", "loadStateKeys"],
                                        "valueOptions": [
                                            {
                                                "label": "Agent Output (string)",
                                                "value": "$flow.output.content"
                                            },
                                            {
                                                "label": "Agent's JSON Key Output (string)",
                                                "value": "$flow.output.<replace-with-key>"
                                            },
                                            {
                                                "label": "Total Messages (number)",
                                                "value": "$flow.state.messages.length"
                                            },
                                            {
                                                "label": "First Message Content (string)",
                                                "value": "$flow.state.messages[0].content"
                                            },
                                            {
                                                "label": "Last Message Content (string)",
                                                "value": "$flow.state.messages[-1].content"
                                            },
                                            {
                                                "label": "Global variable (string)",
                                                "value": "$vars.<variable-name>"
                                            }
                                        ],
                                        "flex": 0.5,
                                        "minWidth": 200
                                    },
                                    {
                                        "field": "operation",
                                        "headerName": "Operation",
                                        "type": "singleSelect",
                                        "valueOptions": [
                                            "Contains",
                                            "Not Contains",
                                            "Start With",
                                            "End With",
                                            "Is",
                                            "Is Not",
                                            "Is Empty",
                                            "Is Not Empty",
                                            "Greater Than",
                                            "Less Than",
                                            "Equal To",
                                            "Not Equal To",
                                            "Greater Than or Equal To",
                                            "Less Than or Equal To"
                                        ],
                                        "editable": true,
                                        "flex": 0.4,
                                        "minWidth": 150
                                    },
                                    {
                                        "field": "value",
                                        "headerName": "Value",
                                        "flex": 1,
                                        "editable": true
                                    },
                                    {
                                        "field": "output",
                                        "headerName": "Output Name",
                                        "editable": true,
                                        "flex": 0.3,
                                        "minWidth": 150
                                    }
                                ]
                            },
                            {
                                "label": "Condition (Code)",
                                "name": "conditionFunction",
                                "type": "code",
                                "description": "Function to evaluate the condition",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Must return a string value at the end of function. For example:\n    ```js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: `$flow.state.messages`:\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    ```\n\n    For example, to get the last message content:\n    ```js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    ```\n\n3. If you want to use the Condition Agent's output for conditional checks, it is available as `$flow.output` with the following structure:\n\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, we can check if the agent's output contains specific keyword:\n    ```js\n    const result = $flow.output.content;\n    \n    if (result.includes(\"some-keyword\")) {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n    If Structured Output is enabled, `$flow.output` will be in the JSON format as defined in the Structured Output configuration:\n    ```json\n    {\n        \"foo\": 'var'\n    }\n    ```\n\n4. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n5. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "hideCodeExecute": true,
                                "codeExample": "const result = $flow.output.content;\n\nif (result.includes(\"some-keyword\")) {\n    return \"Agent\";\n}\n\nreturn \"End\";\n",
                                "optional": true
                            }
                        ],
                        "id": "seqConditionAgent_0-input-condition-conditionFunction"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Start | Agent | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Start | Agent | LLMNode | ToolNode",
                        "list": true,
                        "id": "seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this agent",
                        "id": "seqConditionAgent_0-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "conditionAgentName": "Check if docs relevant",
                    "sequentialNode": ["{{seqLLMNode_3.data.instance}}"],
                    "model": "",
                    "systemMessagePrompt": "You are a grader assessing relevance of a retrieved document to a user question.\n\nHere is the retrieved document:\n{context}\n\nHere is the user question: {question}\n\nIf the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n\nGive a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n\nRemember, always use the extract tool to output only \"yes\" or \"no\"",
                    "humanMessagePrompt": "The previous conversation is an interaction between a bot and a user.\nExtract whether the if the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n\nGive a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n\nIf document is relavant to question, respond only with the word \"yes\".\nOtherwise, respond only with the word \"no\".\n\nRemember, always use the extract tool to output only \"yes\" or \"no\"",
                    "promptValues": "{\"context\":\"{{seqToolNode_0.data.instance}}\",\"question\":\"{{question}}\"}",
                    "conditionAgentStructuredOutput": "[{\"key\":\"score\",\"type\":\"Enum\",\"enumValues\":\"yes, no\",\"description\":\"grading score\",\"actions\":\"\",\"id\":1}]",
                    "condition": "",
                    "selectedConditionFunctionTab_seqConditionAgent_0": "conditionUI",
                    "conditionUI": "[{\"variable\":\"$flow.output.score\",\"operation\":\"Is\",\"value\":\"yes\",\"output\":\"Generate\",\"actions\":\"\",\"id\":1},{\"variable\":\"$flow.output.score\",\"operation\":\"Is\",\"value\":\"no\",\"output\":\"Rewrite\",\"actions\":\"\",\"id\":2}]"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "seqConditionAgent_0-output-end-Condition",
                                "name": "end",
                                "label": "End",
                                "type": "Condition",
                                "isAnchor": true
                            },
                            {
                                "id": "seqConditionAgent_0-output-generate-Condition",
                                "name": "generate",
                                "label": "Generate",
                                "type": "Condition",
                                "isAnchor": true
                            },
                            {
                                "id": "seqConditionAgent_0-output-rewrite-Condition",
                                "name": "rewrite",
                                "label": "Rewrite",
                                "type": "Condition",
                                "isAnchor": true
                            }
                        ],
                        "default": "next"
                    }
                ],
                "outputs": {
                    "output": "next"
                },
                "selected": false
            },
            "width": 300,
            "height": 627,
            "selected": false,
            "positionAbsolute": {
                "x": 1833.6825613005371,
                "y": 50.77506638740766
            },
            "dragging": false
        },
        {
            "id": "seqLLMNode_1",
            "position": {
                "x": 2214.7883262686187,
                "y": 687.0859636111031
            },
            "type": "customNode",
            "data": {
                "id": "seqLLMNode_1",
                "label": "LLM Node",
                "version": 2,
                "name": "seqLLMNode",
                "type": "LLMNode",
                "baseClasses": ["LLMNode"],
                "category": "Sequential Agents",
                "description": "Run Chat Model and return the output",
                "inputParams": [
                    {
                        "label": "Name",
                        "name": "llmNodeName",
                        "type": "string",
                        "placeholder": "LLM",
                        "id": "seqLLMNode_1-input-llmNodeName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_1-input-systemMessagePrompt-string"
                    },
                    {
                        "label": "Human Prompt",
                        "name": "humanMessagePrompt",
                        "type": "string",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_1-input-humanMessagePrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_1-input-promptValues-json"
                    },
                    {
                        "label": "JSON Structured Output",
                        "name": "llmStructuredOutput",
                        "type": "datagrid",
                        "description": "Instruct the LLM to give output in a JSON structured schema",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "type",
                                "headerName": "Type",
                                "type": "singleSelect",
                                "valueOptions": ["String", "String Array", "Number", "Boolean", "Enum"],
                                "editable": true
                            },
                            {
                                "field": "enumValues",
                                "headerName": "Enum Values",
                                "editable": true
                            },
                            {
                                "field": "description",
                                "headerName": "Description",
                                "flex": 1,
                                "editable": true
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_1-input-llmStructuredOutput-datagrid"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "tabs",
                        "tabIdentifier": "selectedUpdateStateMemoryTab",
                        "default": "updateStateMemoryUI",
                        "additionalParams": true,
                        "tabs": [
                            {
                                "label": "Update State (Table)",
                                "name": "updateStateMemoryUI",
                                "type": "datagrid",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                                "datagrid": [
                                    {
                                        "field": "key",
                                        "headerName": "Key",
                                        "type": "asyncSingleSelect",
                                        "loadMethod": "loadStateKeys",
                                        "flex": 0.5,
                                        "editable": true
                                    },
                                    {
                                        "field": "value",
                                        "headerName": "Value",
                                        "type": "freeSolo",
                                        "valueOptions": [
                                            {
                                                "label": "LLM Node Output (string)",
                                                "value": "$flow.output.content"
                                            },
                                            {
                                                "label": "LLM JSON Output Key (string)",
                                                "value": "$flow.output.<replace-with-key>"
                                            },
                                            {
                                                "label": "Global variable (string)",
                                                "value": "$vars.<variable-name>"
                                            },
                                            {
                                                "label": "Input Question (string)",
                                                "value": "$flow.input"
                                            },
                                            {
                                                "label": "Session Id (string)",
                                                "value": "$flow.sessionId"
                                            },
                                            {
                                                "label": "Chat Id (string)",
                                                "value": "$flow.chatId"
                                            },
                                            {
                                                "label": "Chatflow Id (string)",
                                                "value": "$flow.chatflowId"
                                            }
                                        ],
                                        "editable": true,
                                        "flex": 1
                                    }
                                ],
                                "optional": true,
                                "additionalParams": true
                            },
                            {
                                "label": "Update State (Code)",
                                "name": "updateStateMemoryCode",
                                "type": "code",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                                "hideCodeExecute": true,
                                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "seqLLMNode_1-input-updateStateMemory-tabs"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Start | Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Start | Agent | Condition | LLMNode | ToolNode",
                        "list": true,
                        "id": "seqLLMNode_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this node",
                        "id": "seqLLMNode_1-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "llmNodeName": "Rewrite",
                    "systemMessagePrompt": "You are a helpful assistant that can Transform the query to produce a better question.",
                    "humanMessagePrompt": "Look at the input and try to reason about the underlying semantic intent / meaning.\n\nHere is the initial question:\n{question} \n  \nFormulate an improved question:\n",
                    "sequentialNode": ["{{seqConditionAgent_0.data.instance}}", "{{seqConditionAgent_0.data.instance}}"],
                    "model": "",
                    "promptValues": "{\"question\":\"{{question}}\"}",
                    "llmStructuredOutput": "",
                    "updateStateMemory": "updateStateMemoryUI",
                    "selectedUpdateStateMemoryTab_seqLLMNode_1": "updateStateMemoryUI"
                },
                "outputAnchors": [
                    {
                        "id": "seqLLMNode_1-output-seqLLMNode-LLMNode",
                        "name": "seqLLMNode",
                        "label": "LLMNode",
                        "description": "Run Chat Model and return the output",
                        "type": "LLMNode"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 450,
            "selected": false,
            "positionAbsolute": {
                "x": 2214.7883262686187,
                "y": 687.0859636111031
            },
            "dragging": false
        },
        {
            "id": "seqLLMNode_2",
            "position": {
                "x": 2227.3672008899293,
                "y": 202.42164215206395
            },
            "type": "customNode",
            "data": {
                "id": "seqLLMNode_2",
                "label": "LLM Node",
                "version": 2,
                "name": "seqLLMNode",
                "type": "LLMNode",
                "baseClasses": ["LLMNode"],
                "category": "Sequential Agents",
                "description": "Run Chat Model and return the output",
                "inputParams": [
                    {
                        "label": "Name",
                        "name": "llmNodeName",
                        "type": "string",
                        "placeholder": "LLM",
                        "id": "seqLLMNode_2-input-llmNodeName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_2-input-systemMessagePrompt-string"
                    },
                    {
                        "label": "Human Prompt",
                        "name": "humanMessagePrompt",
                        "type": "string",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_2-input-humanMessagePrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_2-input-promptValues-json"
                    },
                    {
                        "label": "JSON Structured Output",
                        "name": "llmStructuredOutput",
                        "type": "datagrid",
                        "description": "Instruct the LLM to give output in a JSON structured schema",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "type",
                                "headerName": "Type",
                                "type": "singleSelect",
                                "valueOptions": ["String", "String Array", "Number", "Boolean", "Enum"],
                                "editable": true
                            },
                            {
                                "field": "enumValues",
                                "headerName": "Enum Values",
                                "editable": true
                            },
                            {
                                "field": "description",
                                "headerName": "Description",
                                "flex": 1,
                                "editable": true
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_2-input-llmStructuredOutput-datagrid"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "tabs",
                        "tabIdentifier": "selectedUpdateStateMemoryTab",
                        "default": "updateStateMemoryUI",
                        "additionalParams": true,
                        "tabs": [
                            {
                                "label": "Update State (Table)",
                                "name": "updateStateMemoryUI",
                                "type": "datagrid",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                                "datagrid": [
                                    {
                                        "field": "key",
                                        "headerName": "Key",
                                        "type": "asyncSingleSelect",
                                        "loadMethod": "loadStateKeys",
                                        "flex": 0.5,
                                        "editable": true
                                    },
                                    {
                                        "field": "value",
                                        "headerName": "Value",
                                        "type": "freeSolo",
                                        "valueOptions": [
                                            {
                                                "label": "LLM Node Output (string)",
                                                "value": "$flow.output.content"
                                            },
                                            {
                                                "label": "LLM JSON Output Key (string)",
                                                "value": "$flow.output.<replace-with-key>"
                                            },
                                            {
                                                "label": "Global variable (string)",
                                                "value": "$vars.<variable-name>"
                                            },
                                            {
                                                "label": "Input Question (string)",
                                                "value": "$flow.input"
                                            },
                                            {
                                                "label": "Session Id (string)",
                                                "value": "$flow.sessionId"
                                            },
                                            {
                                                "label": "Chat Id (string)",
                                                "value": "$flow.chatId"
                                            },
                                            {
                                                "label": "Chatflow Id (string)",
                                                "value": "$flow.chatflowId"
                                            }
                                        ],
                                        "editable": true,
                                        "flex": 1
                                    }
                                ],
                                "optional": true,
                                "additionalParams": true
                            },
                            {
                                "label": "Update State (Code)",
                                "name": "updateStateMemoryCode",
                                "type": "code",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                                "hideCodeExecute": true,
                                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "seqLLMNode_2-input-updateStateMemory-tabs"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Start | Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Start | Agent | Condition | LLMNode | ToolNode",
                        "list": true,
                        "id": "seqLLMNode_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this node",
                        "id": "seqLLMNode_2-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "llmNodeName": "Generate",
                    "systemMessagePrompt": "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Remember to include sources and citations.\n\nQuestion: {question} \n\nContext: {context}\n\nAnswer:",
                    "humanMessagePrompt": "Given the user question and context, answer user query. Remember to includes sources and citations",
                    "sequentialNode": ["{{seqConditionAgent_0.data.instance}}", "{{seqConditionAgent_0.data.instance}}"],
                    "model": "",
                    "promptValues": "{\"question\":\"{{question}}\",\"context\":\"$flow.state.sources\"}",
                    "llmStructuredOutput": "",
                    "updateStateMemory": "updateStateMemoryUI",
                    "selectedUpdateStateMemoryTab_seqLLMNode_2": "updateStateMemoryUI"
                },
                "outputAnchors": [
                    {
                        "id": "seqLLMNode_2-output-seqLLMNode-LLMNode",
                        "name": "seqLLMNode",
                        "label": "LLMNode",
                        "description": "Run Chat Model and return the output",
                        "type": "LLMNode"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 450,
            "selected": false,
            "positionAbsolute": {
                "x": 2227.3672008899293,
                "y": 202.42164215206395
            },
            "dragging": false
        },
        {
            "id": "seqLoop_0",
            "position": {
                "x": 2557.3813854226105,
                "y": 836.5518871718609
            },
            "type": "customNode",
            "data": {
                "id": "seqLoop_0",
                "label": "Loop",
                "version": 2,
                "name": "seqLoop",
                "type": "Loop",
                "baseClasses": ["Loop"],
                "category": "Sequential Agents",
                "description": "Loop back to the specific sequential node",
                "inputParams": [
                    {
                        "label": "Loop To",
                        "name": "loopToName",
                        "description": "Name of the agent/llm to loop back to",
                        "type": "string",
                        "placeholder": "Agent",
                        "id": "seqLoop_0-input-loopToName-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Agent | Condition | LLMNode | ToolNode",
                        "list": true,
                        "id": "seqLoop_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
                    }
                ],
                "inputs": {
                    "sequentialNode": ["{{seqLLMNode_1.data.instance}}", "{{seqLLMNode_1.data.instance}}"],
                    "loopToName": "Agent"
                },
                "outputAnchors": [],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 241,
            "selected": false,
            "positionAbsolute": {
                "x": 2557.3813854226105,
                "y": 836.5518871718609
            },
            "dragging": false
        },
        {
            "id": "seqEnd_0",
            "position": {
                "x": 2566.2338203424747,
                "y": 472.1743069141402
            },
            "type": "customNode",
            "data": {
                "id": "seqEnd_0",
                "label": "End",
                "version": 2,
                "name": "seqEnd",
                "type": "End",
                "baseClasses": ["End"],
                "category": "Sequential Agents",
                "description": "End conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Agent | Condition | LLMNode | ToolNode",
                        "id": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
                    }
                ],
                "inputs": {
                    "sequentialNode": "{{seqLLMNode_2.data.instance}}"
                },
                "outputAnchors": [],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 143,
            "selected": false,
            "positionAbsolute": {
                "x": 2566.2338203424747,
                "y": 472.1743069141402
            },
            "dragging": false
        },
        {
            "id": "retrieverTool_0",
            "position": {
                "x": 783.2970370305982,
                "y": -455.34898059787446
            },
            "type": "customNode",
            "data": {
                "id": "retrieverTool_0",
                "label": "Retriever Tool",
                "version": 2,
                "name": "retrieverTool",
                "type": "RetrieverTool",
                "baseClasses": ["RetrieverTool", "DynamicTool", "Tool", "StructuredTool", "Runnable"],
                "category": "Tools",
                "description": "Use a retriever as allowed tool for agent",
                "inputParams": [
                    {
                        "label": "Retriever Name",
                        "name": "name",
                        "type": "string",
                        "placeholder": "search_state_of_union",
                        "id": "retrieverTool_0-input-name-string"
                    },
                    {
                        "label": "Retriever Description",
                        "name": "description",
                        "type": "string",
                        "description": "When should agent uses to retrieve documents",
                        "rows": 3,
                        "placeholder": "Searches and returns documents regarding the state-of-the-union.",
                        "id": "retrieverTool_0-input-description-string"
                    },
                    {
                        "label": "Return Source Documents",
                        "name": "returnSourceDocuments",
                        "type": "boolean",
                        "optional": true,
                        "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Retriever",
                        "name": "retriever",
                        "type": "BaseRetriever",
                        "id": "retrieverTool_0-input-retriever-BaseRetriever"
                    }
                ],
                "inputs": {
                    "name": "search_apple",
                    "description": "Search and return documents about Apple Inc (APPL)",
                    "retriever": "{{pinecone_0.data.instance}}",
                    "returnSourceDocuments": true
                },
                "outputAnchors": [
                    {
                        "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
                        "name": "retrieverTool",
                        "label": "RetrieverTool",
                        "description": "Use a retriever as allowed tool for agent",
                        "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 602,
            "selected": false,
            "positionAbsolute": {
                "x": 783.2970370305982,
                "y": -455.34898059787446
            },
            "dragging": false
        },
        {
            "id": "seqEnd_1",
            "position": {
                "x": 2215.392769584973,
                "y": 3.472498837195502
            },
            "type": "customNode",
            "data": {
                "id": "seqEnd_1",
                "label": "End",
                "version": 2,
                "name": "seqEnd",
                "type": "End",
                "baseClasses": ["End"],
                "category": "Sequential Agents",
                "description": "End conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Agent | Condition | LLMNode | ToolNode",
                        "id": "seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
                    }
                ],
                "inputs": {
                    "sequentialNode": "{{seqConditionAgent_0.data.instance}}"
                },
                "outputAnchors": [],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 143,
            "selected": false,
            "positionAbsolute": {
                "x": 2215.392769584973,
                "y": 3.472498837195502
            },
            "dragging": false
        },
        {
            "id": "pinecone_0",
            "position": {
                "x": 447.904826960472,
                "y": -484.62963155354555
            },
            "type": "customNode",
            "data": {
                "id": "pinecone_0",
                "label": "Pinecone",
                "version": 4,
                "name": "pinecone",
                "type": "Pinecone",
                "baseClasses": ["Pinecone", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["pineconeApi"],
                        "id": "pinecone_0-input-credential-credential"
                    },
                    {
                        "label": "Pinecone Index",
                        "name": "pineconeIndex",
                        "type": "string",
                        "id": "pinecone_0-input-pineconeIndex-string"
                    },
                    {
                        "label": "Pinecone Namespace",
                        "name": "pineconeNamespace",
                        "type": "string",
                        "placeholder": "my-first-namespace",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-pineconeNamespace-string"
                    },
                    {
                        "label": "Pinecone Text Key",
                        "name": "pineconeTextKey",
                        "description": "The key in the metadata for storing text. Default to `text`",
                        "type": "string",
                        "placeholder": "text",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-pineconeTextKey-string"
                    },
                    {
                        "label": "Pinecone Metadata Filter",
                        "name": "pineconeMetadataFilter",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "pinecone_0-input-pineconeMetadataFilter-json"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-topK-number"
                    },
                    {
                        "label": "Search Type",
                        "name": "searchType",
                        "type": "options",
                        "default": "similarity",
                        "options": [
                            {
                                "label": "Similarity",
                                "name": "similarity"
                            },
                            {
                                "label": "Max Marginal Relevance",
                                "name": "mmr"
                            }
                        ],
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-searchType-options"
                    },
                    {
                        "label": "Fetch K (for MMR Search)",
                        "name": "fetchK",
                        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
                        "placeholder": "20",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-fetchK-number"
                    },
                    {
                        "label": "Lambda (for MMR Search)",
                        "name": "lambda",
                        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
                        "placeholder": "0.5",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-lambda-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "pinecone_0-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "pinecone_0-input-embeddings-Embeddings"
                    },
                    {
                        "label": "Record Manager",
                        "name": "recordManager",
                        "type": "RecordManager",
                        "description": "Keep track of the record to prevent duplication",
                        "optional": true,
                        "id": "pinecone_0-input-recordManager-RecordManager"
                    }
                ],
                "inputs": {
                    "document": "",
                    "embeddings": "{{openAIEmbeddings_0.data.instance}}",
                    "recordManager": "",
                    "pineconeIndex": "flowiseindex",
                    "pineconeNamespace": "pinecone-form10k",
                    "pineconeTextKey": "",
                    "pineconeMetadataFilter": "{\"source\":\"apple\"}",
                    "topK": "",
                    "searchType": "similarity",
                    "fetchK": "",
                    "lambda": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Pinecone Retriever",
                                "description": "",
                                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "pinecone_0-output-vectorStore-Pinecone|VectorStore",
                                "name": "vectorStore",
                                "label": "Pinecone Vector Store",
                                "description": "",
                                "type": "Pinecone | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "width": 300,
            "height": 604,
            "selected": false,
            "positionAbsolute": {
                "x": 447.904826960472,
                "y": -484.62963155354555
            },
            "dragging": false
        },
        {
            "id": "openAIEmbeddings_0",
            "position": {
                "x": 83.1892702543966,
                "y": -431.8201391798152
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_0",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 423,
            "selected": false,
            "positionAbsolute": {
                "x": 83.1892702543966,
                "y": -431.8201391798152
            },
            "dragging": false
        },
        {
            "id": "seqState_0",
            "position": {
                "x": 77.70108535391958,
                "y": 754.5682118080191
            },
            "type": "customNode",
            "data": {
                "id": "seqState_0",
                "label": "State",
                "version": 2,
                "name": "seqState",
                "type": "State",
                "baseClasses": ["State"],
                "category": "Sequential Agents",
                "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
                "inputParams": [
                    {
                        "label": "Custom State",
                        "name": "stateMemory",
                        "type": "tabs",
                        "tabIdentifier": "selectedStateTab",
                        "additionalParams": true,
                        "default": "stateMemoryUI",
                        "tabs": [
                            {
                                "label": "Custom State (Table)",
                                "name": "stateMemoryUI",
                                "type": "datagrid",
                                "description": "Structure for state. By default, state contains \"messages\" that got updated with each message sent and received.",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\nSpecify the Key, Operation Type, and Default Value for the state object. The Operation Type can be either \"Replace\" or \"Append\".\n\n**Replace**\n- Replace the existing value with the new value.\n- If the new value is null, the existing value will be retained.\n\n**Append**\n- Append the new value to the existing value.\n- Default value can be empty or an array. Ex: [\"a\", \"b\"]\n- Final value is an array.\n"
                                },
                                "datagrid": [
                                    {
                                        "field": "key",
                                        "headerName": "Key",
                                        "editable": true
                                    },
                                    {
                                        "field": "type",
                                        "headerName": "Operation",
                                        "type": "singleSelect",
                                        "valueOptions": ["Replace", "Append"],
                                        "editable": true
                                    },
                                    {
                                        "field": "defaultValue",
                                        "headerName": "Default Value",
                                        "flex": 1,
                                        "editable": true
                                    }
                                ],
                                "optional": true,
                                "additionalParams": true
                            },
                            {
                                "label": "Custom State (Code)",
                                "name": "stateMemoryCode",
                                "type": "code",
                                "description": "JSON object representing the state",
                                "hideCodeExecute": true,
                                "codeExample": "{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "seqState_0-input-stateMemory-tabs"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "stateMemory": "stateMemoryUI",
                    "selectedStateTab_seqState_0": "stateMemoryUI",
                    "stateMemoryUI": "[{\"key\":\"sources\",\"type\":\"Replace\",\"defaultValue\":\"\",\"actions\":\"\",\"id\":0}]"
                },
                "outputAnchors": [
                    {
                        "id": "seqState_0-output-seqState-State",
                        "name": "seqState",
                        "label": "State",
                        "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
                        "type": "State"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 251,
            "selected": false,
            "positionAbsolute": {
                "x": 77.70108535391958,
                "y": 754.5682118080191
            },
            "dragging": false
        },
        {
            "id": "seqLLMNode_3",
            "position": {
                "x": 1484.4394246580907,
                "y": 133.55863518590365
            },
            "type": "customNode",
            "data": {
                "id": "seqLLMNode_3",
                "label": "LLM Node",
                "version": 2,
                "name": "seqLLMNode",
                "type": "LLMNode",
                "baseClasses": ["LLMNode"],
                "category": "Sequential Agents",
                "description": "Run Chat Model and return the output",
                "inputParams": [
                    {
                        "label": "Name",
                        "name": "llmNodeName",
                        "type": "string",
                        "placeholder": "LLM",
                        "id": "seqLLMNode_3-input-llmNodeName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_3-input-systemMessagePrompt-string"
                    },
                    {
                        "label": "Human Prompt",
                        "name": "humanMessagePrompt",
                        "type": "string",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_3-input-humanMessagePrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_3-input-promptValues-json"
                    },
                    {
                        "label": "JSON Structured Output",
                        "name": "llmStructuredOutput",
                        "type": "datagrid",
                        "description": "Instruct the LLM to give output in a JSON structured schema",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "type",
                                "headerName": "Type",
                                "type": "singleSelect",
                                "valueOptions": ["String", "String Array", "Number", "Boolean", "Enum"],
                                "editable": true
                            },
                            {
                                "field": "enumValues",
                                "headerName": "Enum Values",
                                "editable": true
                            },
                            {
                                "field": "description",
                                "headerName": "Description",
                                "flex": 1,
                                "editable": true
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqLLMNode_3-input-llmStructuredOutput-datagrid"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "tabs",
                        "tabIdentifier": "selectedUpdateStateMemoryTab",
                        "default": "updateStateMemoryUI",
                        "additionalParams": true,
                        "tabs": [
                            {
                                "label": "Update State (Table)",
                                "name": "updateStateMemoryUI",
                                "type": "datagrid",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                                "datagrid": [
                                    {
                                        "field": "key",
                                        "headerName": "Key",
                                        "type": "asyncSingleSelect",
                                        "loadMethod": "loadStateKeys",
                                        "flex": 0.5,
                                        "editable": true
                                    },
                                    {
                                        "field": "value",
                                        "headerName": "Value",
                                        "type": "freeSolo",
                                        "valueOptions": [
                                            {
                                                "label": "LLM Node Output (string)",
                                                "value": "$flow.output.content"
                                            },
                                            {
                                                "label": "LLM JSON Output Key (string)",
                                                "value": "$flow.output.<replace-with-key>"
                                            },
                                            {
                                                "label": "Global variable (string)",
                                                "value": "$vars.<variable-name>"
                                            },
                                            {
                                                "label": "Input Question (string)",
                                                "value": "$flow.input"
                                            },
                                            {
                                                "label": "Session Id (string)",
                                                "value": "$flow.sessionId"
                                            },
                                            {
                                                "label": "Chat Id (string)",
                                                "value": "$flow.chatId"
                                            },
                                            {
                                                "label": "Chatflow Id (string)",
                                                "value": "$flow.chatflowId"
                                            }
                                        ],
                                        "editable": true,
                                        "flex": 1
                                    }
                                ],
                                "optional": true,
                                "additionalParams": true
                            },
                            {
                                "label": "Update State (Code)",
                                "name": "updateStateMemoryCode",
                                "type": "code",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                                "hideCodeExecute": true,
                                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "seqLLMNode_3-input-updateStateMemory-tabs"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Start | Agent | Condition | LLM | Tool Node",
                        "name": "sequentialNode",
                        "type": "Start | Agent | Condition | LLMNode | ToolNode",
                        "list": true,
                        "id": "seqLLMNode_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this node",
                        "id": "seqLLMNode_3-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "llmNodeName": "Return Agent",
                    "systemMessagePrompt": "",
                    "humanMessagePrompt": "",
                    "sequentialNode": ["{{seqToolNode_0.data.instance}}", "{{seqToolNode_0.data.instance}}"],
                    "model": "",
                    "promptValues": "",
                    "llmStructuredOutput": "",
                    "updateStateMemory": "updateStateMemoryUI",
                    "selectedUpdateStateMemoryTab_seqLLMNode_3": "updateStateMemoryUI"
                },
                "outputAnchors": [
                    {
                        "id": "seqLLMNode_3-output-seqLLMNode-LLMNode",
                        "name": "seqLLMNode",
                        "label": "LLMNode",
                        "description": "Run Chat Model and return the output",
                        "type": "LLMNode"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 450,
            "selected": false,
            "positionAbsolute": {
                "x": 1484.4394246580907,
                "y": 133.55863518590365
            },
            "dragging": false
        },
        {
            "id": "retrieverTool_1",
            "position": {
                "x": 790.3030387882359,
                "y": -1120.8808285089046
            },
            "type": "customNode",
            "data": {
                "id": "retrieverTool_1",
                "label": "Retriever Tool",
                "version": 2,
                "name": "retrieverTool",
                "type": "RetrieverTool",
                "baseClasses": ["RetrieverTool", "DynamicTool", "Tool", "StructuredTool", "Runnable"],
                "category": "Tools",
                "description": "Use a retriever as allowed tool for agent",
                "inputParams": [
                    {
                        "label": "Retriever Name",
                        "name": "name",
                        "type": "string",
                        "placeholder": "search_state_of_union",
                        "id": "retrieverTool_1-input-name-string"
                    },
                    {
                        "label": "Retriever Description",
                        "name": "description",
                        "type": "string",
                        "description": "When should agent uses to retrieve documents",
                        "rows": 3,
                        "placeholder": "Searches and returns documents regarding the state-of-the-union.",
                        "id": "retrieverTool_1-input-description-string"
                    },
                    {
                        "label": "Return Source Documents",
                        "name": "returnSourceDocuments",
                        "type": "boolean",
                        "optional": true,
                        "id": "retrieverTool_1-input-returnSourceDocuments-boolean"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Retriever",
                        "name": "retriever",
                        "type": "BaseRetriever",
                        "id": "retrieverTool_1-input-retriever-BaseRetriever"
                    }
                ],
                "inputs": {
                    "name": "search_tesla",
                    "description": "Search and return documents about Tesla Inc (TSLA)",
                    "retriever": "{{pinecone_1.data.instance}}",
                    "returnSourceDocuments": true
                },
                "outputAnchors": [
                    {
                        "id": "retrieverTool_1-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
                        "name": "retrieverTool",
                        "label": "RetrieverTool",
                        "description": "Use a retriever as allowed tool for agent",
                        "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 602,
            "selected": false,
            "positionAbsolute": {
                "x": 790.3030387882359,
                "y": -1120.8808285089046
            },
            "dragging": false
        },
        {
            "id": "pinecone_1",
            "position": {
                "x": 450.26001217086275,
                "y": -1141.7900096795315
            },
            "type": "customNode",
            "data": {
                "id": "pinecone_1",
                "label": "Pinecone",
                "version": 4,
                "name": "pinecone",
                "type": "Pinecone",
                "baseClasses": ["Pinecone", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["pineconeApi"],
                        "id": "pinecone_1-input-credential-credential"
                    },
                    {
                        "label": "Pinecone Index",
                        "name": "pineconeIndex",
                        "type": "string",
                        "id": "pinecone_1-input-pineconeIndex-string"
                    },
                    {
                        "label": "Pinecone Namespace",
                        "name": "pineconeNamespace",
                        "type": "string",
                        "placeholder": "my-first-namespace",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_1-input-pineconeNamespace-string"
                    },
                    {
                        "label": "Pinecone Text Key",
                        "name": "pineconeTextKey",
                        "description": "The key in the metadata for storing text. Default to `text`",
                        "type": "string",
                        "placeholder": "text",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_1-input-pineconeTextKey-string"
                    },
                    {
                        "label": "Pinecone Metadata Filter",
                        "name": "pineconeMetadataFilter",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "pinecone_1-input-pineconeMetadataFilter-json"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_1-input-topK-number"
                    },
                    {
                        "label": "Search Type",
                        "name": "searchType",
                        "type": "options",
                        "default": "similarity",
                        "options": [
                            {
                                "label": "Similarity",
                                "name": "similarity"
                            },
                            {
                                "label": "Max Marginal Relevance",
                                "name": "mmr"
                            }
                        ],
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_1-input-searchType-options"
                    },
                    {
                        "label": "Fetch K (for MMR Search)",
                        "name": "fetchK",
                        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
                        "placeholder": "20",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_1-input-fetchK-number"
                    },
                    {
                        "label": "Lambda (for MMR Search)",
                        "name": "lambda",
                        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
                        "placeholder": "0.5",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_1-input-lambda-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "pinecone_1-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "pinecone_1-input-embeddings-Embeddings"
                    },
                    {
                        "label": "Record Manager",
                        "name": "recordManager",
                        "type": "RecordManager",
                        "description": "Keep track of the record to prevent duplication",
                        "optional": true,
                        "id": "pinecone_1-input-recordManager-RecordManager"
                    }
                ],
                "inputs": {
                    "document": "",
                    "embeddings": "{{openAIEmbeddings_1.data.instance}}",
                    "recordManager": "",
                    "pineconeIndex": "flowiseindex",
                    "pineconeNamespace": "pinecone-form10k",
                    "pineconeTextKey": "",
                    "pineconeMetadataFilter": "{\"source\":\"tesla\"}",
                    "topK": "",
                    "searchType": "similarity",
                    "fetchK": "",
                    "lambda": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "pinecone_1-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Pinecone Retriever",
                                "description": "",
                                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "pinecone_1-output-vectorStore-Pinecone|VectorStore",
                                "name": "vectorStore",
                                "label": "Pinecone Vector Store",
                                "description": "",
                                "type": "Pinecone | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "width": 300,
            "height": 604,
            "selected": false,
            "positionAbsolute": {
                "x": 450.26001217086275,
                "y": -1141.7900096795315
            },
            "dragging": false
        },
        {
            "id": "openAIEmbeddings_1",
            "position": {
                "x": 83.2190471911639,
                "y": -1022.4738406801706
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_1",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_1-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_1-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_1-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 423,
            "selected": false,
            "positionAbsolute": {
                "x": 83.2190471911639,
                "y": -1022.4738406801706
            },
            "dragging": false
        },
        {
            "id": "chatOpenAI_0",
            "position": {
                "x": 91.23954366267867,
                "y": 44.74196864160342
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o",
                    "temperature": "0",
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": "",
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "positionAbsolute": {
                "x": 91.23954366267867,
                "y": 44.74196864160342
            },
            "dragging": false
        },
        {
            "id": "stickyNote_0",
            "position": {
                "x": 1140.2198047126058,
                "y": 646.3675590258875
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_0",
                "label": "Sticky Note",
                "version": 2,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "tags": ["Utilities"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_0-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "This is a 3 step flow:\n\n1.) First agent will determine if there is a need to call the tools. If yes, LLM will output something like: {tool_calls: []}\n\n2.) The tools within tool_calls from LLM will be executed by the Tool Node\n\n3.) The result of the tools is passed to Return Agent, for it to finalize into a proper natural language response\n\nAI Message -> Tool Message -> AI Message"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_0-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 304,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 1140.2198047126058,
                "y": 646.3675590258875
            }
        },
        {
            "id": "stickyNote_1",
            "position": {
                "x": -239.50512438417962,
                "y": 177.3825013233846
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_1",
                "label": "Sticky Note",
                "version": 2,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "tags": ["Utilities"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_1-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "This is an self-improving agentic RAG.\n\n1.) LLM will decide if tools are needed to search from vector databases\n2.) Condition agent is used to decided if the documents retrieved are relevant to the question asked\n3.) If yes, generate the natural language response.\n4.) If no, rewrite the query and loop back to the first LLM"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_1-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 243,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": -239.50512438417962,
                "y": 177.3825013233846
            }
        },
        {
            "id": "stickyNote_2",
            "position": {
                "x": 1843.7085078021976,
                "y": 699.2543113600216
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_2",
                "label": "Sticky Note",
                "version": 2,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "tags": ["Utilities"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_2-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "We asked the LLM to grade the relevance of the context to the question asked.\n\nThen output a JSON object:\n{ score: \"yes\" or \"no\" }"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_2-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 123,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 1843.7085078021976,
                "y": 699.2543113600216
            }
        },
        {
            "id": "seqToolNode_0",
            "position": {
                "x": 1145.2597612442403,
                "y": 82.9257022956856
            },
            "type": "customNode",
            "data": {
                "id": "seqToolNode_0",
                "label": "Tool Node",
                "version": 2,
                "name": "seqToolNode",
                "type": "ToolNode",
                "baseClasses": ["ToolNode"],
                "category": "Sequential Agents",
                "description": "Execute tool and return tool's output",
                "inputParams": [
                    {
                        "label": "Name",
                        "name": "toolNodeName",
                        "type": "string",
                        "placeholder": "Tool",
                        "id": "seqToolNode_0-input-toolNodeName-string"
                    },
                    {
                        "label": "Require Approval",
                        "name": "interrupt",
                        "description": "Require approval before executing tools",
                        "type": "boolean",
                        "optional": true,
                        "id": "seqToolNode_0-input-interrupt-boolean"
                    },
                    {
                        "label": "Approval Prompt",
                        "name": "approvalPrompt",
                        "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
                        "type": "string",
                        "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqToolNode_0-input-approvalPrompt-string"
                    },
                    {
                        "label": "Approve Button Text",
                        "name": "approveButtonText",
                        "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
                        "type": "string",
                        "default": "Yes",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqToolNode_0-input-approveButtonText-string"
                    },
                    {
                        "label": "Reject Button Text",
                        "name": "rejectButtonText",
                        "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
                        "type": "string",
                        "default": "No",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqToolNode_0-input-rejectButtonText-string"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "tabs",
                        "tabIdentifier": "selectedUpdateStateMemoryTab",
                        "additionalParams": true,
                        "default": "updateStateMemoryUI",
                        "tabs": [
                            {
                                "label": "Update State (Table)",
                                "name": "updateStateMemoryUI",
                                "type": "datagrid",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as `$flow.output` with the following structure (array):\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"sourceDocuments\": [\n                {\n                    \"pageContent\": \"This is the page content\",\n                    \"metadata\": \"{foo: var}\",\n                }\n            ],\n        }\n    ]\n    ```\n\n    For example:\n    | Key          | Value                                     |\n    |--------------|-------------------------------------------|\n    | sources      | `$flow.output[0].sourceDocuments`       |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After tool execution, you might want to update the State values",
                                "datagrid": [
                                    {
                                        "field": "key",
                                        "headerName": "Key",
                                        "type": "asyncSingleSelect",
                                        "loadMethod": "loadStateKeys",
                                        "flex": 0.5,
                                        "editable": true
                                    },
                                    {
                                        "field": "value",
                                        "headerName": "Value",
                                        "type": "freeSolo",
                                        "valueOptions": [
                                            {
                                                "label": "All Tools Output (array)",
                                                "value": "$flow.output"
                                            },
                                            {
                                                "label": "First Tool Output (string)",
                                                "value": "$flow.output[0].toolOutput"
                                            },
                                            {
                                                "label": "First Tool Input Arguments (string | json)",
                                                "value": "$flow.output[0].toolInput"
                                            },
                                            {
                                                "label": "First Tool Returned Source Documents (array)",
                                                "value": "$flow.output[0].sourceDocuments"
                                            },
                                            {
                                                "label": "Global variable (string)",
                                                "value": "$vars.<variable-name>"
                                            },
                                            {
                                                "label": "Input Question (string)",
                                                "value": "$flow.input"
                                            },
                                            {
                                                "label": "Session Id (string)",
                                                "value": "$flow.sessionId"
                                            },
                                            {
                                                "label": "Chat Id (string)",
                                                "value": "$flow.chatId"
                                            },
                                            {
                                                "label": "Chatflow Id (string)",
                                                "value": "$flow.chatflowId"
                                            }
                                        ],
                                        "editable": true,
                                        "flex": 1
                                    }
                                ],
                                "optional": true,
                                "additionalParams": true
                            },
                            {
                                "label": "Update State (Code)",
                                "name": "updateStateMemoryCode",
                                "type": "code",
                                "hint": {
                                    "label": "How to use",
                                    "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the tool's output as the value to update state, it is available as `$flow.output` with the following structure (array):\n    ```json\n    [\n        {\n            \"tool\": \"tool's name\",\n            \"toolInput\": {},\n            \"toolOutput\": \"tool's output content\",\n            \"sourceDocuments\": [\n                {\n                    \"pageContent\": \"This is the page content\",\n                    \"metadata\": \"{foo: var}\",\n                }\n            ],\n        }\n    ]\n    ```\n\n    For example:\n    ```js\n    /* Assuming you have the following state:\n    {\n        \"sources\": null\n    }\n    */\n    \n    return {\n        \"sources\": $flow.output[0].sourceDocuments\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                                },
                                "description": "This is only applicable when you have a custom State at the START node. After tool execution, you might want to update the State values. Must return an object representing the state",
                                "hideCodeExecute": true,
                                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "seqToolNode_0-input-updateStateMemory-tabs"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "optional": true,
                        "id": "seqToolNode_0-input-tools-Tool"
                    },
                    {
                        "label": "LLM Node",
                        "name": "llmNode",
                        "type": "LLMNode",
                        "id": "seqToolNode_0-input-llmNode-LLMNode"
                    }
                ],
                "inputs": {
                    "tools": ["{{retrieverTool_0.data.instance}}", "{{retrieverTool_1.data.instance}}"],
                    "llmNode": "{{seqLLMNode_0.data.instance}}",
                    "toolNodeName": "Retrieve",
                    "interrupt": "",
                    "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
                    "approveButtonText": "Yes",
                    "rejectButtonText": "No",
                    "updateStateMemory": "updateStateMemoryUI",
                    "selectedUpdateStateMemoryTab_seqToolNode_0": "updateStateMemoryCode",
                    "updateStateMemoryCode": "const result = $flow.output;\n\nconst sourceDocuments = result[0].sourceDocuments || [];\n\n/*\n* Format into:\nabc\nsources: {source: 'a', page: 12}\n*/\nconst formattedSources = sourceDocuments.map(item => {\n        const pageContent = item.pageContent;\n        const metadata = `Sources: ${JSON.stringify(item.metadata)}`;\n        return `${pageContent}\\n${metadata}`;\n    }).join('\\n\\n');\n\nreturn {\n  sources: formattedSources\n};"
                },
                "outputAnchors": [
                    {
                        "id": "seqToolNode_0-output-seqToolNode-ToolNode",
                        "name": "seqToolNode",
                        "label": "ToolNode",
                        "description": "Execute tool and return tool's output",
                        "type": "ToolNode"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 528,
            "selected": false,
            "positionAbsolute": {
                "x": 1145.2597612442403,
                "y": 82.9257022956856
            },
            "dragging": false
        },
        {
            "id": "agentMemory_0",
            "position": {
                "x": -239.3552509118846,
                "y": 449.35468482835086
            },
            "type": "customNode",
            "data": {
                "id": "agentMemory_0",
                "label": "Agent Memory",
                "version": 1,
                "name": "agentMemory",
                "type": "AgentMemory",
                "baseClasses": ["AgentMemory", "BaseCheckpointSaver"],
                "category": "Memory",
                "description": "Memory for agentflow to remember the state of the conversation",
                "inputParams": [
                    {
                        "label": "Database",
                        "name": "databaseType",
                        "type": "options",
                        "options": [
                            {
                                "label": "SQLite",
                                "name": "sqlite"
                            }
                        ],
                        "default": "sqlite",
                        "id": "agentMemory_0-input-databaseType-options"
                    },
                    {
                        "label": "Database File Path",
                        "name": "databaseFilePath",
                        "type": "string",
                        "placeholder": "C:\\Users\\User\\.flowise\\database.sqlite",
                        "description": "If SQLite is selected, provide the path to the SQLite database file. Leave empty to use default application database",
                        "additionalParams": true,
                        "optional": true,
                        "id": "agentMemory_0-input-databaseFilePath-string"
                    },
                    {
                        "label": "Additional Connection Configuration",
                        "name": "additionalConfig",
                        "type": "json",
                        "additionalParams": true,
                        "optional": true,
                        "id": "agentMemory_0-input-additionalConfig-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "databaseType": "sqlite",
                    "databaseFilePath": "",
                    "additionalConfig": ""
                },
                "outputAnchors": [
                    {
                        "id": "agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver",
                        "name": "agentMemory",
                        "label": "AgentMemory",
                        "description": "Memory for agentflow to remember the state of the conversation",
                        "type": "AgentMemory | BaseCheckpointSaver"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 327,
            "selected": false,
            "positionAbsolute": {
                "x": -239.3552509118846,
                "y": 449.35468482835086
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "pinecone_0",
            "sourceHandle": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
            "target": "retrieverTool_0",
            "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
            "type": "buttonedge",
            "id": "pinecone_0-pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
        },
        {
            "source": "openAIEmbeddings_0",
            "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "pinecone_0",
            "targetHandle": "pinecone_0-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-pinecone_0-pinecone_0-input-embeddings-Embeddings"
        },
        {
            "source": "seqState_0",
            "sourceHandle": "seqState_0-output-seqState-State",
            "target": "seqStart_0",
            "targetHandle": "seqStart_0-input-state-State",
            "type": "buttonedge",
            "id": "seqState_0-seqState_0-output-seqState-State-seqStart_0-seqStart_0-input-state-State"
        },
        {
            "source": "seqLLMNode_3",
            "sourceHandle": "seqLLMNode_3-output-seqLLMNode-LLMNode",
            "target": "seqConditionAgent_0",
            "targetHandle": "seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqLLMNode_3-seqLLMNode_3-output-seqLLMNode-LLMNode-seqConditionAgent_0-seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode"
        },
        {
            "source": "openAIEmbeddings_1",
            "sourceHandle": "openAIEmbeddings_1-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "pinecone_1",
            "targetHandle": "pinecone_1-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_1-openAIEmbeddings_1-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-pinecone_1-pinecone_1-input-embeddings-Embeddings"
        },
        {
            "source": "pinecone_1",
            "sourceHandle": "pinecone_1-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
            "target": "retrieverTool_1",
            "targetHandle": "retrieverTool_1-input-retriever-BaseRetriever",
            "type": "buttonedge",
            "id": "pinecone_1-pinecone_1-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-retrieverTool_1-retrieverTool_1-input-retriever-BaseRetriever"
        },
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "seqStart_0",
            "targetHandle": "seqStart_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"
        },
        {
            "source": "retrieverTool_0",
            "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "target": "seqToolNode_0",
            "targetHandle": "seqToolNode_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqToolNode_0-seqToolNode_0-input-tools-Tool"
        },
        {
            "source": "seqLLMNode_0",
            "sourceHandle": "seqLLMNode_0-output-seqLLMNode-LLMNode",
            "target": "seqToolNode_0",
            "targetHandle": "seqToolNode_0-input-llmNode-LLMNode",
            "type": "buttonedge",
            "id": "seqLLMNode_0-seqLLMNode_0-output-seqLLMNode-LLMNode-seqToolNode_0-seqToolNode_0-input-llmNode-LLMNode"
        },
        {
            "source": "retrieverTool_1",
            "sourceHandle": "retrieverTool_1-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "target": "seqToolNode_0",
            "targetHandle": "seqToolNode_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "retrieverTool_1-retrieverTool_1-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqToolNode_0-seqToolNode_0-input-tools-Tool"
        },
        {
            "source": "agentMemory_0",
            "sourceHandle": "agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver",
            "target": "seqStart_0",
            "targetHandle": "seqStart_0-input-agentMemory-BaseCheckpointSaver",
            "type": "buttonedge",
            "id": "agentMemory_0-agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver-seqStart_0-seqStart_0-input-agentMemory-BaseCheckpointSaver"
        },
        {
            "source": "seqStart_0",
            "sourceHandle": "seqStart_0-output-seqStart-Start",
            "target": "seqLLMNode_0",
            "targetHandle": "seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqStart_0-seqStart_0-output-seqStart-Start-seqLLMNode_0-seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
        },
        {
            "source": "seqToolNode_0",
            "sourceHandle": "seqToolNode_0-output-seqToolNode-ToolNode",
            "target": "seqLLMNode_3",
            "targetHandle": "seqLLMNode_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqToolNode_0-seqToolNode_0-output-seqToolNode-ToolNode-seqLLMNode_3-seqLLMNode_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
        },
        {
            "source": "seqConditionAgent_0",
            "sourceHandle": "seqConditionAgent_0-output-end-Condition",
            "target": "seqEnd_1",
            "targetHandle": "seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqConditionAgent_0-seqConditionAgent_0-output-end-Condition-seqEnd_1-seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
        },
        {
            "source": "seqConditionAgent_0",
            "sourceHandle": "seqConditionAgent_0-output-generate-Condition",
            "target": "seqLLMNode_2",
            "targetHandle": "seqLLMNode_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqConditionAgent_0-seqConditionAgent_0-output-generate-Condition-seqLLMNode_2-seqLLMNode_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
        },
        {
            "source": "seqConditionAgent_0",
            "sourceHandle": "seqConditionAgent_0-output-rewrite-Condition",
            "target": "seqLLMNode_1",
            "targetHandle": "seqLLMNode_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqConditionAgent_0-seqConditionAgent_0-output-rewrite-Condition-seqLLMNode_1-seqLLMNode_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
        },
        {
            "source": "seqLLMNode_2",
            "sourceHandle": "seqLLMNode_2-output-seqLLMNode-LLMNode",
            "target": "seqEnd_0",
            "targetHandle": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqLLMNode_2-seqLLMNode_2-output-seqLLMNode-LLMNode-seqEnd_0-seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
        },
        {
            "source": "seqLLMNode_1",
            "sourceHandle": "seqLLMNode_1-output-seqLLMNode-LLMNode",
            "target": "seqLoop_0",
            "targetHandle": "seqLoop_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
            "type": "buttonedge",
            "id": "seqLLMNode_1-seqLLMNode_1-output-seqLLMNode-LLMNode-seqLoop_0-seqLoop_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
        }
    ]
}
