{
    "description": "Customer support team consisting of Support Representative and Quality Assurance Specialist to handle support tickets",
    "framework": ["Langchain"],
    "usecases": ["Customer Support", "Hierarchical Agent Teams"],
    "nodes": [
        {
            "id": "supervisor_0",
            "position": {
                "x": 343.59847938459717,
                "y": 124.00657409829381
            },
            "type": "customNode",
            "data": {
                "id": "supervisor_0",
                "label": "Supervisor",
                "version": 1,
                "name": "supervisor",
                "type": "Supervisor",
                "baseClasses": ["Supervisor"],
                "category": "Multi Agents",
                "inputParams": [
                    {
                        "label": "Supervisor Name",
                        "name": "supervisorName",
                        "type": "string",
                        "placeholder": "Supervisor",
                        "default": "Supervisor",
                        "id": "supervisor_0-input-supervisorName-string"
                    },
                    {
                        "label": "Supervisor Prompt",
                        "name": "supervisorPrompt",
                        "type": "string",
                        "description": "Prompt must contains {team_members}",
                        "rows": 4,
                        "default": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
                        "additionalParams": true,
                        "id": "supervisor_0-input-supervisorPrompt-string"
                    },
                    {
                        "label": "Recursion Limit",
                        "name": "recursionLimit",
                        "type": "number",
                        "description": "Maximum number of times a call can recurse. If not provided, defaults to 100.",
                        "default": 100,
                        "additionalParams": true,
                        "id": "supervisor_0-input-recursionLimit-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tool Calling Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, GroqChat. Best result with GPT-4 model",
                        "id": "supervisor_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "supervisor_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "supervisorName": "Supervisor",
                    "supervisorPrompt": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "recursionLimit": 100,
                    "inputModeration": ""
                },
                "outputAnchors": [
                    {
                        "id": "supervisor_0-output-supervisor-Supervisor",
                        "name": "supervisor",
                        "label": "Supervisor",
                        "description": "",
                        "type": "Supervisor"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 431,
            "selected": false,
            "positionAbsolute": {
                "x": 343.59847938459717,
                "y": 124.00657409829381
            },
            "dragging": false
        },
        {
            "id": "worker_0",
            "position": {
                "x": 848.0791314419789,
                "y": 550.1251435439353
            },
            "type": "customNode",
            "data": {
                "id": "worker_0",
                "label": "Worker",
                "version": 1,
                "name": "worker",
                "type": "Worker",
                "baseClasses": ["Worker"],
                "category": "Multi Agents",
                "inputParams": [
                    {
                        "label": "Worker Name",
                        "name": "workerName",
                        "type": "string",
                        "placeholder": "Worker",
                        "id": "worker_0-input-workerName-string"
                    },
                    {
                        "label": "Worker Prompt",
                        "name": "workerPrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are a research assistant who can search for up-to-date info using search engine.",
                        "id": "worker_0-input-workerPrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "worker_0-input-promptValues-json"
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "id": "worker_0-input-maxIterations-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "optional": true,
                        "id": "worker_0-input-tools-Tool"
                    },
                    {
                        "label": "Supervisor",
                        "name": "supervisor",
                        "type": "Supervisor",
                        "id": "worker_0-input-supervisor-Supervisor"
                    },
                    {
                        "label": "Tool Calling Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
                        "id": "worker_0-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "workerName": "Quality Assurance Specialist",
                    "workerPrompt": "You are working at {company} and are now collaborating with your team on a customer request. Your task is to ensure that the support representative delivers the best possible support. It's crucial that the representative provides complete, accurate answers without making any assumptions.\n\nYour objective is to maintain top-tier support quality assurance within your team.\n\nReview the response drafted by the support representative for the customer's inquiry. Make sure the answer is thorough, accurate, and meets the high standards expected in customer support. Confirm that every aspect of the customer's question is addressed comprehensively, with a friendly and helpful tone. Verify that all references and sources used to find the information are included, ensuring the response is well-supported and leaves no questions unanswered.\n\nOnce your review is complete, return it to the Support Representative for finalization.",
                    "tools": "",
                    "supervisor": "{{supervisor_0.data.instance}}",
                    "model": "",
                    "promptValues": "{\"company\":\"Flowise Inc\"}",
                    "maxIterations": ""
                },
                "outputAnchors": [
                    {
                        "id": "worker_0-output-worker-Worker",
                        "name": "worker",
                        "label": "Worker",
                        "description": "",
                        "type": "Worker"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 808,
            "positionAbsolute": {
                "x": 848.0791314419789,
                "y": 550.1251435439353
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "worker_1",
            "position": {
                "x": 1573.2919579833303,
                "y": -234.22598124451474
            },
            "type": "customNode",
            "data": {
                "id": "worker_1",
                "label": "Worker",
                "version": 1,
                "name": "worker",
                "type": "Worker",
                "baseClasses": ["Worker"],
                "category": "Multi Agents",
                "inputParams": [
                    {
                        "label": "Worker Name",
                        "name": "workerName",
                        "type": "string",
                        "placeholder": "Worker",
                        "id": "worker_1-input-workerName-string"
                    },
                    {
                        "label": "Worker Prompt",
                        "name": "workerPrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are a research assistant who can search for up-to-date info using search engine.",
                        "id": "worker_1-input-workerPrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "worker_1-input-promptValues-json"
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "id": "worker_1-input-maxIterations-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "optional": true,
                        "id": "worker_1-input-tools-Tool"
                    },
                    {
                        "label": "Supervisor",
                        "name": "supervisor",
                        "type": "Supervisor",
                        "id": "worker_1-input-supervisor-Supervisor"
                    },
                    {
                        "label": "Tool Calling Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
                        "id": "worker_1-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "workerName": "Support Representative",
                    "workerPrompt": "As a representative at {company}, your role is to deliver exceptional customer support. Your objective is to provide the highest quality assistance, ensuring that your answers are comprehensive and based on facts without any assumptions.\n\nYour goal is to strive to be the most friendly and helpful support representative on your team.\n\nHere is your previous conversation with the customer:\n{conversation}\n\nCraft a detailed and informative response to the customer's inquiry, addressing all aspects of their question. Your response should include references to all sources used to find the answer, including external data or solutions. Ensure your answer is thorough, leaving no questions unanswered, while maintaining a friendly and supportive tone throughout.\n\nAlways use the tool provided - search_docs to look for answers. Check if you need to pass the result to Quality Assurance Specialist for review.",
                    "tools": ["{{retrieverTool_0.data.instance}}"],
                    "supervisor": "{{supervisor_0.data.instance}}",
                    "model": "",
                    "promptValues": "{\"company\":\"Flowise Inc\",\"conversation\":\"{{customFunction_0.data.instance}}\"}",
                    "maxIterations": ""
                },
                "outputAnchors": [
                    {
                        "id": "worker_1-output-worker-Worker",
                        "name": "worker",
                        "label": "Worker",
                        "description": "",
                        "type": "Worker"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 808,
            "positionAbsolute": {
                "x": 1573.2919579833303,
                "y": -234.22598124451474
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "retrieverTool_0",
            "position": {
                "x": 1136.3773214513722,
                "y": -661.7020929797668
            },
            "type": "customNode",
            "data": {
                "id": "retrieverTool_0",
                "label": "Retriever Tool",
                "version": 2,
                "name": "retrieverTool",
                "type": "RetrieverTool",
                "baseClasses": ["RetrieverTool", "DynamicTool", "Tool", "StructuredTool", "Runnable"],
                "category": "Tools",
                "description": "Use a retriever as allowed tool for agent",
                "inputParams": [
                    {
                        "label": "Retriever Name",
                        "name": "name",
                        "type": "string",
                        "placeholder": "search_state_of_union",
                        "id": "retrieverTool_0-input-name-string"
                    },
                    {
                        "label": "Retriever Description",
                        "name": "description",
                        "type": "string",
                        "description": "When should agent uses to retrieve documents",
                        "rows": 3,
                        "placeholder": "Searches and returns documents regarding the state-of-the-union.",
                        "id": "retrieverTool_0-input-description-string"
                    },
                    {
                        "label": "Return Source Documents",
                        "name": "returnSourceDocuments",
                        "type": "boolean",
                        "optional": true,
                        "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Retriever",
                        "name": "retriever",
                        "type": "BaseRetriever",
                        "id": "retrieverTool_0-input-retriever-BaseRetriever"
                    }
                ],
                "inputs": {
                    "name": "search_docs",
                    "description": "Search and return documents about any issue or bugfix. Always give priority to this tool",
                    "retriever": "{{pinecone_0.data.instance}}",
                    "returnSourceDocuments": ""
                },
                "outputAnchors": [
                    {
                        "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
                        "name": "retrieverTool",
                        "label": "RetrieverTool",
                        "description": "Use a retriever as allowed tool for agent",
                        "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 602,
            "selected": false,
            "positionAbsolute": {
                "x": 1136.3773214513722,
                "y": -661.7020929797668
            },
            "dragging": false
        },
        {
            "id": "pinecone_0",
            "position": {
                "x": 767.1744633865214,
                "y": -634.6870559540365
            },
            "type": "customNode",
            "data": {
                "id": "pinecone_0",
                "label": "Pinecone",
                "version": 3,
                "name": "pinecone",
                "type": "Pinecone",
                "baseClasses": ["Pinecone", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["pineconeApi"],
                        "id": "pinecone_0-input-credential-credential"
                    },
                    {
                        "label": "Pinecone Index",
                        "name": "pineconeIndex",
                        "type": "string",
                        "id": "pinecone_0-input-pineconeIndex-string"
                    },
                    {
                        "label": "Pinecone Namespace",
                        "name": "pineconeNamespace",
                        "type": "string",
                        "placeholder": "my-first-namespace",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-pineconeNamespace-string"
                    },
                    {
                        "label": "Pinecone Metadata Filter",
                        "name": "pineconeMetadataFilter",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "pinecone_0-input-pineconeMetadataFilter-json"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-topK-number"
                    },
                    {
                        "label": "Search Type",
                        "name": "searchType",
                        "type": "options",
                        "default": "similarity",
                        "options": [
                            {
                                "label": "Similarity",
                                "name": "similarity"
                            },
                            {
                                "label": "Max Marginal Relevance",
                                "name": "mmr"
                            }
                        ],
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-searchType-options"
                    },
                    {
                        "label": "Fetch K (for MMR Search)",
                        "name": "fetchK",
                        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
                        "placeholder": "20",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-fetchK-number"
                    },
                    {
                        "label": "Lambda (for MMR Search)",
                        "name": "lambda",
                        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
                        "placeholder": "0.5",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "pinecone_0-input-lambda-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "pinecone_0-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "pinecone_0-input-embeddings-Embeddings"
                    },
                    {
                        "label": "Record Manager",
                        "name": "recordManager",
                        "type": "RecordManager",
                        "description": "Keep track of the record to prevent duplication",
                        "optional": true,
                        "id": "pinecone_0-input-recordManager-RecordManager"
                    }
                ],
                "inputs": {
                    "document": "",
                    "embeddings": "{{openAIEmbeddings_0.data.instance}}",
                    "recordManager": "",
                    "pineconeIndex": "flowiseindex",
                    "pineconeNamespace": "pinecone-flowise-docs",
                    "pineconeMetadataFilter": "",
                    "topK": "",
                    "searchType": "similarity",
                    "fetchK": "",
                    "lambda": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Pinecone Retriever",
                                "description": "",
                                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "pinecone_0-output-vectorStore-Pinecone|VectorStore",
                                "name": "vectorStore",
                                "label": "Pinecone Vector Store",
                                "description": "",
                                "type": "Pinecone | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "width": 300,
            "height": 604,
            "selected": false,
            "positionAbsolute": {
                "x": 767.1744633865214,
                "y": -634.6870559540365
            },
            "dragging": false
        },
        {
            "id": "openAIEmbeddings_0",
            "position": {
                "x": 373.4730229546882,
                "y": -480.5312248256105
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_0",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 423,
            "selected": false,
            "positionAbsolute": {
                "x": 373.4730229546882,
                "y": -480.5312248256105
            },
            "dragging": false
        },
        {
            "id": "customFunction_0",
            "position": {
                "x": 1214.8704502141265,
                "y": 109.13589410824264
            },
            "type": "customNode",
            "data": {
                "id": "customFunction_0",
                "label": "Custom JS Function",
                "version": 1,
                "name": "customFunction",
                "type": "CustomFunction",
                "baseClasses": ["CustomFunction", "Utilities"],
                "category": "Utilities",
                "description": "Execute custom javascript function",
                "inputParams": [
                    {
                        "label": "Input Variables",
                        "name": "functionInputVariables",
                        "description": "Input variables can be used in the function with prefix $. For example: $var",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "customFunction_0-input-functionInputVariables-json"
                    },
                    {
                        "label": "Function Name",
                        "name": "functionName",
                        "type": "string",
                        "optional": true,
                        "placeholder": "My Function",
                        "id": "customFunction_0-input-functionName-string"
                    },
                    {
                        "label": "Javascript Function",
                        "name": "javascriptFunction",
                        "type": "code",
                        "id": "customFunction_0-input-javascriptFunction-code"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "functionInputVariables": "",
                    "functionName": "",
                    "javascriptFunction": "// Simulating fetching conversation between system and customer\nconst conversations =[\n  {\n    \"role\": \"bot\",\n    \"content\": \"Hey how can I help you?\",\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"There is a bug when installing Flowise\",\n  },\n  {\n    \"role\": \"bot\",\n    \"content\": \"Can you tell me what was the error?\",\n  }\n];\n\nreturn conversations;"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "customFunction_0-output-output-string|number|boolean|json|array",
                                "name": "output",
                                "label": "Output",
                                "description": "",
                                "type": "string | number | boolean | json | array"
                            },
                            {
                                "id": "customFunction_0-output-EndingNode-CustomFunction",
                                "name": "EndingNode",
                                "label": "Ending Node",
                                "description": "",
                                "type": "CustomFunction"
                            }
                        ],
                        "default": "output"
                    }
                ],
                "outputs": {
                    "output": "output"
                },
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "positionAbsolute": {
                "x": 1214.8704502141265,
                "y": 109.13589410824264
            },
            "dragging": false
        },
        {
            "id": "chatOpenAI_0",
            "position": {
                "x": -29.209923556934555,
                "y": -53.48197675171315
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o",
                    "temperature": "0",
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": "",
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "positionAbsolute": {
                "x": -29.209923556934555,
                "y": -53.48197675171315
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "openAIEmbeddings_0",
            "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "pinecone_0",
            "targetHandle": "pinecone_0-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-pinecone_0-pinecone_0-input-embeddings-Embeddings"
        },
        {
            "source": "pinecone_0",
            "sourceHandle": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
            "target": "retrieverTool_0",
            "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
            "type": "buttonedge",
            "id": "pinecone_0-pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
        },
        {
            "source": "retrieverTool_0",
            "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "target": "worker_1",
            "targetHandle": "worker_1-input-tools-Tool",
            "type": "buttonedge",
            "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-worker_1-worker_1-input-tools-Tool"
        },
        {
            "source": "supervisor_0",
            "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
            "target": "worker_1",
            "targetHandle": "worker_1-input-supervisor-Supervisor",
            "type": "buttonedge",
            "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_1-worker_1-input-supervisor-Supervisor"
        },
        {
            "source": "supervisor_0",
            "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
            "target": "worker_0",
            "targetHandle": "worker_0-input-supervisor-Supervisor",
            "type": "buttonedge",
            "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_0-worker_0-input-supervisor-Supervisor"
        },
        {
            "source": "customFunction_0",
            "sourceHandle": "customFunction_0-output-output-string|number|boolean|json|array",
            "target": "worker_1",
            "targetHandle": "worker_1-input-promptValues-json",
            "type": "buttonedge",
            "id": "customFunction_0-customFunction_0-output-output-string|number|boolean|json|array-worker_1-worker_1-input-promptValues-json"
        },
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "supervisor_0",
            "targetHandle": "supervisor_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-supervisor_0-supervisor_0-input-model-BaseChatModel"
        }
    ]
}
