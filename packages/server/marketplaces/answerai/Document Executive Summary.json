{
    "nodes": [
        {
            "id": "chatOpenAI_0",
            "position": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": "",
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            }
        },
        {
            "id": "llmChain_0",
            "position": {
                "x": 1150.5733832269552,
                "y": 536.2519213587326
            },
            "type": "customNode",
            "data": {
                "id": "llmChain_0",
                "label": "LLM Chain",
                "version": 3,
                "name": "llmChain",
                "type": "LLMChain",
                "baseClasses": ["LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chain to run queries against LLMs",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "chainName",
                        "type": "string",
                        "placeholder": "Name Your Chain",
                        "optional": true,
                        "id": "llmChain_0-input-chainName-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "llmChain_0-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Prompt",
                        "name": "prompt",
                        "type": "BasePromptTemplate",
                        "id": "llmChain_0-input-prompt-BasePromptTemplate"
                    },
                    {
                        "label": "Output Parser",
                        "name": "outputParser",
                        "type": "BaseLLMOutputParser",
                        "optional": true,
                        "id": "llmChain_0-input-outputParser-BaseLLMOutputParser"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "llmChain_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "prompt": "{{promptTemplate_0.data.instance}}",
                    "outputParser": "",
                    "inputModeration": "",
                    "chainName": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                                "name": "llmChain",
                                "label": "LLM Chain",
                                "description": "",
                                "type": "LLMChain | BaseChain | Runnable"
                            },
                            {
                                "id": "llmChain_0-output-outputPrediction-string|json",
                                "name": "outputPrediction",
                                "label": "Output Prediction",
                                "description": "",
                                "type": "string | json"
                            }
                        ],
                        "default": "llmChain"
                    }
                ],
                "outputs": {
                    "output": "llmChain"
                },
                "selected": false
            },
            "width": 300,
            "height": 507,
            "positionAbsolute": {
                "x": 1150.5733832269552,
                "y": 536.2519213587326
            },
            "selected": false
        },
        {
            "id": "promptTemplate_0",
            "position": {
                "x": 717.7027066350117,
                "y": 949.0890443806736
            },
            "type": "customNode",
            "data": {
                "id": "promptTemplate_0",
                "label": "Prompt Template",
                "version": 1,
                "name": "promptTemplate",
                "type": "PromptTemplate",
                "baseClasses": ["PromptTemplate", "BaseStringPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a basic prompt for an LLM",
                "inputParams": [
                    {
                        "label": "Template",
                        "name": "template",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "What is a good name for a company that makes {product}?",
                        "id": "promptTemplate_0-input-template-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "promptTemplate_0-input-promptValues-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "template": "You are tasked with creating an executive summary of a lengthy document. Your goal is to produce a concise, informative summary that highlights the key points and main ideas of the original text. This summary should provide a quick overview for busy executives or decision-makers who need to grasp the essential information without reading the entire document.\n\nHere is the document to be summarized:\n\n{document_file}\n{document_text}\n\nTo create an effective executive summary, follow these steps:\n\n1. Carefully read and analyze the entire document.\n2. Identify the main purpose or objective of the document.\n3. Extract the key points, main ideas, and critical information from each major section.\n4. Focus on the most important findings, conclusions, or recommendations.\n5. Organize the summary in a logical structure, typically following the order of the original document.\n\nYour executive summary should:\n- Be approximately 10% of the length of the original document, but no longer than 1-2 pages.\n- Use clear, concise language without technical jargon or excessive detail.\n- Maintain a professional and objective tone.\n- Include only the most essential information, avoiding minor details or examples.\n- Be understandable to someone who hasn't read the full document.\n\nWrite your executive summary using these guidelines:\n- Start with a brief introduction that states the purpose of the original document.\n- Use short paragraphs, each focusing on a main point or idea.\n- Use bullet points for lists of key findings or recommendations, if appropriate.\n- Conclude with a brief statement summarizing the overall importance or implications of the document.\n\nProvide your executive summary within <executive_summary> tags. Do not include any personal comments or opinions outside of these tags.",
                    "promptValues": "{\"document_file\":\"{{textFile_1.data.instance}}\",\"document_text\":\"{{question}}\"}"
                },
                "outputAnchors": [
                    {
                        "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
                        "name": "promptTemplate",
                        "label": "PromptTemplate",
                        "description": "Schema to represent a basic prompt for an LLM",
                        "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 511,
            "positionAbsolute": {
                "x": 717.7027066350117,
                "y": 949.0890443806736
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "stickyNote_0",
            "position": {
                "x": 253.09264709304995,
                "y": 1108.4217298598132
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_0",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_0-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "A"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_0-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 42,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 253.09264709304995,
                "y": 1108.4217298598132
            }
        },
        {
            "id": "textFile_1",
            "position": {
                "x": 255.56875748447578,
                "y": 671.8421910644768
            },
            "type": "customNode",
            "data": {
                "id": "textFile_1",
                "label": "Text File",
                "version": 3,
                "name": "textFile",
                "type": "Document",
                "baseClasses": ["Document"],
                "category": "Document Loaders",
                "description": "Load data from text files",
                "inputParams": [
                    {
                        "label": "Txt File",
                        "name": "txtFile",
                        "type": "file",
                        "fileType": ".txt, .html, .aspx, .asp, .cpp, .c, .cs, .css, .go, .h, .java, .js, .less, .ts, .php, .proto, .python, .py, .rst, .ruby, .rb, .rs, .scala, .sc, .scss, .sol, .sql, .swift, .markdown, .md, .tex, .ltx, .vb, .xml",
                        "id": "textFile_1-input-txtFile-file"
                    },
                    {
                        "label": "Additional Metadata",
                        "name": "metadata",
                        "type": "json",
                        "description": "Additional metadata to be added to the extracted documents",
                        "optional": true,
                        "additionalParams": true,
                        "id": "textFile_1-input-metadata-json"
                    },
                    {
                        "label": "Omit Metadata Keys",
                        "name": "omitMetadataKeys",
                        "type": "string",
                        "rows": 4,
                        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
                        "placeholder": "key1, key2, key3.nestedKey1",
                        "optional": true,
                        "additionalParams": true,
                        "id": "textFile_1-input-omitMetadataKeys-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Text Splitter",
                        "name": "textSplitter",
                        "type": "TextSplitter",
                        "optional": true,
                        "id": "textFile_1-input-textSplitter-TextSplitter"
                    }
                ],
                "inputs": {
                    "textSplitter": "",
                    "metadata": "",
                    "omitMetadataKeys": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "Array of document objects containing metadata and pageContent",
                        "options": [
                            {
                                "id": "textFile_1-output-document-Document|json",
                                "name": "document",
                                "label": "Document",
                                "description": "Array of document objects containing metadata and pageContent",
                                "type": "Document | json"
                            },
                            {
                                "id": "textFile_1-output-text-string|json",
                                "name": "text",
                                "label": "Text",
                                "description": "Concatenated string from pageContent of documents",
                                "type": "string | json"
                            }
                        ],
                        "default": "document"
                    }
                ],
                "outputs": {
                    "output": "text"
                },
                "selected": false
            },
            "width": 300,
            "height": 438,
            "selected": false,
            "positionAbsolute": {
                "x": 255.56875748447578,
                "y": 671.8421910644768
            },
            "dragging": false
        },
        {
            "id": "stickyNote_1",
            "position": {
                "x": 1511.0976253300662,
                "y": 321.66094924765554
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_1",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_1-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Instructions for Best Results:\n\n1.Upload your document in instance A. It must be a .txt file.  Click the green chat box and type in GO! \n2. Sit back and relax while we work our magic.\n3. Enjoy! You'll receive a comprehensive executive summary of your entire document.\n\n----------------OR---------------\nInstead of uploading the document, Just copy the entire content and copy and paste in the chatbox and it will generate an executive summary."
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_1-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 344,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 1511.0976253300662,
                "y": 321.66094924765554
            }
        }
    ],
    "edges": [
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "llmChain_0",
            "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
        },
        {
            "source": "promptTemplate_0",
            "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "target": "llmChain_0",
            "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
            "type": "buttonedge",
            "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
        },
        {
            "source": "textFile_1",
            "sourceHandle": "textFile_1-output-document-Document|json",
            "target": "promptTemplate_0",
            "targetHandle": "promptTemplate_0-input-promptValues-json",
            "type": "buttonedge",
            "id": "textFile_1-textFile_1-output-document-Document|json-promptTemplate_0-promptTemplate_0-input-promptValues-json"
        }
    ]
}
