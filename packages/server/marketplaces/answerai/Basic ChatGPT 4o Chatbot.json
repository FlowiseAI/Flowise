{
    "edges": [
        {
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel",
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-model-BaseChatModel",
            "type": "buttonedge"
        },
        {
            "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-conversationChain_0-conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate",
            "source": "chatPromptTemplate_0",
            "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate",
            "type": "buttonedge"
        },
        {
            "id": "RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory",
            "source": "RedisBackedChatMemory_0",
            "sourceHandle": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-memory-BaseMemory",
            "type": "buttonedge"
        }
    ],
    "nodes": [
        {
            "data": {
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "id": "chatOpenAI_0",
                "inputAnchors": [
                    {
                        "id": "chatOpenAI_0-input-cache-BaseCache",
                        "label": "Cache",
                        "name": "cache",
                        "optional": true,
                        "type": "BaseCache"
                    }
                ],
                "inputParams": [
                    {
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential",
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential"
                    },
                    {
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions",
                        "label": "Model Name",
                        "loadMethod": "listModels",
                        "name": "modelName",
                        "type": "asyncOptions"
                    },
                    {
                        "default": 0.9,
                        "id": "chatOpenAI_0-input-temperature-number",
                        "label": "Temperature",
                        "name": "temperature",
                        "optional": true,
                        "step": 0.1,
                        "type": "number"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number",
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "optional": true,
                        "step": 1,
                        "type": "number"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number",
                        "label": "Top Probability",
                        "name": "topP",
                        "optional": true,
                        "step": 0.1,
                        "type": "number"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number",
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "optional": true,
                        "step": 0.1,
                        "type": "number"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number",
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "optional": true,
                        "step": 0.1,
                        "type": "number"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number",
                        "label": "Timeout",
                        "name": "timeout",
                        "optional": true,
                        "step": 1,
                        "type": "number"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string",
                        "label": "BasePath",
                        "name": "basepath",
                        "optional": true,
                        "type": "string"
                    },
                    {
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json",
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "optional": true,
                        "type": "json"
                    },
                    {
                        "default": false,
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean",
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "optional": true,
                        "type": "boolean"
                    },
                    {
                        "additionalParams": true,
                        "default": "low",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "id": "chatOpenAI_0-input-imageResolution-options",
                        "label": "Image Resolution",
                        "name": "imageResolution",
                        "optional": false,
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "type": "options"
                    }
                ],
                "inputs": {
                    "allowImageUploads": "",
                    "baseOptions": "",
                    "basepath": "",
                    "cache": "",
                    "frequencyPenalty": "",
                    "imageResolution": "low",
                    "maxTokens": "",
                    "modelName": "gpt-4o",
                    "presencePenalty": "",
                    "temperature": 0.9,
                    "timeout": "",
                    "topP": ""
                },
                "label": "ChatOpenAI",
                "name": "chatOpenAI",
                "outputAnchors": [
                    {
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "label": "ChatOpenAI",
                        "name": "chatOpenAI",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false,
                "type": "ChatOpenAI",
                "version": 6
            },
            "dragging": false,
            "height": 669,
            "id": "chatOpenAI_0",
            "position": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            },
            "positionAbsolute": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            },
            "selected": false,
            "type": "customNode",
            "width": 300
        },
        {
            "data": {
                "baseClasses": ["ConversationChain", "LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chat models specific conversational chain with memory",
                "id": "conversationChain_0",
                "inputAnchors": [
                    {
                        "id": "conversationChain_0-input-model-BaseChatModel",
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel"
                    },
                    {
                        "id": "conversationChain_0-input-memory-BaseMemory",
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseMemory"
                    },
                    {
                        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
                        "id": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate",
                        "label": "Chat Prompt Template",
                        "name": "chatPromptTemplate",
                        "optional": true,
                        "type": "ChatPromptTemplate"
                    },
                    {
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "id": "conversationChain_0-input-inputModeration-Moderation",
                        "label": "Input Moderation",
                        "list": true,
                        "name": "inputModeration",
                        "optional": true,
                        "type": "Moderation"
                    }
                ],
                "inputParams": [
                    {
                        "additionalParams": true,
                        "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
                        "description": "If Chat Prompt Template is provided, this will be ignored",
                        "id": "conversationChain_0-input-systemMessagePrompt-string",
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "optional": true,
                        "placeholder": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
                        "rows": 4,
                        "type": "string"
                    }
                ],
                "inputs": {
                    "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
                    "inputModeration": "",
                    "memory": "{{RedisBackedChatMemory_0.data.instance}}",
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."
                },
                "label": "Conversation Chain",
                "name": "conversationChain",
                "outputAnchors": [
                    {
                        "description": "Chat models specific conversational chain with memory",
                        "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
                        "label": "ConversationChain",
                        "name": "conversationChain",
                        "type": "ConversationChain | LLMChain | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false,
                "type": "ConversationChain",
                "version": 3
            },
            "dragging": false,
            "height": 434,
            "id": "conversationChain_0",
            "position": {
                "x": 1351.5401212609158,
                "y": 324.8249424384527
            },
            "positionAbsolute": {
                "x": 1351.5401212609158,
                "y": 324.8249424384527
            },
            "selected": false,
            "type": "customNode",
            "width": 300
        },
        {
            "data": {
                "baseClasses": ["ChatPromptTemplate", "BaseChatPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a chat prompt",
                "id": "chatPromptTemplate_0",
                "inputAnchors": [],
                "inputParams": [
                    {
                        "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
                        "rows": 4,
                        "type": "string"
                    },
                    {
                        "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
                        "label": "Human Message",
                        "name": "humanMessagePrompt",
                        "placeholder": "{text}",
                        "rows": 4,
                        "type": "string"
                    },
                    {
                        "acceptVariable": true,
                        "id": "chatPromptTemplate_0-input-promptValues-json",
                        "label": "Format Prompt Values",
                        "list": true,
                        "name": "promptValues",
                        "optional": true,
                        "type": "json"
                    }
                ],
                "inputs": {
                    "humanMessagePrompt": "{user_query}",
                    "promptValues": "{\"user_query\":\"{{question}}\"}",
                    "systemMessagePrompt": "You are a basic ChatGPT 4o chatbot designed to respond to various general queries from users. Your goal is to provide helpful, informative, and engaging responses to the best of your ability.\n\nGuidelines for your responses:\n1. Be polite, friendly, and professional in your tone.\n2. Provide accurate and up-to-date information to the best of your knowledge.\n3. If you're unsure about something, admit it and suggest where the user might find more information.\n4. Avoid discussing personal opinions on controversial topics.\n5. Do not provide harmful, illegal, or unethical advice.\n6. Respect user privacy and do not ask for or store personal information.\n7. If a query is unclear, ask for clarification.\n8. Tailor your language to be appropriate for a general audience.\n\nThe user's query is:\n{user_query}\n\nTo generate your response, follow these steps:\n1. Analyze the user's query to understand the main topic and intent.\n2. Draw upon your knowledge base to formulate a relevant and informative response.\n3. Structure your response in a clear and logical manner.\n4. If appropriate, provide examples or additional context to enhance understanding.\n5. If the query requires a step-by-step explanation, break down your response into numbered or bulleted points.\n6. If the query is open-ended or opinion-based, provide a balanced perspective or suggest resources for further exploration.\n\nWrite your response inside <response> tags. Ensure that your response directly addresses the user's query and follows the guidelines provided above."
                },
                "label": "Chat Prompt Template",
                "name": "chatPromptTemplate",
                "outputAnchors": [
                    {
                        "description": "Schema to represent a chat prompt",
                        "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
                        "label": "ChatPromptTemplate",
                        "name": "chatPromptTemplate",
                        "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false,
                "type": "ChatPromptTemplate",
                "version": 1
            },
            "dragging": false,
            "height": 688,
            "id": "chatPromptTemplate_0",
            "position": {
                "x": 775.32917871904,
                "y": 867.0325040326356
            },
            "positionAbsolute": {
                "x": 775.32917871904,
                "y": 867.0325040326356
            },
            "selected": false,
            "type": "customNode",
            "width": 300
        },
        {
            "data": {
                "id": "RedisBackedChatMemory_0",
                "label": "Redis-Backed Chat Memory",
                "version": 2,
                "name": "RedisBackedChatMemory",
                "type": "RedisBackedChatMemory",
                "baseClasses": ["RedisBackedChatMemory", "BaseChatMemory", "BaseMemory"],
                "category": "Memory",
                "description": "Summarizes the conversation and stores the memory in Redis server",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "optional": true,
                        "credentialNames": ["redisCacheApi", "redisCacheUrlApi"],
                        "id": "RedisBackedChatMemory_0-input-credential-credential"
                    },
                    {
                        "label": "Session Id",
                        "name": "sessionId",
                        "type": "string",
                        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
                        "default": "",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-sessionId-string"
                    },
                    {
                        "label": "Session Timeouts",
                        "name": "sessionTTL",
                        "type": "number",
                        "description": "Seconds till a session expires. If not specified, the session will never expire.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-sessionTTL-number"
                    },
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "additionalParams": true,
                        "id": "RedisBackedChatMemory_0-input-memoryKey-string"
                    },
                    {
                        "label": "Window Size",
                        "name": "windowSize",
                        "type": "number",
                        "description": "Window of size k to surface the last k back-and-forth to use as memory.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-windowSize-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "sessionId": "",
                    "sessionTTL": "",
                    "memoryKey": "chat_history",
                    "windowSize": ""
                },
                "outputAnchors": [
                    {
                        "id": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
                        "name": "RedisBackedChatMemory",
                        "label": "RedisBackedChatMemory",
                        "description": "Summarizes the conversation and stores the memory in Redis server",
                        "type": "RedisBackedChatMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {}
            },
            "dragging": false,
            "height": 328,
            "id": "RedisBackedChatMemory_0",
            "position": {
                "x": 1328.8348392220717,
                "y": 1010.5244600115544
            },
            "positionAbsolute": {
                "x": 1328.8348392220717,
                "y": 1010.5244600115544
            },
            "selected": false,
            "type": "customNode",
            "width": 300
        },
        {
            "data": {
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "id": "stickyNote_0",
                "inputAnchors": [],
                "inputParams": [
                    {
                        "id": "stickyNote_0-input-note-string",
                        "label": "",
                        "name": "note",
                        "optional": true,
                        "placeholder": "Type something here",
                        "rows": 1,
                        "type": "string"
                    }
                ],
                "inputs": {
                    "note": "Instructions for Best Results:\n\nClick the green chat box and type in any query that you need information for.\nSit back and relax while we work our magic.\nEnjoy!"
                },
                "label": "Sticky Note",
                "name": "stickyNote",
                "outputAnchors": [
                    {
                        "description": "Add a sticky note",
                        "id": "stickyNote_0-output-stickyNote-StickyNote",
                        "label": "StickyNote",
                        "name": "stickyNote",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false,
                "type": "StickyNote",
                "version": 1
            },
            "dragging": false,
            "height": 163,
            "id": "stickyNote_0",
            "position": {
                "x": 2038.9710385658245,
                "y": 377.5135853532508
            },
            "positionAbsolute": {
                "x": 2038.9710385658245,
                "y": 377.5135853532508
            },
            "selected": false,
            "type": "stickyNote",
            "width": 300
        }
    ]
}
