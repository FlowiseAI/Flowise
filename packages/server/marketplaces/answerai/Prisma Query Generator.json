{
    "nodes": [
        {
            "id": "chatOpenAI_0",
            "position": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": "",
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            }
        },
        {
            "id": "llmChain_0",
            "position": {
                "x": 1150.5733832269552,
                "y": 536.2519213587326
            },
            "type": "customNode",
            "data": {
                "id": "llmChain_0",
                "label": "LLM Chain",
                "version": 3,
                "name": "llmChain",
                "type": "LLMChain",
                "baseClasses": ["LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chain to run queries against LLMs",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "chainName",
                        "type": "string",
                        "placeholder": "Name Your Chain",
                        "optional": true,
                        "id": "llmChain_0-input-chainName-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "llmChain_0-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Prompt",
                        "name": "prompt",
                        "type": "BasePromptTemplate",
                        "id": "llmChain_0-input-prompt-BasePromptTemplate"
                    },
                    {
                        "label": "Output Parser",
                        "name": "outputParser",
                        "type": "BaseLLMOutputParser",
                        "optional": true,
                        "id": "llmChain_0-input-outputParser-BaseLLMOutputParser"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "llmChain_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "prompt": "{{promptTemplate_0.data.instance}}",
                    "outputParser": "",
                    "inputModeration": "",
                    "chainName": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                                "name": "llmChain",
                                "label": "LLM Chain",
                                "description": "",
                                "type": "LLMChain | BaseChain | Runnable"
                            },
                            {
                                "id": "llmChain_0-output-outputPrediction-string|json",
                                "name": "outputPrediction",
                                "label": "Output Prediction",
                                "description": "",
                                "type": "string | json"
                            }
                        ],
                        "default": "llmChain"
                    }
                ],
                "outputs": {
                    "output": "llmChain"
                },
                "selected": false
            },
            "width": 300,
            "height": 507,
            "positionAbsolute": {
                "x": 1150.5733832269552,
                "y": 536.2519213587326
            },
            "selected": false
        },
        {
            "id": "promptTemplate_0",
            "position": {
                "x": 717.7027066350117,
                "y": 1019.0890443806736
            },
            "type": "customNode",
            "data": {
                "id": "promptTemplate_0",
                "label": "Prompt Template",
                "version": 1,
                "name": "promptTemplate",
                "type": "PromptTemplate",
                "baseClasses": ["PromptTemplate", "BaseStringPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a basic prompt for an LLM",
                "inputParams": [
                    {
                        "label": "Template",
                        "name": "template",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "What is a good name for a company that makes {product}?",
                        "id": "promptTemplate_0-input-template-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "promptTemplate_0-input-promptValues-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "template": "You are a Prisma Query Generator AI. Your task is to generate Prisma database queries based on user requirements. You will be provided with a Prisma schema and user requirements for a database operation. Your goal is to analyze these inputs and generate an appropriate Prisma query.\n\nFirst, review the Prisma schema:\n\n{prisma_schema}\n\nNow, consider the user's requirements for the database operation:\n\n{user_requirements}\n\nAnalyze the user requirements carefully. Identify the following:\n1. The type of operation (create, read, update, delete)\n2. The model(s) involved\n3. Any specific fields mentioned\n4. Any relationships that need to be considered\n5. Any filtering, sorting, or pagination requirements\n\nBased on your analysis, generate a Prisma query that fulfills the user's requirements. Ensure that your query:\n1. Uses the correct Prisma client method (e.g., findMany, create, update, delete)\n2. Includes all necessary fields and relationships\n3. Applies any required filters, sorting, or pagination\n4. Follows Prisma query syntax and best practices\n\nPresent your generated Prisma query within <prisma_query> tags. After the query, provide a brief explanation of your reasoning within <explanation> tags.\n<example>\nHere's an example of how your output should be structured:\n\nThis query retrieves users who are 18 years or older and have at least one published post. It includes their published posts in the results, selecting only the title and content of each post. The results are ordered by the creation date of the users in descending order and limited to 10 users. This query structure fulfills the requirements for filtering by age, including related posts, and applying pagination.\n\nIf the user requirements are unclear or cannot be fulfilled with the given Prisma schema, explain the issue and ask for clarification within <clarification_needed> tags.\n\nRemember to consider potential edge cases and error handling in your query generation. If necessary, include comments in your Prisma query to explain any complex logic or decisions.\n\nNow, generate the Prisma query based on the provided schema and user requirements.",
                    "promptValues": "{\"prisma_schema\":\"{{plainText_0.data.instance}}\",\"user_requirements\":\"{{plainText_1.data.instance}}\"}"
                },
                "outputAnchors": [
                    {
                        "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
                        "name": "promptTemplate",
                        "label": "PromptTemplate",
                        "description": "Schema to represent a basic prompt for an LLM",
                        "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 511,
            "positionAbsolute": {
                "x": 717.7027066350117,
                "y": 1019.0890443806736
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "stickyNote_0",
            "position": {
                "x": 1465.584173736184,
                "y": 156.66403891057325
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_0",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_0-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Instructions for Best Results:\n\n1. Start with adding prisma schema in Instance A. \n2. Then mention user requirements in instance B. \n3. Hit save and Click the green chat box and type in GO!\n2. Sit back and relax while we work our magic.\n3. Enjoy your prisma query in no time!"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_0-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 243,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 1465.584173736184,
                "y": 156.66403891057325
            }
        },
        {
            "id": "plainText_0",
            "position": {
                "x": 258.4627297067908,
                "y": 641.942183125382
            },
            "type": "customNode",
            "data": {
                "id": "plainText_0",
                "label": "Plain Text",
                "version": 2,
                "name": "plainText",
                "type": "Document",
                "baseClasses": ["Document"],
                "category": "Document Loaders",
                "description": "Load data from plain text",
                "inputParams": [
                    {
                        "label": "Text",
                        "name": "text",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...",
                        "id": "plainText_0-input-text-string"
                    },
                    {
                        "label": "Additional Metadata",
                        "name": "metadata",
                        "type": "json",
                        "description": "Additional metadata to be added to the extracted documents",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_0-input-metadata-json"
                    },
                    {
                        "label": "Omit Metadata Keys",
                        "name": "omitMetadataKeys",
                        "type": "string",
                        "rows": 4,
                        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
                        "placeholder": "key1, key2, key3.nestedKey1",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_0-input-omitMetadataKeys-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Text Splitter",
                        "name": "textSplitter",
                        "type": "TextSplitter",
                        "optional": true,
                        "id": "plainText_0-input-textSplitter-TextSplitter"
                    }
                ],
                "inputs": {
                    "text": "<prisma_schema>\n//add your schema here\n</prisma_schema>",
                    "textSplitter": "",
                    "metadata": "",
                    "omitMetadataKeys": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "Array of document objects containing metadata and pageContent",
                        "options": [
                            {
                                "id": "plainText_0-output-document-Document|json",
                                "name": "document",
                                "label": "Document",
                                "description": "Array of document objects containing metadata and pageContent",
                                "type": "Document | json"
                            },
                            {
                                "id": "plainText_0-output-text-string|json",
                                "name": "text",
                                "label": "Text",
                                "description": "Concatenated string from pageContent of documents",
                                "type": "string | json"
                            }
                        ],
                        "default": "document"
                    }
                ],
                "outputs": {
                    "output": "text"
                },
                "selected": false
            },
            "width": 300,
            "height": 485,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 258.4627297067908,
                "y": 641.942183125382
            }
        },
        {
            "id": "plainText_1",
            "position": {
                "x": 171.81035337569762,
                "y": 1257.9131168031304
            },
            "type": "customNode",
            "data": {
                "id": "plainText_1",
                "label": "Plain Text",
                "version": 2,
                "name": "plainText",
                "type": "Document",
                "baseClasses": ["Document"],
                "category": "Document Loaders",
                "description": "Load data from plain text",
                "inputParams": [
                    {
                        "label": "Text",
                        "name": "text",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...",
                        "id": "plainText_1-input-text-string"
                    },
                    {
                        "label": "Additional Metadata",
                        "name": "metadata",
                        "type": "json",
                        "description": "Additional metadata to be added to the extracted documents",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_1-input-metadata-json"
                    },
                    {
                        "label": "Omit Metadata Keys",
                        "name": "omitMetadataKeys",
                        "type": "string",
                        "rows": 4,
                        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
                        "placeholder": "key1, key2, key3.nestedKey1",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_1-input-omitMetadataKeys-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Text Splitter",
                        "name": "textSplitter",
                        "type": "TextSplitter",
                        "optional": true,
                        "id": "plainText_1-input-textSplitter-TextSplitter"
                    }
                ],
                "inputs": {
                    "text": "<user_requirements>\n//add user requirements here\n</user_requirements>",
                    "textSplitter": "",
                    "metadata": "",
                    "omitMetadataKeys": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "Array of document objects containing metadata and pageContent",
                        "options": [
                            {
                                "id": "plainText_1-output-document-Document|json",
                                "name": "document",
                                "label": "Document",
                                "description": "Array of document objects containing metadata and pageContent",
                                "type": "Document | json"
                            },
                            {
                                "id": "plainText_1-output-text-string|json",
                                "name": "text",
                                "label": "Text",
                                "description": "Concatenated string from pageContent of documents",
                                "type": "string | json"
                            }
                        ],
                        "default": "document"
                    }
                ],
                "outputs": {
                    "output": "text"
                },
                "selected": false
            },
            "width": 300,
            "height": 485,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 171.81035337569762,
                "y": 1257.9131168031304
            }
        },
        {
            "id": "stickyNote_1",
            "position": {
                "x": 257.0057711375271,
                "y": 1126.8935959152918
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_1",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_1-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "A"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_1-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 42,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 257.0057711375271,
                "y": 1126.8935959152918
            }
        },
        {
            "id": "stickyNote_2",
            "position": {
                "x": 165.93021125952694,
                "y": 1740.7194060286135
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_2",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_2-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "B"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_2-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 42,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 165.93021125952694,
                "y": 1740.7194060286135
            }
        },
        {
            "id": "stickyNote_4",
            "position": {
                "x": -133.7564543190436,
                "y": 1376.2603869627317
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_4",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_4-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Add your user requriements here like:\n\"I need to fetch all users who are over 18 years old and have at least one published post. Include their profile information and the titles of their published posts. Order the results by the user's name in ascending order and limit the output to 5 users.\""
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_4-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 163,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": -133.7564543190436,
                "y": 1376.2603869627317
            }
        }
    ],
    "edges": [
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "llmChain_0",
            "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
        },
        {
            "source": "promptTemplate_0",
            "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "target": "llmChain_0",
            "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
            "type": "buttonedge",
            "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
        },
        {
            "source": "plainText_0",
            "sourceHandle": "plainText_0-output-text-string|json",
            "target": "promptTemplate_0",
            "targetHandle": "promptTemplate_0-input-promptValues-json",
            "type": "buttonedge",
            "id": "plainText_0-plainText_0-output-text-string|json-promptTemplate_0-promptTemplate_0-input-promptValues-json"
        },
        {
            "source": "plainText_1",
            "sourceHandle": "plainText_1-output-text-string|json",
            "target": "promptTemplate_0",
            "targetHandle": "promptTemplate_0-input-promptValues-json",
            "type": "buttonedge",
            "id": "plainText_1-plainText_1-output-text-string|json-promptTemplate_0-promptTemplate_0-input-promptValues-json"
        }
    ]
}
