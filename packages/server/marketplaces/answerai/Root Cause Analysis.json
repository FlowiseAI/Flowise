{
    "nodes": [
        {
            "id": "chatOpenAI_0",
            "position": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": "",
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 707.5800903626107,
                "y": 109.12476306943097
            }
        },
        {
            "id": "stickyNote_4",
            "position": {
                "x": 2074.3360956723227,
                "y": 196.92558505164095
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_4",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_4-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Instructions for Best Results:\n\n1. Click the green chat box and type in\nthe problem your company is facing. For example: \n\n\"Our mid-sized e-commerce company has seen a rise in customer complaints over the past three months due to delayed deliveries, incorrect shipments, and poor customer service. On-time delivery rates dropped from 95% to 78%, and customer satisfaction from 4.5 to 3.2 out of 5. Returns increased by 20%, and repeat customers decreased by 15%. Our warehouse and customer service teams are overwhelmed. Despite a new inventory management system implemented six months ago, issues persist. We need to identify root causes and develop solutions to improve operations and customer satisfaction\".\n\n2. Sit back and enjoy an let the AI find the root cause and give you exact solutions."
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_4-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 525,
            "selected": false,
            "positionAbsolute": {
                "x": 2074.3360956723227,
                "y": 196.92558505164095
            },
            "dragging": false
        },
        {
            "id": "conversationalRetrievalQAChain_0",
            "position": {
                "x": 1591.8813462176108,
                "y": 431.84496906213064
            },
            "type": "customNode",
            "data": {
                "id": "conversationalRetrievalQAChain_0",
                "label": "Conversational Retrieval QA Chain",
                "version": 3,
                "name": "conversationalRetrievalQAChain",
                "type": "ConversationalRetrievalQAChain",
                "baseClasses": ["ConversationalRetrievalQAChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
                "inputParams": [
                    {
                        "label": "Return Source Documents",
                        "name": "returnSourceDocuments",
                        "type": "boolean",
                        "optional": true,
                        "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
                    },
                    {
                        "label": "Rephrase Prompt",
                        "name": "rephrasePrompt",
                        "type": "string",
                        "description": "Using previous chat history, rephrase question into a standalone question",
                        "warning": "Prompt must include input variables: {chat_history} and {question}",
                        "rows": 4,
                        "additionalParams": true,
                        "optional": true,
                        "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
                        "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
                    },
                    {
                        "label": "Response Prompt",
                        "name": "responsePrompt",
                        "type": "string",
                        "description": "Taking the rephrased question, search for answer from the provided context",
                        "warning": "Prompt must include input variable: {context}",
                        "rows": 4,
                        "additionalParams": true,
                        "optional": true,
                        "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
                        "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Vector Store Retriever",
                        "name": "vectorStoreRetriever",
                        "type": "BaseRetriever",
                        "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseMemory",
                        "optional": true,
                        "description": "If left empty, a default BufferMemory will be used",
                        "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
                    "memory": "",
                    "returnSourceDocuments": "",
                    "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
                    "responsePrompt": "You are an AI assistant tasked with conducting a root cause analysis for a given problem and suggesting potential solutions. Your goal is to analyze the problem thoroughly, identify its underlying causes, and propose effective solutions.\n\nHere is the problem description:\n{question}\nFollow these steps to conduct your root cause analysis:\n\n1. Problem Understanding:\n   - Carefully read and analyze the problem description.\n   - Identify the main issues and symptoms described.\n\n2. Data Gathering:\n   - List any relevant information provided in the problem description.\n   - Note any missing information that would be helpful for a more comprehensive analysis.\n\n3. Cause Identification:\n   - Use techniques such as the \"5 Whys\" or fishbone diagram to identify potential root causes.\n   - Consider various factors: people, processes, equipment, environment, materials, and management.\n\n4. Root Cause Determination:\n   - Evaluate the identified causes and determine which are the most likely root causes.\n   - Explain your reasoning for selecting these as the root causes.\n\n5. Solution Generation:\n   - Propose potential solutions that address the identified root causes.\n   - Consider both short-term fixes and long-term preventive measures.\n\n6. Solution Evaluation:\n   - Briefly assess the pros and cons of each proposed solution.\n   - Recommend the most effective solution(s) based on your analysis.\n\nPresent your analysis and solutions in the following format:\n\n<root_cause_analysis>\n<problem_summary>\nSummarize the main problem and its symptoms in 2-3 sentences.\n</problem_summary>\n\n<root_causes>\nList the identified root causes, with a brief explanation for each.\n</root_causes>\n\n<proposed_solutions>\nList your proposed solutions, including:\n- A brief description of each solution\n- How it addresses the root cause(s)\n- Potential benefits and drawbacks\n</proposed_solutions>\n\n<recommendations>\nProvide your final recommendations, explaining why you believe these are the most effective solutions.\n</recommendations>\n</root_cause_analysis>\n\nRemember to be clear, concise, and thorough in your analysis. Use logical reasoning and explain your thought process throughout. If you need any clarification or additional information about the problem, state this in your analysis.",
                    "inputModeration": ""
                },
                "outputAnchors": [
                    {
                        "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
                        "name": "conversationalRetrievalQAChain",
                        "label": "ConversationalRetrievalQAChain",
                        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
                        "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 530,
            "selected": false,
            "positionAbsolute": {
                "x": 1591.8813462176108,
                "y": 431.84496906213064
            },
            "dragging": false
        },
        {
            "id": "memoryVectorStore_0",
            "position": {
                "x": 1104.4488886870895,
                "y": 1008.8450904569852
            },
            "type": "customNode",
            "data": {
                "id": "memoryVectorStore_0",
                "label": "In-Memory Vector Store",
                "version": 1,
                "name": "memoryVectorStore",
                "type": "Memory",
                "baseClasses": ["Memory", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
                "inputParams": [
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "optional": true,
                        "id": "memoryVectorStore_0-input-topK-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "memoryVectorStore_0-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "memoryVectorStore_0-input-embeddings-Embeddings"
                    }
                ],
                "inputs": {
                    "document": "",
                    "embeddings": "{{openAIEmbeddings_0.data.instance}}",
                    "topK": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Memory Retriever",
                                "description": "",
                                "type": "Memory | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                                "name": "vectorStore",
                                "label": "Memory Vector Store",
                                "description": "",
                                "type": "Memory | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "width": 300,
            "height": 405,
            "selected": false,
            "positionAbsolute": {
                "x": 1104.4488886870895,
                "y": 1008.8450904569852
            },
            "dragging": false
        },
        {
            "id": "openAIEmbeddings_0",
            "position": {
                "x": 572.7844631040856,
                "y": 1081.1241515792376
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_0",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 423,
            "selected": false,
            "positionAbsolute": {
                "x": 572.7844631040856,
                "y": 1081.1241515792376
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "conversationalRetrievalQAChain_0",
            "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
        },
        {
            "source": "memoryVectorStore_0",
            "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
            "target": "conversationalRetrievalQAChain_0",
            "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "type": "buttonedge",
            "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
        },
        {
            "source": "openAIEmbeddings_0",
            "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "memoryVectorStore_0",
            "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
        }
    ]
}
