{
    "description": "Use Anthropic Claude with 200k context window to ingest whole document for QnA",
    "categories": "Buffer Memory,Prompt Template,Conversation Chain,ChatAnthropic,Langchain",
    "framework": "Langchain",
    "nodes": [
        {
            "width": 300,
            "height": 376,
            "id": "bufferMemory_0",
            "position": {
                "x": 240.5161028076149,
                "y": 165.35849026339048
            },
            "type": "customNode",
            "data": {
                "id": "bufferMemory_0",
                "label": "Buffer Memory",
                "version": 1,
                "name": "bufferMemory",
                "type": "BufferMemory",
                "baseClasses": ["BufferMemory", "BaseChatMemory", "BaseMemory"],
                "category": "Memory",
                "description": "Remembers previous conversational back and forths directly",
                "inputParams": [
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "id": "bufferMemory_0-input-memoryKey-string"
                    },
                    {
                        "label": "Input Key",
                        "name": "inputKey",
                        "type": "string",
                        "default": "input",
                        "id": "bufferMemory_0-input-inputKey-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "memoryKey": "chat_history",
                    "inputKey": "input"
                },
                "outputAnchors": [
                    {
                        "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
                        "name": "bufferMemory",
                        "label": "BufferMemory",
                        "type": "BufferMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 240.5161028076149,
                "y": 165.35849026339048
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 383,
            "id": "conversationChain_0",
            "position": {
                "x": 958.9887390513221,
                "y": 318.8734467468765
            },
            "type": "customNode",
            "data": {
                "id": "conversationChain_0",
                "label": "Conversation Chain",
                "version": 3,
                "name": "conversationChain",
                "type": "ConversationChain",
                "baseClasses": ["ConversationChain", "LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chat models specific conversational chain with memory",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "description": "If Chat Prompt Template is provided, this will be ignored",
                        "additionalParams": true,
                        "optional": true,
                        "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
                        "placeholder": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
                        "id": "conversationChain_0-input-systemMessagePrompt-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "id": "conversationChain_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseMemory",
                        "id": "conversationChain_0-input-memory-BaseMemory"
                    },
                    {
                        "label": "Chat Prompt Template",
                        "name": "chatPromptTemplate",
                        "type": "ChatPromptTemplate",
                        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
                        "optional": true,
                        "id": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "conversationChain_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "inputModeration": "",
                    "model": "{{chatAnthropic_0.data.instance}}",
                    "memory": "{{bufferMemory_0.data.instance}}",
                    "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
                    "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."
                },
                "outputAnchors": [
                    {
                        "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
                        "name": "conversationChain",
                        "label": "ConversationChain",
                        "type": "ConversationChain | LLMChain | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 958.9887390513221,
                "y": 318.8734467468765
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 574,
            "id": "chatAnthropic_0",
            "position": {
                "x": 585.3308245972187,
                "y": -116.32789506560908
            },
            "type": "customNode",
            "data": {
                "id": "chatAnthropic_0",
                "label": "ChatAnthropic",
                "version": 3,
                "name": "chatAnthropic",
                "type": "ChatAnthropic",
                "baseClasses": ["ChatAnthropic", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around ChatAnthropic large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["anthropicApi"],
                        "id": "chatAnthropic_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "options",
                        "options": [
                            {
                                "label": "claude-2",
                                "name": "claude-2",
                                "description": "Claude 2 latest major version, automatically get updates to the model as they are released"
                            },
                            {
                                "label": "claude-2.1",
                                "name": "claude-2.1",
                                "description": "Claude 2 latest full version"
                            },
                            {
                                "label": "claude-instant-1",
                                "name": "claude-instant-1",
                                "description": "Claude Instant latest major version, automatically get updates to the model as they are released"
                            },
                            {
                                "label": "claude-v1",
                                "name": "claude-v1"
                            },
                            {
                                "label": "claude-v1-100k",
                                "name": "claude-v1-100k"
                            },
                            {
                                "label": "claude-v1.0",
                                "name": "claude-v1.0"
                            },
                            {
                                "label": "claude-v1.2",
                                "name": "claude-v1.2"
                            },
                            {
                                "label": "claude-v1.3",
                                "name": "claude-v1.3"
                            },
                            {
                                "label": "claude-v1.3-100k",
                                "name": "claude-v1.3-100k"
                            },
                            {
                                "label": "claude-instant-v1",
                                "name": "claude-instant-v1"
                            },
                            {
                                "label": "claude-instant-v1-100k",
                                "name": "claude-instant-v1-100k"
                            },
                            {
                                "label": "claude-instant-v1.0",
                                "name": "claude-instant-v1.0"
                            },
                            {
                                "label": "claude-instant-v1.1",
                                "name": "claude-instant-v1.1"
                            },
                            {
                                "label": "claude-instant-v1.1-100k",
                                "name": "claude-instant-v1.1-100k"
                            }
                        ],
                        "default": "claude-2",
                        "optional": true,
                        "id": "chatAnthropic_0-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatAnthropic_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokensToSample",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatAnthropic_0-input-maxTokensToSample-number"
                    },
                    {
                        "label": "Top P",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatAnthropic_0-input-topP-number"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatAnthropic_0-input-topK-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatAnthropic_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "claude-2.1",
                    "temperature": 0.9,
                    "maxTokensToSample": "",
                    "topP": "",
                    "topK": ""
                },
                "outputAnchors": [
                    {
                        "id": "chatAnthropic_0-output-chatAnthropic-ChatAnthropic|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatAnthropic",
                        "label": "ChatAnthropic",
                        "type": "ChatAnthropic | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 585.3308245972187,
                "y": -116.32789506560908
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 688,
            "id": "chatPromptTemplate_0",
            "position": {
                "x": -106.44189698270114,
                "y": 20.133956087516538
            },
            "type": "customNode",
            "data": {
                "id": "chatPromptTemplate_0",
                "label": "Chat Prompt Template",
                "version": 1,
                "name": "chatPromptTemplate",
                "type": "ChatPromptTemplate",
                "baseClasses": ["ChatPromptTemplate", "BaseChatPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a chat prompt",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
                        "id": "chatPromptTemplate_0-input-systemMessagePrompt-string"
                    },
                    {
                        "label": "Human Message",
                        "name": "humanMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "{text}",
                        "id": "chatPromptTemplate_0-input-humanMessagePrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "chatPromptTemplate_0-input-promptValues-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\nThe AI has the following context:\n{context}",
                    "humanMessagePrompt": "{input}",
                    "promptValues": "{\"context\":\"{{plainText_0.data.instance}}\",\"input\":\"{{question}}\"}"
                },
                "outputAnchors": [
                    {
                        "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
                        "name": "chatPromptTemplate",
                        "label": "ChatPromptTemplate",
                        "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": -106.44189698270114,
                "y": 20.133956087516538
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 485,
            "id": "plainText_0",
            "position": {
                "x": -487.7511991135089,
                "y": 77.83838996645807
            },
            "type": "customNode",
            "data": {
                "id": "plainText_0",
                "label": "Plain Text",
                "version": 2,
                "name": "plainText",
                "type": "Document",
                "baseClasses": ["Document"],
                "category": "Document Loaders",
                "description": "Load data from plain text",
                "inputParams": [
                    {
                        "label": "Text",
                        "name": "text",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...",
                        "id": "plainText_0-input-text-string"
                    },
                    {
                        "label": "Metadata",
                        "name": "metadata",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_0-input-metadata-json"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Text Splitter",
                        "name": "textSplitter",
                        "type": "TextSplitter",
                        "optional": true,
                        "id": "plainText_0-input-textSplitter-TextSplitter"
                    }
                ],
                "inputs": {
                    "text": "Welcome to Skyworld Hotel, where your dreams take flight and your stay soars to new heights. Nestled amidst breathtaking cityscape views, our upscale establishment offers an unparalleled blend of luxury and comfort. Our rooms are elegantly appointed, featuring modern amenities and plush furnishings to ensure your relaxation.\n\nIndulge in culinary delights at our rooftop restaurant, offering a gastronomic journey with panoramic vistas. Skyworld Hotel boasts state-of-the-art conference facilities, perfect for business travelers, and an inviting spa for relaxation seekers. Our attentive staff is dedicated to ensuring your every need is met, making your stay memorable.\n\nCentrally located, we offer easy access to local attractions, making us an ideal choice for both leisure and business travelers. Experience the world of hospitality like never before at Skyworld Hotel.",
                    "textSplitter": "",
                    "metadata": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "plainText_0-output-document-Document|json",
                                "name": "document",
                                "label": "Document",
                                "type": "Document | json"
                            },
                            {
                                "id": "plainText_0-output-text-string|json",
                                "name": "text",
                                "label": "Text",
                                "type": "string | json"
                            }
                        ],
                        "default": "document"
                    }
                ],
                "outputs": {
                    "output": "text"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": -487.7511991135089,
                "y": 77.83838996645807
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "bufferMemory_0",
            "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-memory-BaseMemory",
            "type": "buttonedge",
            "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory"
        },
        {
            "source": "chatAnthropic_0",
            "sourceHandle": "chatAnthropic_0-output-chatAnthropic-ChatAnthropic|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatAnthropic_0-chatAnthropic_0-output-chatAnthropic-ChatAnthropic|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel"
        },
        {
            "source": "plainText_0",
            "sourceHandle": "plainText_0-output-text-string|json",
            "target": "chatPromptTemplate_0",
            "targetHandle": "chatPromptTemplate_0-input-promptValues-json",
            "type": "buttonedge",
            "id": "plainText_0-plainText_0-output-text-string|json-chatPromptTemplate_0-chatPromptTemplate_0-input-promptValues-json"
        },
        {
            "source": "chatPromptTemplate_0",
            "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate",
            "type": "buttonedge",
            "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-conversationChain_0-conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate"
        }
    ]
}
