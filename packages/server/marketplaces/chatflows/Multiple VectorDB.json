{
    "description": "Conversational agent to choose between multiple Chain Tools, each connected to different vector databases",
    "usecases": ["Documents QnA"],
    "framework": ["Langchain"],
    "nodes": [
        {
            "width": 300,
            "height": 603,
            "id": "chainTool_2",
            "position": {
                "x": 1274.762717089282,
                "y": -955.2604402500798
            },
            "type": "customNode",
            "data": {
                "id": "chainTool_2",
                "label": "Chain Tool",
                "version": 1,
                "name": "chainTool",
                "type": "ChainTool",
                "baseClasses": ["ChainTool", "DynamicTool", "Tool", "StructuredTool", "BaseLangChain"],
                "category": "Tools",
                "description": "Use a chain as allowed tool for agent",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "name",
                        "type": "string",
                        "placeholder": "state-of-union-qa",
                        "id": "chainTool_2-input-name-string"
                    },
                    {
                        "label": "Chain Description",
                        "name": "description",
                        "type": "string",
                        "rows": 3,
                        "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
                        "id": "chainTool_2-input-description-string"
                    },
                    {
                        "label": "Return Direct",
                        "name": "returnDirect",
                        "type": "boolean",
                        "optional": true,
                        "id": "chainTool_2-input-returnDirect-boolean"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Base Chain",
                        "name": "baseChain",
                        "type": "BaseChain",
                        "id": "chainTool_2-input-baseChain-BaseChain"
                    }
                ],
                "inputs": {
                    "name": "ai-paper-qa",
                    "description": "AI Paper QA - useful for when you need to ask questions about the AI-Generated Content paper.",
                    "returnDirect": true,
                    "baseChain": "{{retrievalQAChain_0.data.instance}}"
                },
                "outputAnchors": [
                    {
                        "id": "chainTool_2-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|BaseLangChain",
                        "name": "chainTool",
                        "label": "ChainTool",
                        "type": "ChainTool | DynamicTool | Tool | StructuredTool | BaseLangChain"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 1274.762717089282,
                "y": -955.2604402500798
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 603,
            "id": "chainTool_3",
            "position": {
                "x": 1278.5582632273515,
                "y": -214.68611013834368
            },
            "type": "customNode",
            "data": {
                "id": "chainTool_3",
                "label": "Chain Tool",
                "version": 1,
                "name": "chainTool",
                "type": "ChainTool",
                "baseClasses": ["ChainTool", "DynamicTool", "Tool", "StructuredTool", "BaseLangChain"],
                "category": "Tools",
                "description": "Use a chain as allowed tool for agent",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "name",
                        "type": "string",
                        "placeholder": "state-of-union-qa",
                        "id": "chainTool_3-input-name-string"
                    },
                    {
                        "label": "Chain Description",
                        "name": "description",
                        "type": "string",
                        "rows": 3,
                        "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
                        "id": "chainTool_3-input-description-string"
                    },
                    {
                        "label": "Return Direct",
                        "name": "returnDirect",
                        "type": "boolean",
                        "optional": true,
                        "id": "chainTool_3-input-returnDirect-boolean"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Base Chain",
                        "name": "baseChain",
                        "type": "BaseChain",
                        "id": "chainTool_3-input-baseChain-BaseChain"
                    }
                ],
                "inputs": {
                    "name": "state-of-union-qa",
                    "description": "State of the Union QA - useful for when you need to ask questions about the president speech and most recent state of the union address.",
                    "returnDirect": true,
                    "baseChain": "{{retrievalQAChain_1.data.instance}}"
                },
                "outputAnchors": [
                    {
                        "id": "chainTool_3-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|BaseLangChain",
                        "name": "chainTool",
                        "label": "ChainTool",
                        "type": "ChainTool | DynamicTool | Tool | StructuredTool | BaseLangChain"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 1278.5582632273515,
                "y": -214.68611013834368
            }
        },
        {
            "width": 300,
            "height": 332,
            "id": "retrievalQAChain_0",
            "position": {
                "x": 898.1253096948574,
                "y": -859.1174013418433
            },
            "type": "customNode",
            "data": {
                "id": "retrievalQAChain_0",
                "label": "Retrieval QA Chain",
                "version": 2,
                "name": "retrievalQAChain",
                "type": "RetrievalQAChain",
                "baseClasses": ["RetrievalQAChain", "BaseChain", "BaseLangChain"],
                "category": "Chains",
                "description": "QA chain to answer a question based on the retrieved documents",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "retrievalQAChain_0-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Vector Store Retriever",
                        "name": "vectorStoreRetriever",
                        "type": "BaseRetriever",
                        "id": "retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "retrievalQAChain_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "inputModeration": "",
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "vectorStoreRetriever": "{{redis_0.data.instance}}"
                },
                "outputAnchors": [
                    {
                        "id": "retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|BaseLangChain",
                        "name": "retrievalQAChain",
                        "label": "RetrievalQAChain",
                        "type": "RetrievalQAChain | BaseChain | BaseLangChain"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 898.1253096948574,
                "y": -859.1174013418433
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 332,
            "id": "retrievalQAChain_1",
            "position": {
                "x": 920.057949591115,
                "y": 268.2828817441888
            },
            "type": "customNode",
            "data": {
                "id": "retrievalQAChain_1",
                "label": "Retrieval QA Chain",
                "version": 2,
                "name": "retrievalQAChain",
                "type": "RetrievalQAChain",
                "baseClasses": ["RetrievalQAChain", "BaseChain", "BaseLangChain"],
                "category": "Chains",
                "description": "QA chain to answer a question based on the retrieved documents",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "retrievalQAChain_1-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Vector Store Retriever",
                        "name": "vectorStoreRetriever",
                        "type": "BaseRetriever",
                        "id": "retrievalQAChain_1-input-vectorStoreRetriever-BaseRetriever"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "retrievalQAChain_1-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "inputModeration": "",
                    "model": "{{chatOpenAI_1.data.instance}}",
                    "vectorStoreRetriever": "{{faiss_0.data.instance}}"
                },
                "outputAnchors": [
                    {
                        "id": "retrievalQAChain_1-output-retrievalQAChain-RetrievalQAChain|BaseChain|BaseLangChain",
                        "name": "retrievalQAChain",
                        "label": "RetrievalQAChain",
                        "type": "RetrievalQAChain | BaseChain | BaseLangChain"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 920.057949591115,
                "y": 268.2828817441888
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 424,
            "id": "openAIEmbeddings_1",
            "position": {
                "x": 100.06006551346672,
                "y": -686.9997729064416
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_1",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_1-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_1-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_1-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_1-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 100.06006551346672,
                "y": -686.9997729064416
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 424,
            "id": "openAIEmbeddings_2",
            "position": {
                "x": 126.74109446437771,
                "y": 542.6301053870723
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_2",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_2-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_2-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_2-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_2-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_2-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_2-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_2-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_2-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 126.74109446437771,
                "y": 542.6301053870723
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 670,
            "id": "chatOpenAI_0",
            "position": {
                "x": 519.798956186608,
                "y": -1601.3893918503904
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-3.5-turbo-16k",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": true,
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 519.798956186608,
                "y": -1601.3893918503904
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 652,
            "id": "redis_0",
            "position": {
                "x": 517.9599892124863,
                "y": -892.797784079465
            },
            "type": "customNode",
            "data": {
                "id": "redis_0",
                "label": "Redis",
                "version": 1,
                "name": "redis",
                "type": "Redis",
                "baseClasses": ["Redis", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity search upon query using Redis, an open source, in-memory data structure store",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["redisCacheUrlApi", "redisCacheApi"],
                        "id": "redis_0-input-credential-credential"
                    },
                    {
                        "label": "Index Name",
                        "name": "indexName",
                        "placeholder": "<VECTOR_INDEX_NAME>",
                        "type": "string",
                        "id": "redis_0-input-indexName-string"
                    },
                    {
                        "label": "Replace Index on Upsert",
                        "name": "replaceIndex",
                        "description": "Selecting this option will delete the existing index and recreate a new one when upserting",
                        "default": false,
                        "type": "boolean",
                        "id": "redis_0-input-replaceIndex-boolean"
                    },
                    {
                        "label": "Content Field",
                        "name": "contentKey",
                        "description": "Name of the field (column) that contains the actual content",
                        "type": "string",
                        "default": "content",
                        "additionalParams": true,
                        "optional": true,
                        "id": "redis_0-input-contentKey-string"
                    },
                    {
                        "label": "Metadata Field",
                        "name": "metadataKey",
                        "description": "Name of the field (column) that contains the metadata of the document",
                        "type": "string",
                        "default": "metadata",
                        "additionalParams": true,
                        "optional": true,
                        "id": "redis_0-input-metadataKey-string"
                    },
                    {
                        "label": "Vector Field",
                        "name": "vectorKey",
                        "description": "Name of the field (column) that contains the vector",
                        "type": "string",
                        "default": "content_vector",
                        "additionalParams": true,
                        "optional": true,
                        "id": "redis_0-input-vectorKey-string"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "redis_0-input-topK-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "redis_0-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "redis_0-input-embeddings-Embeddings"
                    }
                ],
                "inputs": {
                    "document": ["{{plainText_0.data.instance}}"],
                    "embeddings": "{{openAIEmbeddings_1.data.instance}}",
                    "indexName": "redis-1234",
                    "replaceIndex": true,
                    "contentKey": "content",
                    "metadataKey": "metadata",
                    "vectorKey": "content_vector",
                    "topK": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "redis_0-output-retriever-Redis|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Redis Retriever",
                                "type": "Redis | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "redis_0-output-vectorStore-Redis|VectorStore",
                                "name": "vectorStore",
                                "label": "Redis Vector Store",
                                "type": "Redis | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 517.9599892124863,
                "y": -892.797784079465
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 459,
            "id": "faiss_0",
            "position": {
                "x": 537.5298173812396,
                "y": 545.504276022315
            },
            "type": "customNode",
            "data": {
                "id": "faiss_0",
                "label": "Faiss",
                "version": 1,
                "name": "faiss",
                "type": "Faiss",
                "baseClasses": ["Faiss", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity search upon query using Faiss library from Meta",
                "inputParams": [
                    {
                        "label": "Base Path to load",
                        "name": "basePath",
                        "description": "Path to load faiss.index file",
                        "placeholder": "C:\\Users\\User\\Desktop",
                        "type": "string",
                        "id": "faiss_0-input-basePath-string"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "faiss_0-input-topK-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "faiss_0-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "faiss_0-input-embeddings-Embeddings"
                    }
                ],
                "inputs": {
                    "document": ["{{plainText_1.data.instance}}"],
                    "embeddings": "{{openAIEmbeddings_2.data.instance}}",
                    "basePath": "C:\\Users\\user\\yourpath",
                    "topK": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Faiss Retriever",
                                "type": "Faiss | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "faiss_0-output-vectorStore-Faiss|SaveableVectorStore|VectorStore",
                                "name": "vectorStore",
                                "label": "Faiss Vector Store",
                                "type": "Faiss | SaveableVectorStore | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 537.5298173812396,
                "y": 545.504276022315
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 487,
            "id": "plainText_0",
            "position": {
                "x": 93.6260931892966,
                "y": -1209.0760064103088
            },
            "type": "customNode",
            "data": {
                "id": "plainText_0",
                "label": "Plain Text",
                "version": 2,
                "name": "plainText",
                "type": "Document",
                "baseClasses": ["Document"],
                "category": "Document Loaders",
                "description": "Load data from plain text",
                "inputParams": [
                    {
                        "label": "Text",
                        "name": "text",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...",
                        "id": "plainText_0-input-text-string"
                    },
                    {
                        "label": "Metadata",
                        "name": "metadata",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_0-input-metadata-json"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Text Splitter",
                        "name": "textSplitter",
                        "type": "TextSplitter",
                        "optional": true,
                        "id": "plainText_0-input-textSplitter-TextSplitter"
                    }
                ],
                "inputs": {
                    "text": "AI-generated content refers to text, images, videos, or other media produced by artificial intelligence algorithms. It leverages deep learning and natural language processing to create human-like content autonomously. AI-generated content has diverse applications, from automated customer support chatbots and personalized marketing to creative writing and art generation. While it offers efficiency and scalability, it also raises concerns about ethics, authenticity, and potential misuse. Striking a balance between harnessing its potential for productivity and addressing its ethical implications is crucial as AI-generated content continues to evolve and reshape industries.",
                    "textSplitter": "",
                    "metadata": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "plainText_0-output-document-Document|json",
                                "name": "document",
                                "label": "Document",
                                "type": "Document | json"
                            },
                            {
                                "id": "plainText_0-output-text-string|json",
                                "name": "text",
                                "label": "Text",
                                "type": "string | json"
                            }
                        ],
                        "default": "document"
                    }
                ],
                "outputs": {
                    "output": "document"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 93.6260931892966,
                "y": -1209.0760064103088
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 670,
            "id": "chatOpenAI_1",
            "position": {
                "x": 533.0416474070086,
                "y": -168.63117374104695
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_1",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_1-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_1-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_1-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_1-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_1-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_1-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-3.5-turbo-16k",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": true,
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 533.0416474070086,
                "y": -168.63117374104695
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 328,
            "id": "RedisBackedChatMemory_0",
            "position": {
                "x": 2047.6821632337533,
                "y": 429.48576006102945
            },
            "type": "customNode",
            "data": {
                "id": "RedisBackedChatMemory_0",
                "label": "Redis-Backed Chat Memory",
                "version": 2,
                "name": "RedisBackedChatMemory",
                "type": "RedisBackedChatMemory",
                "baseClasses": ["RedisBackedChatMemory", "BaseChatMemory", "BaseMemory"],
                "category": "Memory",
                "description": "Summarizes the conversation and stores the memory in Redis server",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "optional": true,
                        "credentialNames": ["redisCacheApi", "redisCacheUrlApi"],
                        "id": "RedisBackedChatMemory_0-input-credential-credential"
                    },
                    {
                        "label": "Session Id",
                        "name": "sessionId",
                        "type": "string",
                        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
                        "default": "",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-sessionId-string"
                    },
                    {
                        "label": "Session Timeouts",
                        "name": "sessionTTL",
                        "type": "number",
                        "description": "Seconds till a session expires. If not specified, the session will never expire.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-sessionTTL-number"
                    },
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "additionalParams": true,
                        "id": "RedisBackedChatMemory_0-input-memoryKey-string"
                    },
                    {
                        "label": "Window Size",
                        "name": "windowSize",
                        "type": "number",
                        "description": "Window of size k to surface the last k back-and-forth to use as memory.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-windowSize-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "sessionId": "",
                    "sessionTTL": "",
                    "memoryKey": "chat_history",
                    "windowSize": ""
                },
                "outputAnchors": [
                    {
                        "id": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
                        "name": "RedisBackedChatMemory",
                        "label": "RedisBackedChatMemory",
                        "description": "Summarizes the conversation and stores the memory in Redis server",
                        "type": "RedisBackedChatMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {}
            }
        },
        {
            "width": 300,
            "height": 487,
            "id": "plainText_1",
            "position": {
                "x": 117.23894449422778,
                "y": 23.24339894687961
            },
            "type": "customNode",
            "data": {
                "id": "plainText_1",
                "label": "Plain Text",
                "version": 2,
                "name": "plainText",
                "type": "Document",
                "baseClasses": ["Document"],
                "category": "Document Loaders",
                "description": "Load data from plain text",
                "inputParams": [
                    {
                        "label": "Text",
                        "name": "text",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...",
                        "id": "plainText_1-input-text-string"
                    },
                    {
                        "label": "Metadata",
                        "name": "metadata",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "plainText_1-input-metadata-json"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Text Splitter",
                        "name": "textSplitter",
                        "type": "TextSplitter",
                        "optional": true,
                        "id": "plainText_1-input-textSplitter-TextSplitter"
                    }
                ],
                "inputs": {
                    "text": "Putin has unleashed violence and chaos. But while he may make gains on the battlefield  he will pay a continuing high price over the long run. \n\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n\nTo all Americans, I will be honest with you, as I've always promised. A Russian dictator, invading a foreign country, has costs around the world. \n\nAnd I'm taking robust action to make sure the pain of our sanctions is targeted at Russia's economy. And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n\nThese steps will help blunt gas prices here at home. And I know the news about what's happening can seem alarming. \n\nBut I want you to know that we are going to be okay. \n\nWhen the history of this era is written Putin's war on Ukraine will have left Russia weaker and the rest of the world stronger. \n\nWhile it shouldn't have taken something so terrible for people around the world to see what's at stake now everyone sees it clearly. \n\nWe see the unity among leaders of nations and a more unified Europe a more unified West. And we see unity among the people who are gathering in cities in large crowds around the world even in Russia to demonstrate their support for Ukraine. \n\nIn the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security. \n\nThis is a real test. It's going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people. \n\nTo our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \n\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people. \n\nHe will never extinguish their love of freedom. He will never weaken the resolve of the free world.",
                    "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
                    "metadata": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "plainText_1-output-document-Document|json",
                                "name": "document",
                                "label": "Document",
                                "type": "Document | json"
                            },
                            {
                                "id": "plainText_1-output-text-string|json",
                                "name": "text",
                                "label": "Text",
                                "type": "string | json"
                            }
                        ],
                        "default": "document"
                    }
                ],
                "outputs": {
                    "output": "document"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 117.23894449422778,
                "y": 23.24339894687961
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 430,
            "id": "recursiveCharacterTextSplitter_0",
            "position": {
                "x": -259.38954307457425,
                "y": 75.96855802341503
            },
            "type": "customNode",
            "data": {
                "id": "recursiveCharacterTextSplitter_0",
                "label": "Recursive Character Text Splitter",
                "version": 2,
                "name": "recursiveCharacterTextSplitter",
                "type": "RecursiveCharacterTextSplitter",
                "baseClasses": ["RecursiveCharacterTextSplitter", "TextSplitter", "BaseDocumentTransformer", "Runnable"],
                "category": "Text Splitters",
                "description": "Split documents recursively by different characters - starting with '\\n\\n', then '\\n', then ' '",
                "inputParams": [
                    {
                        "label": "Chunk Size",
                        "name": "chunkSize",
                        "type": "number",
                        "default": 1000,
                        "optional": true,
                        "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number"
                    },
                    {
                        "label": "Chunk Overlap",
                        "name": "chunkOverlap",
                        "type": "number",
                        "optional": true,
                        "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number"
                    },
                    {
                        "label": "Custom Separators",
                        "name": "separators",
                        "type": "string",
                        "rows": 4,
                        "description": "Array of custom separators to determine when to split the text, will override the default separators",
                        "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
                        "additionalParams": true,
                        "optional": true,
                        "id": "recursiveCharacterTextSplitter_0-input-separators-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "chunkSize": 1000,
                    "chunkOverlap": "",
                    "separators": ""
                },
                "outputAnchors": [
                    {
                        "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
                        "name": "recursiveCharacterTextSplitter",
                        "label": "RecursiveCharacterTextSplitter",
                        "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": -259.38954307457425,
                "y": 75.96855802341503
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 435,
            "id": "conversationalAgent_0",
            "position": {
                "x": 2432.125364763489,
                "y": -105.27942167533908
            },
            "type": "customNode",
            "data": {
                "id": "conversationalAgent_0",
                "label": "Conversational Agent",
                "version": 3,
                "name": "conversationalAgent",
                "type": "AgentExecutor",
                "baseClasses": ["AgentExecutor", "BaseChain", "Runnable"],
                "category": "Agents",
                "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessage",
                        "type": "string",
                        "rows": 4,
                        "default": "Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.",
                        "optional": true,
                        "additionalParams": true,
                        "id": "conversationalAgent_0-input-systemMessage-string"
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "conversationalAgent_0-input-maxIterations-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Allowed Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "id": "conversationalAgent_0-input-tools-Tool"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "id": "conversationalAgent_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseChatMemory",
                        "id": "conversationalAgent_0-input-memory-BaseChatMemory"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "conversationalAgent_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "inputModeration": "",
                    "tools": ["{{chainTool_2.data.instance}}", "{{chainTool_3.data.instance}}"],
                    "model": "{{chatOllama_0.data.instance}}",
                    "memory": "{{RedisBackedChatMemory_0.data.instance}}",
                    "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
                    "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."
                },
                "outputAnchors": [
                    {
                        "id": "conversationalAgent_0-output-conversationalAgent-AgentExecutor|BaseChain|Runnable",
                        "name": "conversationalAgent",
                        "label": "AgentExecutor",
                        "type": "AgentExecutor | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 2432.125364763489,
                "y": -105.27942167533908
            },
            "dragging": false
        },
        {
            "id": "chatOllama_0",
            "position": {
                "x": 1662.4375746412504,
                "y": 114.83248283616422
            },
            "type": "customNode",
            "data": {
                "id": "chatOllama_0",
                "label": "ChatOllama",
                "version": 2,
                "name": "chatOllama",
                "type": "ChatOllama",
                "baseClasses": ["ChatOllama", "SimpleChatModel", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Chat completion using open-source LLM on Ollama",
                "inputParams": [
                    {
                        "label": "Base URL",
                        "name": "baseUrl",
                        "type": "string",
                        "default": "http://localhost:11434",
                        "id": "chatOllama_0-input-baseUrl-string"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "string",
                        "placeholder": "llama2",
                        "id": "chatOllama_0-input-modelName-string"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "description": "The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOllama_0-input-temperature-number"
                    },
                    {
                        "label": "Top P",
                        "name": "topP",
                        "type": "number",
                        "description": "Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-topP-number"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "type": "number",
                        "description": "Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-topK-number"
                    },
                    {
                        "label": "Mirostat",
                        "name": "mirostat",
                        "type": "number",
                        "description": "Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-mirostat-number"
                    },
                    {
                        "label": "Mirostat ETA",
                        "name": "mirostatEta",
                        "type": "number",
                        "description": "Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-mirostatEta-number"
                    },
                    {
                        "label": "Mirostat TAU",
                        "name": "mirostatTau",
                        "type": "number",
                        "description": "Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0) Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-mirostatTau-number"
                    },
                    {
                        "label": "Context Window Size",
                        "name": "numCtx",
                        "type": "number",
                        "description": "Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-numCtx-number"
                    },
                    {
                        "label": "Number of GQA groups",
                        "name": "numGqa",
                        "type": "number",
                        "description": "The number of GQA groups in the transformer layer. Required for some models, for example it is 8 for llama2:70b. Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-numGqa-number"
                    },
                    {
                        "label": "Number of GPU",
                        "name": "numGpu",
                        "type": "number",
                        "description": "The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-numGpu-number"
                    },
                    {
                        "label": "Number of Thread",
                        "name": "numThread",
                        "type": "number",
                        "description": "Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-numThread-number"
                    },
                    {
                        "label": "Repeat Last N",
                        "name": "repeatLastN",
                        "type": "number",
                        "description": "Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-repeatLastN-number"
                    },
                    {
                        "label": "Repeat Penalty",
                        "name": "repeatPenalty",
                        "type": "number",
                        "description": "Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-repeatPenalty-number"
                    },
                    {
                        "label": "Stop Sequence",
                        "name": "stop",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "AI assistant:",
                        "description": "Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-stop-string"
                    },
                    {
                        "label": "Tail Free Sampling",
                        "name": "tfsZ",
                        "type": "number",
                        "description": "Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (Default: 1). Refer to <a target=\"_blank\" href=\"https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\">docs</a> for more details",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOllama_0-input-tfsZ-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOllama_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "baseUrl": "http://localhost:11434",
                    "modelName": "llama2",
                    "temperature": 0.9,
                    "topP": "",
                    "topK": "",
                    "mirostat": "",
                    "mirostatEta": "",
                    "mirostatTau": "",
                    "numCtx": "",
                    "numGqa": "",
                    "numGpu": "",
                    "numThread": "",
                    "repeatLastN": "",
                    "repeatPenalty": "",
                    "stop": "",
                    "tfsZ": ""
                },
                "outputAnchors": [
                    {
                        "id": "chatOllama_0-output-chatOllama-ChatOllama|SimpleChatModel|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOllama",
                        "label": "ChatOllama",
                        "description": "Chat completion using open-source LLM on Ollama",
                        "type": "ChatOllama | SimpleChatModel | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 580,
            "selected": false,
            "positionAbsolute": {
                "x": 1662.4375746412504,
                "y": 114.83248283616422
            },
            "dragging": false
        },
        {
            "id": "stickyNote_0",
            "position": {
                "x": 2421.3310049814813,
                "y": -395.88989972468414
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_0",
                "label": "Sticky Note",
                "version": 2,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "tags": ["Utilities"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_0-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Conversational Agent is suitable for LLM which doesn't have function calling support.\n\nIt uses the prompt to decide which Chain Tool is appropriate to answer user question. Downside is there could be higher error rate due to hallucination.\n\nOtherwise, it is recommended to use Multiple Documents QnA template which uses Tool Agent"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_0-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 264,
            "selected": false,
            "positionAbsolute": {
                "x": 2421.3310049814813,
                "y": -395.88989972468414
            },
            "dragging": false
        },
        {
            "source": "RedisBackedChatMemory_0",
            "sourceHandle": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "target": "conversationalAgent_0",
            "targetHandle": "conversationalAgent_0-input-memory-BaseChatMemory",
            "type": "buttonedge",
            "id": "RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-conversationalAgent_0-conversationalAgent_0-input-memory-BaseChatMemory",
            "data": {
                "label": ""
            }
        }
    ],
    "edges": [
        {
            "source": "retrievalQAChain_0",
            "sourceHandle": "retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|BaseLangChain",
            "target": "chainTool_2",
            "targetHandle": "chainTool_2-input-baseChain-BaseChain",
            "type": "buttonedge",
            "id": "retrievalQAChain_0-retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|BaseLangChain-chainTool_2-chainTool_2-input-baseChain-BaseChain",
            "data": {
                "label": ""
            }
        },
        {
            "source": "retrievalQAChain_1",
            "sourceHandle": "retrievalQAChain_1-output-retrievalQAChain-RetrievalQAChain|BaseChain|BaseLangChain",
            "target": "chainTool_3",
            "targetHandle": "chainTool_3-input-baseChain-BaseChain",
            "type": "buttonedge",
            "id": "retrievalQAChain_1-retrievalQAChain_1-output-retrievalQAChain-RetrievalQAChain|BaseChain|BaseLangChain-chainTool_3-chainTool_3-input-baseChain-BaseChain",
            "data": {
                "label": ""
            }
        },
        {
            "source": "openAIEmbeddings_1",
            "sourceHandle": "openAIEmbeddings_1-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "redis_0",
            "targetHandle": "redis_0-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_1-openAIEmbeddings_1-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-redis_0-redis_0-input-embeddings-Embeddings",
            "data": {
                "label": ""
            }
        },
        {
            "source": "redis_0",
            "sourceHandle": "redis_0-output-retriever-Redis|VectorStoreRetriever|BaseRetriever",
            "target": "retrievalQAChain_0",
            "targetHandle": "retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "type": "buttonedge",
            "id": "redis_0-redis_0-output-retriever-Redis|VectorStoreRetriever|BaseRetriever-retrievalQAChain_0-retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "data": {
                "label": ""
            }
        },
        {
            "source": "plainText_0",
            "sourceHandle": "plainText_0-output-document-Document|json",
            "target": "redis_0",
            "targetHandle": "redis_0-input-document-Document",
            "type": "buttonedge",
            "id": "plainText_0-plainText_0-output-document-Document|json-redis_0-redis_0-input-document-Document",
            "data": {
                "label": ""
            }
        },
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "retrievalQAChain_0",
            "targetHandle": "retrievalQAChain_0-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-retrievalQAChain_0-retrievalQAChain_0-input-model-BaseLanguageModel",
            "data": {
                "label": ""
            }
        },
        {
            "source": "chatOpenAI_1",
            "sourceHandle": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "retrievalQAChain_1",
            "targetHandle": "retrievalQAChain_1-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-retrievalQAChain_1-retrievalQAChain_1-input-model-BaseLanguageModel",
            "data": {
                "label": ""
            }
        },
        {
            "source": "faiss_0",
            "sourceHandle": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
            "target": "retrievalQAChain_1",
            "targetHandle": "retrievalQAChain_1-input-vectorStoreRetriever-BaseRetriever",
            "type": "buttonedge",
            "id": "faiss_0-faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever-retrievalQAChain_1-retrievalQAChain_1-input-vectorStoreRetriever-BaseRetriever",
            "data": {
                "label": ""
            }
        },
        {
            "source": "openAIEmbeddings_2",
            "sourceHandle": "openAIEmbeddings_2-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "faiss_0",
            "targetHandle": "faiss_0-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_2-openAIEmbeddings_2-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-faiss_0-faiss_0-input-embeddings-Embeddings",
            "data": {
                "label": ""
            }
        },
        {
            "source": "plainText_1",
            "sourceHandle": "plainText_1-output-document-Document|json",
            "target": "faiss_0",
            "targetHandle": "faiss_0-input-document-Document",
            "type": "buttonedge",
            "id": "plainText_1-plainText_1-output-document-Document|json-faiss_0-faiss_0-input-document-Document",
            "data": {
                "label": ""
            }
        },
        {
            "source": "recursiveCharacterTextSplitter_0",
            "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "target": "plainText_1",
            "targetHandle": "plainText_1-input-textSplitter-TextSplitter",
            "type": "buttonedge",
            "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-plainText_1-plainText_1-input-textSplitter-TextSplitter",
            "data": {
                "label": ""
            }
        },
        {
            "source": "chainTool_2",
            "sourceHandle": "chainTool_2-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|BaseLangChain",
            "target": "conversationalAgent_0",
            "targetHandle": "conversationalAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "chainTool_2-chainTool_2-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|BaseLangChain-conversationalAgent_0-conversationalAgent_0-input-tools-Tool",
            "data": {
                "label": ""
            }
        },
        {
            "source": "chainTool_3",
            "sourceHandle": "chainTool_3-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|BaseLangChain",
            "target": "conversationalAgent_0",
            "targetHandle": "conversationalAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "chainTool_3-chainTool_3-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|BaseLangChain-conversationalAgent_0-conversationalAgent_0-input-tools-Tool",
            "data": {
                "label": ""
            }
        },
        {
            "source": "RedisBackedChatMemory_0",
            "sourceHandle": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "target": "conversationalAgent_0",
            "targetHandle": "conversationalAgent_0-input-memory-BaseChatMemory",
            "type": "buttonedge",
            "id": "RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-conversationalAgent_0-conversationalAgent_0-input-memory-BaseChatMemory",
            "data": {
                "label": ""
            }
        },
        {
            "source": "chatOllama_0",
            "sourceHandle": "chatOllama_0-output-chatOllama-ChatOllama|SimpleChatModel|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "conversationalAgent_0",
            "targetHandle": "conversationalAgent_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOllama_0-chatOllama_0-output-chatOllama-ChatOllama|SimpleChatModel|BaseChatModel|BaseLanguageModel|Runnable-conversationalAgent_0-conversationalAgent_0-input-model-BaseChatModel"
        }
    ]
}
