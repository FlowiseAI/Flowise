{
    "name": "Github Code Debugger Sidekick",
    "description": "",
    "chatbotConfig": "{\"chatFeedback\":{\"status\":true},\"chatLinksInNewTab\":{\"status\":true},\"fullFileUpload\":{\"status\":true,\"allowedUploadFileTypes\":\"text/css,text/csv,text/html,application/json,text/markdown,application/pdf,application/sql,text/plain,application/xml,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\"pdfFile\":{\"usage\":\"perPage\",\"legacyBuild\":false}}}",
    "visibility": ["Private", "Browser Extension"],
    "category": "",
    "type": "CHATFLOW",
    "framework": ["AnswerAgent"],
    "nodes": [
        {
            "id": "chatPromptTemplate_0",
            "position": {
                "x": 716.5540701748693,
                "y": 739.2886292559722
            },
            "type": "customNode",
            "data": {
                "id": "chatPromptTemplate_0",
                "label": "Chat Prompt Template",
                "version": 2,
                "name": "chatPromptTemplate",
                "type": "ChatPromptTemplate",
                "baseClasses": ["ChatPromptTemplate", "BaseChatPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a chat prompt",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
                        "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
                        "display": true
                    },
                    {
                        "label": "Human Message",
                        "name": "humanMessagePrompt",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "{text}",
                        "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
                        "display": true
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "chatPromptTemplate_0-input-promptValues-json",
                        "display": true
                    },
                    {
                        "label": "Messages History",
                        "name": "messageHistory",
                        "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
                        "type": "tabs",
                        "tabIdentifier": "selectedMessagesTab",
                        "additionalParams": true,
                        "default": "messageHistoryCode",
                        "tabs": [
                            {
                                "label": "Add Messages (Code)",
                                "name": "messageHistoryCode",
                                "type": "code",
                                "hideCodeExecute": true,
                                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "chatPromptTemplate_0-input-messageHistory-tabs",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "systemMessagePrompt": "1. IDENTITY & PURPOSE\nYou are Code Debugger Agent, an AI tool designed to assist software developers in diagnosing and resolving code issues. Your primary tasks include:\n‚Ä¢ Analyzing provided code snippets alongside descriptions of bugs or unexpected behavior.\n‚Ä¢ Identifying potential errors, logical issues, syntax mistakes, or other discrepancies in the code.\n‚Ä¢ Proposing detailed fixes along with additional optimization or best practice suggestions.\n‚Ä¢ Optionally invoking tools to retrieve file contents or to create GitHub issues if further action is required.\n\n2. AVAILABLE TOOLS\nTool Name\tWhen to Use\tInvocation Notes\ncreate_issue\tTo create an issue on GitHub for a specific repository when a bug is confirmed.\tProvide repository details and a clear description of the issue.\nget_file_contents\tWhen a user requests to view a specific file‚Äôs content for further analysis.\tSupply the file path and confirm file access permissions.\n\n3. MODES & BEHAVIOR\n‚Ä¢ Default Debug Mode: Analyze provided code snippets and bug descriptions, generate a structured debugging report with identified issues and suggested fixes.\n‚Ä¢ File Inspection Mode: Triggered when the user requests the contents of a file; use get_file_contents to retrieve the code for review.\n‚Ä¢ Issue Creation Mode: When the debugging analysis confirms actionable items, user can ask to create a GitHub issue; use create_issue with a prepared summary and details.\n\n4. STYLE & TONE\n‚Ä¢ Professional, concise, and technically precise.\n‚Ä¢ Use appropriate programming terminology and clear, structured explanations.\n‚Ä¢ Format responses in a structured manner with clearly demarcated sections (debug_report, identified_issues, suggested_fixes, additional_notes).\n‚Ä¢ Avoid informal language and maintain focus on clarity and precision.\n\n5. CITATIONS & SOURCING\n‚Ä¢ When referencing programming documentation or external resources, include inline URLs or document names.\n‚Ä¢ If unsure about a detail or source, explicitly state ‚ÄúI‚Äôm not sure‚Äù and suggest further research.\n‚Ä¢ Do not include unverified information; always verify if possible.\n\n6. SAFETY & PERMISSIONS\n‚Ä¢ Do not expose or retrieve any private or sensitive file content without explicit user consent.\n‚Ä¢ Ensure that any GitHub issue created contains only public and non-sensitive information.\n‚Ä¢ Maintain confidentiality and only work with the data provided by the user.\n\n7. ERROR HANDLING\n‚Ä¢ If a tool (create_issue or get_file_contents) fails or returns an error, include a clear apology, describe the problem, and suggest corrective steps or ask the user for further instructions.\n‚Ä¢ If provided inputs are unclear or incomplete, request clarifications from the user before proceeding.\n\n8. EXAMPLES (DO NOT OUTPUT VERBATIM)\n‚Ä¢ Example 1:\n‚ÄÉInput: User provides a code snippet and a bug description.\n‚ÄÉResponse: Generate a containing an section with numbered issues (e.g., ‚Äú1. In function myFunction, the variable x is used before initialization.‚Äù), a section with a corrected code snippet or explanation, and an section with optimization tips.\n‚Ä¢ Example 2:\n‚ÄÉInput: User asks to view a file‚Äôs code.\n‚ÄÉResponse: Invoke get_file_contents with the requested file path and display the results.\n‚Ä¢ Example 3:\n‚ÄÉInput: After analysis, the user confirms the need to open a GitHub issue.\n‚ÄÉResponse: Use create_issue with the prepared summary from the debugging report.\n\n9. NON-NEGOTIABLE RULES\n‚Ä¢ Always follow the provided debugging process and report format exactly as outlined.\n‚Ä¢ Never fabricate information; state ‚ÄúI‚Äôm not sure‚Äù when necessary.\n‚Ä¢ Always confirm with the user before invoking create_issue or retrieving file contents via get_file_contents.\n‚Ä¢ Every output must include a clearly structured debugging report with the sections: , , , and .\n‚Ä¢ Avoid unnecessary verbosity; be concise while remaining thorough.",
                    "humanMessagePrompt": "###\nThe current URL is: {url}\nWeb Context (if any):\n{webContentText}\nOnly use the content or the URL if they are provided. otherwise ignore this section and only use the user input.\n###\n\n###\nFile Uploaded (if any)\n{fileUpload}\nOnly use the content of the file if it is provided. otherwise ignore this section and follow the user input.\n###\n\nUser Input:\n{input}",
                    "promptValues": "{\"url\":\"No URL Provided by the user\",\"webContentText\":\"No Content provided by the user\",\"fileUpload\":\"{{file_attachment}}\",\"input\":\"{{question}}\"}",
                    "messageHistory": "messageHistoryCode",
                    "selectedMessagesTab_chatPromptTemplate_0": "messageHistoryCode"
                },
                "outputAnchors": [
                    {
                        "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
                        "name": "chatPromptTemplate",
                        "label": "ChatPromptTemplate",
                        "description": "Schema to represent a chat prompt",
                        "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 748,
            "selected": false,
            "positionAbsolute": {
                "x": 716.5540701748693,
                "y": 739.2886292559722
            },
            "dragging": false
        },
        {
            "id": "stickyNote_1",
            "position": {
                "x": 65.32060453152891,
                "y": 1490.391941334096
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_1",
                "label": "Sticky Note",
                "version": 2,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "tags": ["Utilities"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_1-input-note-string",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "B"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_1-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 42,
            "selected": false,
            "positionAbsolute": {
                "x": 65.32060453152891,
                "y": 1490.391941334096
            },
            "dragging": false
        },
        {
            "id": "stickyNote_4",
            "position": {
                "x": 1987.5551946614194,
                "y": 174.90120537083527
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_4",
                "label": "Sticky Note",
                "version": 2,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "tags": ["Utilities"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_4-input-note-string",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Instructions for Best Results:\n\n1. Start with Debugging: Enter your code snippet into Instance A.\n2. Describe the Bug: Add bug details and description into Instance B.\n3. Save Your Chatflow: Once you're all set, save the chatflow.\n4. Analyze Your Blog: Click the green chat box and type \"GO!\"\n5. Boom! you got your answers."
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_4-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 243,
            "selected": false,
            "positionAbsolute": {
                "x": 1987.5551946614194,
                "y": 174.90120537083527
            },
            "dragging": false
        },
        {
            "id": "AAIChatMemory_0",
            "position": {
                "x": 398.1920171992573,
                "y": 241.0308969851949
            },
            "type": "customNode",
            "data": {
                "id": "AAIChatMemory_0",
                "label": "Answer Chat Memory",
                "version": 1,
                "name": "AAIChatMemory",
                "type": "AAIChatMemory",
                "baseClasses": ["AAIChatMemory", "BaseChatMemory", "BaseMemory"],
                "tags": ["AAI"],
                "category": "Memory",
                "description": "Summarizes the conversation and stores the memory in Answer Agents servers",
                "inputParams": [
                    {
                        "label": "Session Id",
                        "name": "sessionId",
                        "type": "string",
                        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
                        "default": "",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-sessionId-string",
                        "display": true
                    },
                    {
                        "label": "Session Timeouts",
                        "name": "sessionTTL",
                        "type": "number",
                        "description": "Seconds till a session expires. If not specified, the session will never expire.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-sessionTTL-number",
                        "display": true
                    },
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "additionalParams": true,
                        "id": "AAIChatMemory_0-input-memoryKey-string",
                        "display": true
                    },
                    {
                        "label": "Window Size",
                        "name": "windowSize",
                        "type": "number",
                        "description": "Window of size k to surface the last k back-and-forth to use as memory.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-windowSize-number",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "sessionId": "",
                    "sessionTTL": "",
                    "memoryKey": "chat_history",
                    "windowSize": ""
                },
                "outputAnchors": [
                    {
                        "id": "AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory",
                        "name": "AAIChatMemory",
                        "label": "AAIChatMemory",
                        "description": "Summarizes the conversation and stores the memory in Answer Agents servers",
                        "type": "AAIChatMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 259,
            "selected": false,
            "positionAbsolute": {
                "x": 398.1920171992573,
                "y": 241.0308969851949
            },
            "dragging": false
        },
        {
            "id": "aaiChatOpenAI_0",
            "position": {
                "x": 726.1802298400639,
                "y": 44.97779243674282
            },
            "type": "customNode",
            "data": {
                "id": "aaiChatOpenAI_0",
                "label": "Answer ChatOpenAI",
                "version": 1,
                "name": "aaiChatOpenAI",
                "type": "AAIChatOpenAI",
                "baseClasses": ["AAIChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "tags": ["AAI"],
                "category": "Chat Models",
                "description": "OpenAI GPT models ‚Ä¢ Zero configuration required",
                "inputParams": [
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-4o-mini",
                        "id": "aaiChatOpenAI_0-input-modelName-asyncOptions",
                        "display": true
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-temperature-number",
                        "display": true
                    },
                    {
                        "label": "Streaming",
                        "name": "streaming",
                        "type": "boolean",
                        "default": true,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-streaming-boolean",
                        "display": true
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-maxTokens-number",
                        "display": true
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-topP-number",
                        "display": true
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-frequencyPenalty-number",
                        "display": true
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-presencePenalty-number",
                        "display": true
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-timeout-number",
                        "display": true
                    },
                    {
                        "label": "Strict Tool Calling",
                        "name": "strictToolCalling",
                        "type": "boolean",
                        "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-strictToolCalling-boolean",
                        "display": true
                    },
                    {
                        "label": "Stop Sequence",
                        "name": "stopSequence",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-stopSequence-string",
                        "display": true
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-basepath-string",
                        "display": true
                    },
                    {
                        "label": "Proxy Url",
                        "name": "proxyUrl",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-proxyUrl-string",
                        "display": true
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-baseOptions-json",
                        "display": true
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
                        "default": false,
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-allowImageUploads-boolean",
                        "display": true
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "show": {
                            "allowImageUploads": true
                        },
                        "id": "aaiChatOpenAI_0-input-imageResolution-options",
                        "display": true
                    },
                    {
                        "label": "Reasoning Effort",
                        "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
                        "name": "reasoningEffort",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "Medium",
                                "name": "medium"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            }
                        ],
                        "default": "medium",
                        "optional": false,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-reasoningEffort-options",
                        "display": true
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-cache-BaseCache",
                        "display": true
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o-mini",
                    "temperature": 0.9,
                    "streaming": true,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "strictToolCalling": "",
                    "stopSequence": "",
                    "basepath": "",
                    "proxyUrl": "",
                    "baseOptions": "",
                    "allowImageUploads": true,
                    "imageResolution": "low",
                    "reasoningEffort": "medium"
                },
                "outputAnchors": [
                    {
                        "id": "aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "aaiChatOpenAI",
                        "label": "AAIChatOpenAI",
                        "description": "OpenAI GPT models ‚Ä¢ Zero configuration required",
                        "type": "AAIChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 676,
            "selected": false,
            "positionAbsolute": {
                "x": 726.1802298400639,
                "y": 44.97779243674282
            },
            "dragging": false
        },
        {
            "id": "aaiToolAgent_0",
            "position": {
                "x": 1321.1212546490456,
                "y": 351.6960927916322
            },
            "type": "customNode",
            "data": {
                "id": "aaiToolAgent_0",
                "label": "Tool Agent",
                "version": 2,
                "name": "aaiToolAgent",
                "type": "AgentExecutor",
                "baseClasses": ["AgentExecutor", "BaseChain", "Runnable"],
                "tags": ["AAI"],
                "category": "Agents",
                "description": "Tool Agent ‚Ä¢ Zero configuration required",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessage",
                        "type": "string",
                        "default": "You are a helpful AI assistant.",
                        "description": "If Chat Prompt Template is provided, this will be ignored",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-systemMessage-string",
                        "display": true
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-maxIterations-number",
                        "display": true
                    },
                    {
                        "label": "Enable Detailed Streaming",
                        "name": "enableDetailedStreaming",
                        "type": "boolean",
                        "default": false,
                        "description": "Stream detailed intermediate steps during agent execution",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-enableDetailedStreaming-boolean",
                        "display": true
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "id": "aaiToolAgent_0-input-tools-Tool",
                        "display": true
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseChatMemory",
                        "id": "aaiToolAgent_0-input-memory-BaseChatMemory",
                        "display": true
                    },
                    {
                        "label": "Tool Calling Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
                        "id": "aaiToolAgent_0-input-model-BaseChatModel",
                        "display": true
                    },
                    {
                        "label": "Chat Prompt Template",
                        "name": "chatPromptTemplate",
                        "type": "ChatPromptTemplate",
                        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
                        "optional": true,
                        "id": "aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
                        "display": true
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "aaiToolAgent_0-input-inputModeration-Moderation",
                        "display": true
                    }
                ],
                "inputs": {
                    "tools": ["{{githubMCP_0.data.instance}}"],
                    "memory": "{{AAIChatMemory_0.data.instance}}",
                    "model": "{{aaiChatOpenAI_0.data.instance}}",
                    "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
                    "systemMessage": "You are a helpful AI assistant.",
                    "inputModeration": "",
                    "maxIterations": "",
                    "enableDetailedStreaming": ""
                },
                "outputAnchors": [
                    {
                        "id": "aaiToolAgent_0-output-aaiToolAgent-AgentExecutor|BaseChain|Runnable",
                        "name": "aaiToolAgent",
                        "label": "AgentExecutor",
                        "description": "Tool Agent ‚Ä¢ Zero configuration required",
                        "type": "AgentExecutor | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 492,
            "selected": false,
            "positionAbsolute": {
                "x": 1321.1212546490456,
                "y": 351.6960927916322
            },
            "dragging": false
        },
        {
            "id": "githubMCP_0",
            "position": {
                "x": 357.81000981584987,
                "y": 743.4940422901898
            },
            "type": "customNode",
            "data": {
                "id": "githubMCP_0",
                "label": "Github MCP",
                "version": 1,
                "name": "githubMCP",
                "type": "Github MCP Tool",
                "baseClasses": ["Tool"],
                "tags": ["AAI"],
                "category": "MCP Servers",
                "description": "MCP Server for the GitHub API",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["githubApi"],
                        "id": "githubMCP_0-input-credential-credential",
                        "display": true
                    },
                    {
                        "label": "Available Actions",
                        "name": "mcpActions",
                        "type": "asyncMultiOptions",
                        "loadMethod": "listActions",
                        "refresh": true,
                        "id": "githubMCP_0-input-mcpActions-asyncMultiOptions",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "mcpActions": "[\"create_issue\",\"get_file_contents\"]"
                },
                "outputAnchors": [
                    {
                        "id": "githubMCP_0-output-githubMCP-Tool",
                        "name": "githubMCP",
                        "label": "Github MCP Tool",
                        "description": "MCP Server for the GitHub API",
                        "type": "Tool"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 434,
            "selected": false,
            "positionAbsolute": {
                "x": 357.81000981584987,
                "y": 743.4940422901898
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "aaiChatOpenAI_0",
            "sourceHandle": "aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "aaiChatOpenAI_0-aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-aaiToolAgent_0-aaiToolAgent_0-input-model-BaseChatModel"
        },
        {
            "source": "AAIChatMemory_0",
            "sourceHandle": "AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-memory-BaseChatMemory",
            "type": "buttonedge",
            "id": "AAIChatMemory_0-AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory-aaiToolAgent_0-aaiToolAgent_0-input-memory-BaseChatMemory"
        },
        {
            "source": "chatPromptTemplate_0",
            "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
            "type": "buttonedge",
            "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-aaiToolAgent_0-aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
        },
        {
            "source": "githubMCP_0",
            "sourceHandle": "githubMCP_0-output-githubMCP-Tool",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "githubMCP_0-githubMCP_0-output-githubMCP-Tool-aaiToolAgent_0-aaiToolAgent_0-input-tools-Tool"
        }
    ]
}
