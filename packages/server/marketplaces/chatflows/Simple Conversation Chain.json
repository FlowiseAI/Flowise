{
    "description": "Basic example of Conversation Chain with built-in memory - works exactly like ChatGPT",
    "categories": "Buffer Memory,ChatOpenAI,Conversation Chain,Langchain",
    "framework": "Langchain",
    "badge": "POPULAR",
    "nodes": [
        {
            "width": 300,
            "height": 574,
            "id": "chatOpenAI_0",
            "position": {
                "x": 579.0877964395976,
                "y": -138.68792413227874
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 3,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "options",
                        "options": [
                            {
                                "label": "gpt-4",
                                "name": "gpt-4"
                            },
                            {
                                "label": "gpt-4-turbo-preview",
                                "name": "gpt-4-turbo-preview"
                            },
                            {
                                "label": "gpt-4-0125-preview",
                                "name": "gpt-4-0125-preview"
                            },
                            {
                                "label": "gpt-4-1106-preview",
                                "name": "gpt-4-1106-preview"
                            },
                            {
                                "label": "gpt-4-vision-preview",
                                "name": "gpt-4-vision-preview"
                            },
                            {
                                "label": "gpt-4-0613",
                                "name": "gpt-4-0613"
                            },
                            {
                                "label": "gpt-4-32k",
                                "name": "gpt-4-32k"
                            },
                            {
                                "label": "gpt-4-32k-0613",
                                "name": "gpt-4-32k-0613"
                            },
                            {
                                "label": "gpt-3.5-turbo",
                                "name": "gpt-3.5-turbo"
                            },
                            {
                                "label": "gpt-3.5-turbo-1106",
                                "name": "gpt-3.5-turbo-1106"
                            },
                            {
                                "label": "gpt-3.5-turbo-0613",
                                "name": "gpt-3.5-turbo-0613"
                            },
                            {
                                "label": "gpt-3.5-turbo-16k",
                                "name": "gpt-3.5-turbo-16k"
                            },
                            {
                                "label": "gpt-3.5-turbo-16k-0613",
                                "name": "gpt-3.5-turbo-16k-0613"
                            }
                        ],
                        "default": "gpt-3.5-turbo",
                        "optional": true,
                        "id": "chatOpenAI_0-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-3.5-turbo-16k",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": ""
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 579.0877964395976,
                "y": -138.68792413227874
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 376,
            "id": "bufferMemory_0",
            "position": {
                "x": 220.30240896145915,
                "y": 351.61324070296877
            },
            "type": "customNode",
            "data": {
                "id": "bufferMemory_0",
                "label": "Buffer Memory",
                "version": 1,
                "name": "bufferMemory",
                "type": "BufferMemory",
                "baseClasses": ["BufferMemory", "BaseChatMemory", "BaseMemory"],
                "category": "Memory",
                "description": "Remembers previous conversational back and forths directly",
                "inputParams": [
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "id": "bufferMemory_0-input-memoryKey-string"
                    },
                    {
                        "label": "Input Key",
                        "name": "inputKey",
                        "type": "string",
                        "default": "input",
                        "id": "bufferMemory_0-input-inputKey-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "memoryKey": "chat_history",
                    "inputKey": "input"
                },
                "outputAnchors": [
                    {
                        "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
                        "name": "bufferMemory",
                        "label": "BufferMemory",
                        "type": "BufferMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 220.30240896145915,
                "y": 351.61324070296877
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 383,
            "id": "conversationChain_0",
            "position": {
                "x": 958.9887390513221,
                "y": 318.8734467468765
            },
            "type": "customNode",
            "data": {
                "id": "conversationChain_0",
                "label": "Conversation Chain",
                "version": 3,
                "name": "conversationChain",
                "type": "ConversationChain",
                "baseClasses": ["ConversationChain", "LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chat models specific conversational chain with memory",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "description": "If Chat Prompt Template is provided, this will be ignored",
                        "additionalParams": true,
                        "optional": true,
                        "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
                        "placeholder": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
                        "id": "conversationChain_0-input-systemMessagePrompt-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "id": "conversationChain_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseMemory",
                        "id": "conversationChain_0-input-memory-BaseMemory"
                    },
                    {
                        "label": "Chat Prompt Template",
                        "name": "chatPromptTemplate",
                        "type": "ChatPromptTemplate",
                        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
                        "optional": true,
                        "id": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "conversationChain_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "inputModeration": "",
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "memory": "{{bufferMemory_0.data.instance}}",
                    "chatPromptTemplate": "",
                    "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."
                },
                "outputAnchors": [
                    {
                        "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
                        "name": "conversationChain",
                        "label": "ConversationChain",
                        "type": "ConversationChain | LLMChain | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 958.9887390513221,
                "y": 318.8734467468765
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel"
        },
        {
            "source": "bufferMemory_0",
            "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "target": "conversationChain_0",
            "targetHandle": "conversationChain_0-input-memory-BaseMemory",
            "type": "buttonedge",
            "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory"
        }
    ]
}
