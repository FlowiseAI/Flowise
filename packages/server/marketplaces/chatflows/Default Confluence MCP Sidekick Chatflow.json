{
    "name": "Confluence Sidekick",
    "description": "This chatflow is designed to create a specialized AI agent, “Confluence MCP Assistant,” that interfaces with a Confluence server via the Confluence MCP protocols. It automatically executes validated API calls to manage pages, comments, attachments, and spaces while providing detailed error feedback and following strict security and schema guidelines.",
    "framework": ["Answer Agent"],
    "usecases": ["Confluence"],
    "nodes": [
        {
            "id": "aaiToolAgent_0",
            "position": {
                "x": 797.3975527814143,
                "y": 277.3911080764195
            },
            "type": "customNode",
            "data": {
                "id": "aaiToolAgent_0",
                "label": "Tool Agent",
                "version": 2,
                "name": "aaiToolAgent",
                "type": "AgentExecutor",
                "baseClasses": ["AgentExecutor", "BaseChain", "Runnable"],
                "tags": ["AAI"],
                "category": "Agents",
                "description": "Tool Agent • Zero configuration required",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessage",
                        "type": "string",
                        "default": "You are a helpful AI assistant.",
                        "description": "If Chat Prompt Template is provided, this will be ignored",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-systemMessage-string",
                        "display": true
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-maxIterations-number",
                        "display": true
                    },
                    {
                        "label": "Enable Detailed Streaming",
                        "name": "enableDetailedStreaming",
                        "type": "boolean",
                        "default": false,
                        "description": "Stream detailed intermediate steps during agent execution",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-enableDetailedStreaming-boolean",
                        "display": true
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "id": "aaiToolAgent_0-input-tools-Tool",
                        "display": true
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseChatMemory",
                        "id": "aaiToolAgent_0-input-memory-BaseChatMemory",
                        "display": true
                    },
                    {
                        "label": "Tool Calling Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
                        "id": "aaiToolAgent_0-input-model-BaseChatModel",
                        "display": true
                    },
                    {
                        "label": "Chat Prompt Template",
                        "name": "chatPromptTemplate",
                        "type": "ChatPromptTemplate",
                        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
                        "optional": true,
                        "id": "aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
                        "display": true
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "aaiToolAgent_0-input-inputModeration-Moderation",
                        "display": true
                    }
                ],
                "inputs": {
                    "tools": ["{{currentDateTime_0.data.instance}}", "{{confluenceMCP_0.data.instance}}"],
                    "memory": "{{AAIChatMemory_0.data.instance}}",
                    "model": "{{aaiChatOpenAI_0.data.instance}}",
                    "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
                    "systemMessage": "You are a helpful AI assistant.",
                    "inputModeration": "",
                    "maxIterations": "",
                    "enableDetailedStreaming": ""
                },
                "outputAnchors": [
                    {
                        "id": "aaiToolAgent_0-output-aaiToolAgent-AgentExecutor|BaseChain|Runnable",
                        "name": "aaiToolAgent",
                        "label": "AgentExecutor",
                        "description": "Tool Agent • Zero configuration required",
                        "type": "AgentExecutor | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 492,
            "positionAbsolute": {
                "x": 797.3975527814143,
                "y": 277.3911080764195
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "aaiChatOpenAI_0",
            "position": {
                "x": 321.48081667566703,
                "y": -247.03465143583247
            },
            "type": "customNode",
            "data": {
                "id": "aaiChatOpenAI_0",
                "label": "Answer ChatOpenAI",
                "version": 1,
                "name": "aaiChatOpenAI",
                "type": "AAIChatOpenAI",
                "baseClasses": ["AAIChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "tags": ["AAI"],
                "category": "Chat Models",
                "description": "OpenAI GPT models • Zero configuration required",
                "inputParams": [
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-4o-mini",
                        "id": "aaiChatOpenAI_0-input-modelName-asyncOptions",
                        "display": true
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-temperature-number",
                        "display": true
                    },
                    {
                        "label": "Streaming",
                        "name": "streaming",
                        "type": "boolean",
                        "default": true,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-streaming-boolean",
                        "display": true
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-maxTokens-number",
                        "display": true
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-topP-number",
                        "display": true
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-frequencyPenalty-number",
                        "display": true
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-presencePenalty-number",
                        "display": true
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-timeout-number",
                        "display": true
                    },
                    {
                        "label": "Strict Tool Calling",
                        "name": "strictToolCalling",
                        "type": "boolean",
                        "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-strictToolCalling-boolean",
                        "display": true
                    },
                    {
                        "label": "Stop Sequence",
                        "name": "stopSequence",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-stopSequence-string",
                        "display": true
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-basepath-string",
                        "display": true
                    },
                    {
                        "label": "Proxy Url",
                        "name": "proxyUrl",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-proxyUrl-string",
                        "display": true
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-baseOptions-json",
                        "display": true
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
                        "default": false,
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-allowImageUploads-boolean",
                        "display": true
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "show": {
                            "allowImageUploads": true
                        },
                        "id": "aaiChatOpenAI_0-input-imageResolution-options",
                        "display": true
                    },
                    {
                        "label": "Reasoning Effort",
                        "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
                        "name": "reasoningEffort",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "Medium",
                                "name": "medium"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            }
                        ],
                        "default": "medium",
                        "optional": false,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-reasoningEffort-options",
                        "display": true
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-cache-BaseCache",
                        "display": true
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o-mini",
                    "temperature": 0.9,
                    "streaming": true,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "strictToolCalling": "",
                    "stopSequence": "",
                    "basepath": "",
                    "proxyUrl": "",
                    "baseOptions": "",
                    "allowImageUploads": true,
                    "imageResolution": "low",
                    "reasoningEffort": "medium"
                },
                "outputAnchors": [
                    {
                        "id": "aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "aaiChatOpenAI",
                        "label": "AAIChatOpenAI",
                        "description": "OpenAI GPT models • Zero configuration required",
                        "type": "AAIChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 676,
            "selected": false,
            "positionAbsolute": {
                "x": 321.48081667566703,
                "y": -247.03465143583247
            },
            "dragging": false
        },
        {
            "id": "AAIChatMemory_0",
            "position": {
                "x": -7.778718489868993,
                "y": 129.4870179639911
            },
            "type": "customNode",
            "data": {
                "id": "AAIChatMemory_0",
                "label": "Answer Chat Memory",
                "version": 1,
                "name": "AAIChatMemory",
                "type": "AAIChatMemory",
                "baseClasses": ["AAIChatMemory", "BaseChatMemory", "BaseMemory"],
                "tags": ["AAI"],
                "category": "Memory",
                "description": "Summarizes the conversation and stores the memory in Answer Agents servers",
                "inputParams": [
                    {
                        "label": "Session Id",
                        "name": "sessionId",
                        "type": "string",
                        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
                        "default": "",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-sessionId-string",
                        "display": true
                    },
                    {
                        "label": "Session Timeouts",
                        "name": "sessionTTL",
                        "type": "number",
                        "description": "Seconds till a session expires. If not specified, the session will never expire.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-sessionTTL-number",
                        "display": true
                    },
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "additionalParams": true,
                        "id": "AAIChatMemory_0-input-memoryKey-string",
                        "display": true
                    },
                    {
                        "label": "Window Size",
                        "name": "windowSize",
                        "type": "number",
                        "description": "Window of size k to surface the last k back-and-forth to use as memory.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-windowSize-number",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "sessionId": "",
                    "sessionTTL": "",
                    "memoryKey": "chat_history",
                    "windowSize": ""
                },
                "outputAnchors": [
                    {
                        "id": "AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory",
                        "name": "AAIChatMemory",
                        "label": "AAIChatMemory",
                        "description": "Summarizes the conversation and stores the memory in Answer Agents servers",
                        "type": "AAIChatMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 259,
            "selected": false,
            "positionAbsolute": {
                "x": -7.778718489868993,
                "y": 129.4870179639911
            },
            "dragging": false
        },
        {
            "id": "chatPromptTemplate_0",
            "position": {
                "x": 308.95311224250247,
                "y": 664.7281332633123
            },
            "type": "customNode",
            "data": {
                "id": "chatPromptTemplate_0",
                "label": "Chat Prompt Template",
                "version": 2,
                "name": "chatPromptTemplate",
                "type": "ChatPromptTemplate",
                "baseClasses": ["ChatPromptTemplate", "BaseChatPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a chat prompt",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
                        "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
                        "display": true
                    },
                    {
                        "label": "Human Message",
                        "name": "humanMessagePrompt",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "{text}",
                        "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
                        "display": true
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "chatPromptTemplate_0-input-promptValues-json",
                        "display": true
                    },
                    {
                        "label": "Messages History",
                        "name": "messageHistory",
                        "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
                        "type": "tabs",
                        "tabIdentifier": "selectedMessagesTab",
                        "additionalParams": true,
                        "default": "messageHistoryCode",
                        "tabs": [
                            {
                                "label": "Add Messages (Code)",
                                "name": "messageHistoryCode",
                                "type": "code",
                                "hideCodeExecute": true,
                                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "chatPromptTemplate_0-input-messageHistory-tabs",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "systemMessagePrompt": "SYSTEM PROMPT — “Confluence MCP Assistant” (v1.1 • 2025-07-11)\nIDENTITY & PURPOSE\nYou are the Confluence MCP Assistant, an AI agent that interfaces directly with a Confluence MCP (Model Context Protocol) server. Your primary goal is to help users execute all Confluence operations—searching, retrieving, creating, updating, and managing pages, comments, and attachments—by directly translating validated user input into appropriate API calls without additional confirmation for high-impact operations. The agent adheres strictly to the Confluence MCP documentation and schema.\n────────────────────────────────────────────────────────────\n\nAVAILABLE TOOLS\n| Tool Name | When to Use | Invocation Notes | |-----------------|---------------------------------------------------------------|------------------| | get_page | When retrieving a specific page by its ID. | Requires pageId; optionally specify format and includeMarkup. | | search_pages | When searching for pages using CQL queries. | Provide a valid CQL query, limit, and optionally choose text/markdown format and includeMarkup. | | get_spaces | When listing all available Confluence spaces. | Optionally provide a limit; default is 50 if not supplied. | | create_page | When creating a new Confluence page. | Requires spaceKey, title, and content in valid Confluence XHTML; optionally provide parentId. | | update_page | When updating an existing page with new title or content. | Requires pageId, title, content (valid XHTML), and current version number. | | get_comments | When retrieving comments for a specific page. | Requires pageId; optionally specify format and limit. | | add_comment | When adding a comment to a Confluence page. | Requires pageId and content in valid Confluence XHTML; optionally provide parentId for threading. | | get_attachments | When retrieving a list of attachments for a given page. | Requires pageId; optionally specify result limit. | | add_attachment | When attaching a file to a page. | Requires pageId, filename, Base64 encoded fileContent, and optionally a comment. |\n────────────────────────────────────────────────────────────\n\nMODES & BEHAVIOR\n• Default Mode: Processes user instructions by directly mapping validated inputs to the appropriate Confluence MCP API calls automatically, without a confirmation step for high-impact operations.\n• Retrieval Mode: Used when fetching content such as pages, comments, or attachments using get_page, get_comments, and get_attachments.\n• Search Mode: Activated when executing CQL-based searches via search_pages.\n• Management Mode: Applied for creating or updating content (create_page, update_page, add_comment, add_attachment) ensuring requirements like valid XHTML content and schema conformity are met.\n────────────────────────────────────────────────────────────\n\nSTYLE & TONE\n• Professional, clear, and concise.\n• Instructional and supportive, providing detailed explanations and troubleshooting advice when errors occur.\n• Uses plain language with technical precision; avoids undue informality or emojis.\n────────────────────────────────────────────────────────────\n\nCITATIONS & SOURCING\n• Reference the Confluence MCP Documentation when detailing API schema or process steps.\n• Cite documentation sections or inline URLs where applicable to support technical decisions.\n• If unsure about any detail, express uncertainty and request clarifying details from the user.\n────────────────────────────────────────────────────────────\n\nSAFETY & PERMISSIONS\n• Never expose or log sensitive credentials such as CONFLUENCE_API_TOKEN, CONFLUENCE_BASE_URL, or CONFLUENCE_USER_EMAIL.\n• Ensure that necessary credentials are set and valid prior to executing any live API calls.\n• Exercise caution with operations that may impact the Confluence environment, ensuring security and integrity at all times.\n────────────────────────────────────────────────────────────\n\nERROR HANDLING\n• Provide detailed error feedback including potential troubleshooting tips and next actionable steps.\n• If an API tool fails (e.g., due to schema mismatch, network issues, or version conflicts), apologize briefly, explain the issue in detail, and request corrected or additional input from the user.\n• For update conflicts, automatically retrieve the current version before reattempting the update and notify the user regarding any discrepancy.\n────────────────────────────────────────────────────────────\n\nEXAMPLES (DO NOT OUTPUT VERBATIM)\n• A request such as “Show me page 12345 in markdown” should result in an automatic get_page call with pageId = \"12345\" and format set to markdown.\n• A search query like “Find all pages about sprint planning” is mapped to a search_pages call with a CQL query corresponding to text ~ \"sprint planning\".\n• An instruction such as “Update the project details page” should trigger update_page automatically after validating inputs (including checking the current version) and ensuring XHTML content standards are met.\n• For adding an attachment, the agent will perform add_attachment based on provided file data with detailed confirmation of file details included.\n────────────────────────────────────────────────────────────\n\nNON-NEGOTIABLE RULES\n• Validate all user inputs rigorously against the required schema before proceeding with any API call.\n• Never reveal or handle sensitive credential information in outputs.\n• Automatically execute operations once inputs are validated, except when ambiguity arises—in such cases, prompt the user for additional details.\n• Adhere strictly to the Confluence MCP documentation standards; use valid XHTML for content operations.\n• Always include a suggested next step or follow-up with each response to guide the user.",
                    "humanMessagePrompt": "The current URL is: {url}\nWeb Context (if any):\n{webContentText}\nOnly use the content or the URL if they are provided. otherwise ignore this section and only use the user input.\n\n###\nFile Uploaded (if any)\n{fileUpload}\nOnly use the content of the file if it is provided. otherwise ignore this section and follow the user input.\n\n###\n\nUser Input:\n{input}\n",
                    "promptValues": "{\"url\":\"No URL provided by the user\",\"webContentText\":\"{{file_attachment}}\",\"fileUpload\":\"No Web Content was provided by the user\",\"input\":\"{{question}}\"}",
                    "messageHistory": "messageHistoryCode"
                },
                "outputAnchors": [
                    {
                        "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
                        "name": "chatPromptTemplate",
                        "label": "ChatPromptTemplate",
                        "description": "Schema to represent a chat prompt",
                        "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 748,
            "selected": false,
            "positionAbsolute": {
                "x": 308.95311224250247,
                "y": 664.7281332633123
            },
            "dragging": false
        },
        {
            "id": "currentDateTime_0",
            "position": {
                "x": 786.6589970817336,
                "y": -7.1927104677048135
            },
            "type": "customNode",
            "data": {
                "id": "currentDateTime_0",
                "label": "CurrentDateTime",
                "version": 1,
                "name": "currentDateTime",
                "type": "CurrentDateTime",
                "baseClasses": ["CurrentDateTime", "Tool"],
                "tags": ["AAI"],
                "category": "Tools",
                "description": "Get todays day, date and time.",
                "inputParams": [],
                "inputAnchors": [],
                "inputs": {},
                "outputAnchors": [
                    {
                        "id": "currentDateTime_0-output-currentDateTime-CurrentDateTime|Tool",
                        "name": "currentDateTime",
                        "label": "CurrentDateTime",
                        "description": "Get todays day, date and time.",
                        "type": "CurrentDateTime | Tool"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 149,
            "selected": false,
            "positionAbsolute": {
                "x": 786.6589970817336,
                "y": -7.1927104677048135
            },
            "dragging": false
        },
        {
            "id": "confluenceMCP_0",
            "position": {
                "x": -141.6384563932886,
                "y": 550.798093712018
            },
            "type": "customNode",
            "data": {
                "id": "confluenceMCP_0",
                "label": "Confluence MCP",
                "version": 1,
                "name": "confluenceMCP",
                "type": "Confluence MCP Tool",
                "baseClasses": ["Tool"],
                "tags": ["AAI"],
                "category": "MCP Servers",
                "description": "MCP server that integrates the Confluence API",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["confluenceCloudApi"],
                        "id": "confluenceMCP_0-input-credential-credential",
                        "display": true
                    },
                    {
                        "label": "Available Actions",
                        "name": "mcpActions",
                        "type": "asyncMultiOptions",
                        "loadMethod": "listActions",
                        "refresh": true,
                        "id": "confluenceMCP_0-input-mcpActions-asyncMultiOptions",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "mcpActions": "[\"error\"]"
                },
                "outputAnchors": [
                    {
                        "id": "confluenceMCP_0-output-confluenceMCP-Tool",
                        "name": "confluenceMCP",
                        "label": "Confluence MCP Tool",
                        "description": "MCP server that integrates the Confluence API",
                        "type": "Tool"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 406,
            "selected": false,
            "positionAbsolute": {
                "x": -141.6384563932886,
                "y": 550.798093712018
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "AAIChatMemory_0",
            "sourceHandle": "AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-memory-BaseChatMemory",
            "type": "buttonedge",
            "id": "AAIChatMemory_0-AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory-aaiToolAgent_0-aaiToolAgent_0-input-memory-BaseChatMemory"
        },
        {
            "source": "aaiChatOpenAI_0",
            "sourceHandle": "aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "aaiChatOpenAI_0-aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-aaiToolAgent_0-aaiToolAgent_0-input-model-BaseChatModel"
        },
        {
            "source": "chatPromptTemplate_0",
            "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
            "type": "buttonedge",
            "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-aaiToolAgent_0-aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
        },
        {
            "source": "currentDateTime_0",
            "sourceHandle": "currentDateTime_0-output-currentDateTime-CurrentDateTime|Tool",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "currentDateTime_0-currentDateTime_0-output-currentDateTime-CurrentDateTime|Tool-aaiToolAgent_0-aaiToolAgent_0-input-tools-Tool"
        },
        {
            "source": "confluenceMCP_0",
            "sourceHandle": "confluenceMCP_0-output-confluenceMCP-Tool",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "confluenceMCP_0-confluenceMCP_0-output-confluenceMCP-Tool-aaiToolAgent_0-aaiToolAgent_0-input-tools-Tool"
        }
    ]
}
