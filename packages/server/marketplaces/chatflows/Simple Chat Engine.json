{
    "description": "Simple chat engine to handle back and forth conversations using LlamaIndex",
    "usecases": ["Chatbot"],
    "framework": ["LlamaIndex"],
    "nodes": [
        {
            "width": 300,
            "height": 462,
            "id": "simpleChatEngine_0",
            "position": {
                "x": 1210.127368000538,
                "y": 324.98110560103896
            },
            "type": "customNode",
            "data": {
                "id": "simpleChatEngine_0",
                "label": "Simple Chat Engine",
                "version": 1,
                "name": "simpleChatEngine",
                "type": "SimpleChatEngine",
                "baseClasses": ["SimpleChatEngine"],
                "tags": ["LlamaIndex"],
                "category": "Engine",
                "description": "Simple engine to handle back and forth conversations",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "placeholder": "You are a helpful assistant",
                        "id": "simpleChatEngine_0-input-systemMessagePrompt-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel_LlamaIndex",
                        "id": "simpleChatEngine_0-input-model-BaseChatModel_LlamaIndex"
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseChatMemory",
                        "id": "simpleChatEngine_0-input-memory-BaseChatMemory"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "memory": "{{RedisBackedChatMemory_0.data.instance}}",
                    "chatPromptTemplate": "",
                    "inputModeration": "",
                    "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."
                },
                "outputAnchors": [
                    {
                        "id": "simpleChatEngine_0-output-simpleChatEngine-SimpleChatEngine",
                        "name": "simpleChatEngine",
                        "label": "SimpleChatEngine",
                        "type": "SimpleChatEngine"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 1210.127368000538,
                "y": 324.98110560103896
            }
        },
        {
            "width": 300,
            "height": 328,
            "id": "RedisBackedChatMemory_0",
            "position": {
                "x": 75,
                "y": 82
            },
            "type": "customNode",
            "data": {
                "id": "RedisBackedChatMemory_0",
                "label": "Redis-Backed Chat Memory",
                "version": 2,
                "name": "RedisBackedChatMemory",
                "type": "RedisBackedChatMemory",
                "baseClasses": ["RedisBackedChatMemory", "BaseChatMemory", "BaseMemory"],
                "category": "Memory",
                "description": "Summarizes the conversation and stores the memory in Redis server",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "optional": true,
                        "credentialNames": ["redisCacheApi", "redisCacheUrlApi"],
                        "id": "RedisBackedChatMemory_0-input-credential-credential"
                    },
                    {
                        "label": "Session Id",
                        "name": "sessionId",
                        "type": "string",
                        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
                        "default": "",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-sessionId-string"
                    },
                    {
                        "label": "Session Timeouts",
                        "name": "sessionTTL",
                        "type": "number",
                        "description": "Seconds till a session expires. If not specified, the session will never expire.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-sessionTTL-number"
                    },
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "additionalParams": true,
                        "id": "RedisBackedChatMemory_0-input-memoryKey-string"
                    },
                    {
                        "label": "Window Size",
                        "name": "windowSize",
                        "type": "number",
                        "description": "Window of size k to surface the last k back-and-forth to use as memory.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "RedisBackedChatMemory_0-input-windowSize-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "sessionId": "",
                    "sessionTTL": "",
                    "memoryKey": "chat_history",
                    "windowSize": ""
                },
                "outputAnchors": [
                    {
                        "id": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
                        "name": "RedisBackedChatMemory",
                        "label": "RedisBackedChatMemory",
                        "description": "Summarizes the conversation and stores the memory in Redis server",
                        "type": "RedisBackedChatMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {}
            },
            "selected": false,
            "positionAbsolute": {
                "x": 75,
                "y": 82
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 529,
            "id": "azureChatOpenAI_LlamaIndex_0",
            "position": {
                "x": 746.5530862509605,
                "y": -54.107978373323306
            },
            "type": "customNode",
            "data": {
                "id": "azureChatOpenAI_LlamaIndex_0",
                "label": "AzureChatOpenAI",
                "version": 2.0,
                "name": "azureChatOpenAI_LlamaIndex",
                "type": "AzureChatOpenAI",
                "baseClasses": ["AzureChatOpenAI", "BaseChatModel_LlamaIndex"],
                "tags": ["LlamaIndex"],
                "category": "Chat Models",
                "description": "Wrapper around Azure OpenAI Chat LLM specific for LlamaIndex",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["azureOpenAIApi"],
                        "id": "azureChatOpenAI_LlamaIndex_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo-16k",
                        "id": "azureChatOpenAI_LlamaIndex_0-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "azureChatOpenAI_LlamaIndex_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "azureChatOpenAI_LlamaIndex_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "azureChatOpenAI_LlamaIndex_0-input-topP-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "azureChatOpenAI_LlamaIndex_0-input-timeout-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "gpt-3.5-turbo-16k",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "timeout": ""
                },
                "outputAnchors": [
                    {
                        "id": "azureChatOpenAI_LlamaIndex_0-output-azureChatOpenAI_LlamaIndex-AzureChatOpenAI|BaseChatModel_LlamaIndex",
                        "name": "azureChatOpenAI_LlamaIndex",
                        "label": "AzureChatOpenAI",
                        "type": "AzureChatOpenAI | BaseChatModel_LlamaIndex"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 746.5530862509605,
                "y": -54.107978373323306
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "RedisBackedChatMemory_0",
            "sourceHandle": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "target": "simpleChatEngine_0",
            "targetHandle": "simpleChatEngine_0-input-memory-BaseChatMemory",
            "type": "buttonedge",
            "id": "RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-simpleChatEngine_0-simpleChatEngine_0-input-memory-BaseChatMemory",
            "data": {
                "label": ""
            }
        },
        {
            "source": "azureChatOpenAI_LlamaIndex_0",
            "sourceHandle": "azureChatOpenAI_LlamaIndex_0-output-azureChatOpenAI_LlamaIndex-AzureChatOpenAI|BaseChatModel_LlamaIndex",
            "target": "simpleChatEngine_0",
            "targetHandle": "simpleChatEngine_0-input-model-BaseChatModel_LlamaIndex",
            "type": "buttonedge",
            "id": "azureChatOpenAI_LlamaIndex_0-azureChatOpenAI_LlamaIndex_0-output-azureChatOpenAI_LlamaIndex-AzureChatOpenAI|BaseChatModel_LlamaIndex-simpleChatEngine_0-simpleChatEngine_0-input-model-BaseChatModel_LlamaIndex",
            "data": {
                "label": ""
            }
        }
    ]
}
