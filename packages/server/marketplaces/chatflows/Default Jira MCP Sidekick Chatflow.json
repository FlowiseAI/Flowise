{
    "name": "Jira Sidekick",
    "description": "The JIRA MCP Sidekick is an AI-powered chatflow designed to integrate seamlessly with your JIRA MCP server. It helps users efficiently perform key JIRA operations‚Äîsuch as searching for issues using JQL, managing epic details, retrieving comprehensive data about specific issues, creating new issues (like bug reports or feature requests), updating existing ones, transitioning issue statuses, and even handling attachments and comments.",
    "framework": ["Answer Agent"],
    "usecases": ["Project Management"],
    "nodes": [
        {
            "id": "aaiToolAgent_0",
            "position": {
                "x": 797.3975527814143,
                "y": 277.3911080764195
            },
            "type": "customNode",
            "data": {
                "id": "aaiToolAgent_0",
                "label": "Tool Agent",
                "version": 2,
                "name": "aaiToolAgent",
                "type": "AgentExecutor",
                "baseClasses": ["AgentExecutor", "BaseChain", "Runnable"],
                "tags": ["AAI"],
                "category": "Agents",
                "description": "Tool Agent ‚Ä¢ Zero configuration required",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessage",
                        "type": "string",
                        "default": "You are a helpful AI assistant.",
                        "description": "If Chat Prompt Template is provided, this will be ignored",
                        "rows": 4,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-systemMessage-string",
                        "display": true
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-maxIterations-number",
                        "display": true
                    },
                    {
                        "label": "Enable Detailed Streaming",
                        "name": "enableDetailedStreaming",
                        "type": "boolean",
                        "default": false,
                        "description": "Stream detailed intermediate steps during agent execution",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiToolAgent_0-input-enableDetailedStreaming-boolean",
                        "display": true
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "id": "aaiToolAgent_0-input-tools-Tool",
                        "display": true
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseChatMemory",
                        "id": "aaiToolAgent_0-input-memory-BaseChatMemory",
                        "display": true
                    },
                    {
                        "label": "Tool Calling Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
                        "id": "aaiToolAgent_0-input-model-BaseChatModel",
                        "display": true
                    },
                    {
                        "label": "Chat Prompt Template",
                        "name": "chatPromptTemplate",
                        "type": "ChatPromptTemplate",
                        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
                        "optional": true,
                        "id": "aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
                        "display": true
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "aaiToolAgent_0-input-inputModeration-Moderation",
                        "display": true
                    }
                ],
                "inputs": {
                    "tools": ["{{currentDateTime_0.data.instance}}", "{{jiraMCP_0.data.instance}}"],
                    "memory": "{{AAIChatMemory_0.data.instance}}",
                    "model": "{{aaiChatOpenAI_0.data.instance}}",
                    "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
                    "systemMessage": "You are a helpful AI assistant.",
                    "inputModeration": "",
                    "maxIterations": "",
                    "enableDetailedStreaming": ""
                },
                "outputAnchors": [
                    {
                        "id": "aaiToolAgent_0-output-aaiToolAgent-AgentExecutor|BaseChain|Runnable",
                        "name": "aaiToolAgent",
                        "label": "AgentExecutor",
                        "description": "Tool Agent ‚Ä¢ Zero configuration required",
                        "type": "AgentExecutor | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 492,
            "positionAbsolute": {
                "x": 797.3975527814143,
                "y": 277.3911080764195
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "aaiChatOpenAI_0",
            "position": {
                "x": 321.48081667566703,
                "y": -247.03465143583247
            },
            "type": "customNode",
            "data": {
                "id": "aaiChatOpenAI_0",
                "label": "Answer ChatOpenAI",
                "version": 1,
                "name": "aaiChatOpenAI",
                "type": "AAIChatOpenAI",
                "baseClasses": ["AAIChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "tags": ["AAI"],
                "category": "Chat Models",
                "description": "OpenAI GPT models ‚Ä¢ Zero configuration required",
                "inputParams": [
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-4o-mini",
                        "id": "aaiChatOpenAI_0-input-modelName-asyncOptions",
                        "display": true
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-temperature-number",
                        "display": true
                    },
                    {
                        "label": "Streaming",
                        "name": "streaming",
                        "type": "boolean",
                        "default": true,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-streaming-boolean",
                        "display": true
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-maxTokens-number",
                        "display": true
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-topP-number",
                        "display": true
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-frequencyPenalty-number",
                        "display": true
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-presencePenalty-number",
                        "display": true
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-timeout-number",
                        "display": true
                    },
                    {
                        "label": "Strict Tool Calling",
                        "name": "strictToolCalling",
                        "type": "boolean",
                        "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-strictToolCalling-boolean",
                        "display": true
                    },
                    {
                        "label": "Stop Sequence",
                        "name": "stopSequence",
                        "type": "string",
                        "rows": 4,
                        "optional": true,
                        "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-stopSequence-string",
                        "display": true
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-basepath-string",
                        "display": true
                    },
                    {
                        "label": "Proxy Url",
                        "name": "proxyUrl",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-proxyUrl-string",
                        "display": true
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-baseOptions-json",
                        "display": true
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
                        "default": false,
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-allowImageUploads-boolean",
                        "display": true
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "show": {
                            "allowImageUploads": true
                        },
                        "id": "aaiChatOpenAI_0-input-imageResolution-options",
                        "display": true
                    },
                    {
                        "label": "Reasoning Effort",
                        "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
                        "name": "reasoningEffort",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "Medium",
                                "name": "medium"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            }
                        ],
                        "default": "medium",
                        "optional": false,
                        "additionalParams": true,
                        "id": "aaiChatOpenAI_0-input-reasoningEffort-options",
                        "display": true
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "aaiChatOpenAI_0-input-cache-BaseCache",
                        "display": true
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-4o-mini",
                    "temperature": 0.9,
                    "streaming": true,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "strictToolCalling": "",
                    "stopSequence": "",
                    "basepath": "",
                    "proxyUrl": "",
                    "baseOptions": "",
                    "allowImageUploads": true,
                    "imageResolution": "low",
                    "reasoningEffort": "medium"
                },
                "outputAnchors": [
                    {
                        "id": "aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "aaiChatOpenAI",
                        "label": "AAIChatOpenAI",
                        "description": "OpenAI GPT models ‚Ä¢ Zero configuration required",
                        "type": "AAIChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 676,
            "selected": false,
            "positionAbsolute": {
                "x": 321.48081667566703,
                "y": -247.03465143583247
            },
            "dragging": false
        },
        {
            "id": "AAIChatMemory_0",
            "position": {
                "x": -7.778718489868993,
                "y": 129.4870179639911
            },
            "type": "customNode",
            "data": {
                "id": "AAIChatMemory_0",
                "label": "Answer Chat Memory",
                "version": 1,
                "name": "AAIChatMemory",
                "type": "AAIChatMemory",
                "baseClasses": ["AAIChatMemory", "BaseChatMemory", "BaseMemory"],
                "tags": ["AAI"],
                "category": "Memory",
                "description": "Summarizes the conversation and stores the memory in Answer Agents servers",
                "inputParams": [
                    {
                        "label": "Session Id",
                        "name": "sessionId",
                        "type": "string",
                        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
                        "default": "",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-sessionId-string",
                        "display": true
                    },
                    {
                        "label": "Session Timeouts",
                        "name": "sessionTTL",
                        "type": "number",
                        "description": "Seconds till a session expires. If not specified, the session will never expire.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-sessionTTL-number",
                        "display": true
                    },
                    {
                        "label": "Memory Key",
                        "name": "memoryKey",
                        "type": "string",
                        "default": "chat_history",
                        "additionalParams": true,
                        "id": "AAIChatMemory_0-input-memoryKey-string",
                        "display": true
                    },
                    {
                        "label": "Window Size",
                        "name": "windowSize",
                        "type": "number",
                        "description": "Window of size k to surface the last k back-and-forth to use as memory.",
                        "additionalParams": true,
                        "optional": true,
                        "id": "AAIChatMemory_0-input-windowSize-number",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "sessionId": "",
                    "sessionTTL": "",
                    "memoryKey": "chat_history",
                    "windowSize": ""
                },
                "outputAnchors": [
                    {
                        "id": "AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory",
                        "name": "AAIChatMemory",
                        "label": "AAIChatMemory",
                        "description": "Summarizes the conversation and stores the memory in Answer Agents servers",
                        "type": "AAIChatMemory | BaseChatMemory | BaseMemory"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 259,
            "selected": false,
            "positionAbsolute": {
                "x": -7.778718489868993,
                "y": 129.4870179639911
            },
            "dragging": false
        },
        {
            "id": "chatPromptTemplate_0",
            "position": {
                "x": 308.95311224250247,
                "y": 664.7281332633123
            },
            "type": "customNode",
            "data": {
                "id": "chatPromptTemplate_0",
                "label": "Chat Prompt Template",
                "version": 2,
                "name": "chatPromptTemplate",
                "type": "ChatPromptTemplate",
                "baseClasses": ["ChatPromptTemplate", "BaseChatPromptTemplate", "BasePromptTemplate", "Runnable"],
                "category": "Prompts",
                "description": "Schema to represent a chat prompt",
                "inputParams": [
                    {
                        "label": "System Message",
                        "name": "systemMessagePrompt",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
                        "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
                        "display": true
                    },
                    {
                        "label": "Human Message",
                        "name": "humanMessagePrompt",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "{text}",
                        "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
                        "display": true
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "chatPromptTemplate_0-input-promptValues-json",
                        "display": true
                    },
                    {
                        "label": "Messages History",
                        "name": "messageHistory",
                        "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
                        "type": "tabs",
                        "tabIdentifier": "selectedMessagesTab",
                        "additionalParams": true,
                        "default": "messageHistoryCode",
                        "tabs": [
                            {
                                "label": "Add Messages (Code)",
                                "name": "messageHistoryCode",
                                "type": "code",
                                "hideCodeExecute": true,
                                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                                "optional": true,
                                "additionalParams": true
                            }
                        ],
                        "id": "chatPromptTemplate_0-input-messageHistory-tabs",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "systemMessagePrompt": "SYSTEM PROMPT ‚Äî ‚ÄúJIRA MCP Answer Agent‚Äù \nIDENTITY & PURPOSE\nYou are the JIRA MCP Answer Agent, an AI assistant specialized in interacting with the JIRA MCP Server. Your mission is to empower users by providing seamless access to JIRA data and functions. You can search for issues using JQL, manage epics, retrieve detailed issue information, create or update issues, handle status transitions, add attachments, and post comments. Your role is critical for automating workflows across development and content management, ensuring tasks are executed accurately and securely.\nAVAILABLE TOOLS\n| Tool Name | When to Use | Invocation Notes | |-------------------|----------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------| | search_issues | When the user requests to find issues (e.g. all open bugs, issues assigned to a user, status queries) | Provide a JSON object with the key \"searchString\" containing the JQL query | | get_epic_children | When the user wants to retrieve all child issues of an epic (e.g. checking progress or reviewing task breakdown) | Provide a JSON object with the key \"epicKey\", for example {\"epicKey\": \"ENG-123\"} | | get_issue | When detailed information about a specific JIRA issue is needed (e.g. issue history, comments, parent/child relationships) | Provide a JSON object with the key \"issueId\", such as {\"issueId\": \"ENG-456\"} | | create_issue | When creating a new JIRA issue from user input (bug reports, feature requests, tasks) | Provide structured details including \"projectKey\", \"issueType\", \"summary\", and optionally \"description\" and additional \"fields\" | | update_issue | When modifying an existing JIRA issue (e.g. setting priority, reassigning tasks, updating custom fields) | Provide a JSON object with \"issueKey\" and a \"fields\" object containing the updates | | get_transitions | When determining available status transitions for a given issue | Provide a JSON object with \"issueKey\", such as {\"issueKey\": \"ENG-101\"} | | transition_issue | When changing the status of an issue after confirming the available transitions (ensuring proper workflow transitions) | Provide a JSON object with \"issueKey\", \"transitionId\", and optionally a \"comment\" | | add_attachment | When attaching files (screenshots, logs, design documents) to an issue | Provide a JSON object with \"issueKey\", \"fileContent\" (base64 encoded), and \"filename\", for example {\"issueKey\": \"ENG-202\", ...} | | add_comment | When inserting comments for updates, discussions, or clarifications on issues | Provide a JSON object with \"issueIdOrKey\" and \"body\", for example {\"issueIdOrKey\": \"ENG-303\", \"body\": \"Your comment here.\"} |\nMODES & BEHAVIOR\n‚Ä¢ Default Mode: Execute user commands by determining which JIRA MCP tool best fits the request.\n‚Ä¢ Workflow Mode: For multi-step processes (e.g., issue triage or sprint management), guide the user step-by-step while chaining tool invocations as needed.\n‚Ä¢ Manual Override Mode: If inputs are ambiguous or missing necessary details, ask for clarification before any action is taken.\nSTYLE & TONE\n‚Ä¢ Maintain a professional, clear, and concise tone.\n‚Ä¢ Use plain language with actionable instructions and brief explanations of technical terms when necessary.\n‚Ä¢ Avoid informal language and emojis.\nCITATIONS & SOURCING\n‚Ä¢ When referencing external documentation (such as Atlassian‚Äôs guides), include inline URLs to official sources where applicable.\n‚Ä¢ Always indicate uncertainty by saying ‚ÄúI‚Äôm not sure‚Äù when you cannot confidently provide an answer.\n‚Ä¢ Do not fabricate information; verify details via the appropriate JIRA MCP tool.\nSAFETY & PERMISSIONS\n‚Ä¢ Never expose or mishandle credentials; API tokens, URLs, and email addresses must be securely stored in environment variables.\n‚Ä¢ Confirm user intent for any irreversible actions (like creating or deleting issues).\n‚Ä¢ Adhere strictly to JIRA‚Äôs privacy and security protocols to protect sensitive data.\nERROR HANDLING\n‚Ä¢ If a tool invocation fails or returns an error, apologize for the inconvenience and ask the user for clarification or corrected input.\n‚Ä¢ Clearly indicate when an input is unclear or missing necessary parameters, and request further details.\n‚Ä¢ If facing rate limiting or API errors, notify the user and suggest waiting or modifying the request.\nEXAMPLES (DO NOT OUTPUT VERBATIM)\n‚Ä¢ Example 1: ‚ÄúShow me all open bugs‚Äù triggers search_issues with an appropriate JQL query.\n‚Ä¢ Example 2: ‚ÄúLog a new bug report‚Äù prompts the create_issue tool with required fields like projectKey, issueType, and summary.\n‚Ä¢ Example 3: ‚ÄúMove ENG-101 to Done‚Äù causes the agent to first call get_transitions to list options, then use transition_issue with the chosen transition ID.\n‚Ä¢ Example 4: ‚ÄúRetrieve all children of epic ENG-123‚Äù leads to a call to get_epic_children, potentially followed by multiple calls to get_issue for further detail.\nNON-NEGOTIABLE RULES\n‚Ä¢ Always invoke the relevant tool(s) based on the user‚Äôs command rather than manually simulating functionality.\n‚Ä¢ Never expose or log sensitive information such as credentials.\n‚Ä¢ Confirm unclear or irreversible requests before proceeding with the action.\n‚Ä¢ Always provide a follow-up or next suggested action in your responses to guide the user through the process.\nSuggestions:\n‚Ä¢ Consider specifying any additional styling requirements for technical responses or for end-user documentation.\n‚Ä¢ You might want to set priorities for each tool to address concurrent requests, especially for workflows involving multiple steps.\n‚Ä¢ Ensure the agent is clear in prompting users for clarification when multiple tools might be applicable.\n\nClarifying Questions:\n\nWould you like to include distinct modes for development versus editorial workflows, or should the agent always handle both in a unified manner?\nShould we add any additional checks (e.g., user confirmation dialogs) for irreversible actions like issue creation or status transitions?\nAre there any additional tools or detailed aspects of the JIRA MCP that you want to emphasize (e.g., handling attachments or specific custom fields)?\nThe final chatflow created using this system prompt enables users to interact with a comprehensive JIRA MCP integration. It automates key tasks like issue search, creation, updates, and workflow transitions, ensuring a secure and efficient process for managing JIRA issues seamlessly.\n\n\n\n\nWould you like to include distinct modes for development versus editorial workflows, or should the agent always handle both in a unified manner? both\nShould we add any additional checks (e.g., user confirmation dialogs) for irreversible actions like issue creation or status transitions? nope\nAre there any additional tools or detailed aspects of the JIRA MCP that you want to emphasize (e.g., handling attachments or specific custom fields)? nope\n\n\nSYSTEM PROMPT ‚Äî ‚ÄúJIRA MCP Answer Agent‚Äù (v1.1 ‚Ä¢ 2023-10-08)\nIDENTITY & PURPOSE\nYou are the JIRA MCP Answer Agent, an AI assistant specialized in interacting with the JIRA MCP Server. Your mission is to empower users by providing seamless access to JIRA data and functions. You can search for issues using JQL, manage epics, retrieve detailed issue information, create or update issues, handle status transitions, add attachments, and post comments. Your role is critical for automating workflows across both development and editorial domains, ensuring tasks are executed accurately and securely.\nAVAILABLE TOOLS\n| Tool Name | When to Use | Invocation Notes | |-------------------|----------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------| | search_issues | When the user requests to find issues (e.g. all open bugs, issues assigned to a user, status queries) | Provide a JSON object with the key \"searchString\" containing the JQL query | | get_epic_children | When the user wants to retrieve all child issues of an epic (e.g. checking progress or reviewing task breakdown) | Provide a JSON object with the key \"epicKey\", for example {\"epicKey\": \"ENG-123\"} | | get_issue | When detailed information about a specific JIRA issue is needed (e.g. issue history, comments, parent/child relationships) | Provide a JSON object with the key \"issueId\", such as {\"issueId\": \"ENG-456\"} | | create_issue | When creating a new JIRA issue from user input (bug reports, feature requests, tasks) | Provide structured details including \"projectKey\", \"issueType\", \"summary\", and optionally \"description\" and additional \"fields\" | | update_issue | When modifying an existing JIRA issue (e.g. setting priority, reassigning tasks, updating custom fields) | Provide a JSON object with \"issueKey\" and a \"fields\" object containing the updates | | get_transitions | When determining available status transitions for a given issue | Provide a JSON object with \"issueKey\", such as {\"issueKey\": \"ENG-101\"} | | transition_issue | When changing the status of an issue after confirming the available transitions (ensuring proper workflow transitions) | Provide a JSON object with \"issueKey\", \"transitionId\", and optionally a \"comment\" | | add_attachment | When attaching files (screenshots, logs, design documents) to an issue | Provide a JSON object with \"issueKey\", \"fileContent\" (base64 encoded), and \"filename\", for example {\"issueKey\": \"ENG-202\", ...} | | add_comment | When inserting comments for updates, discussions, or clarifications on issues | Provide a JSON object with \"issueIdOrKey\" and \"body\", for example {\"issueIdOrKey\": \"ENG-303\", \"body\": \"Your comment here.\"} |\nMODES & BEHAVIOR\n‚Ä¢ Default Mode: Execute user commands by determining which JIRA MCP tool best fits the request.\n‚Ä¢ Development Mode: Tailored for development workflows such as issue triage, sprint management, code review processes, and release management.\n‚Ä¢ Editorial Mode: Focused on content management workflows including content task creation, progress tracking, review cycles, and planning via JIRA issues.\n‚Ä¢ Manual Override Mode: If inputs are ambiguous or missing necessary details, ask for clarification before any action is taken.\nSTYLE & TONE\n‚Ä¢ Maintain a professional, clear, and concise tone.\n‚Ä¢ Use plain language with actionable instructions and brief explanations of technical terms when necessary.\n‚Ä¢ Avoid informal language and emojis.\nCITATIONS & SOURCING\n‚Ä¢ When referencing external documentation (such as Atlassian‚Äôs guides), include inline URLs to official sources where applicable.\n‚Ä¢ Always indicate uncertainty by saying ‚ÄúI‚Äôm not sure‚Äù when you cannot confidently provide an answer.\n‚Ä¢ Do not fabricate information; verify details via the appropriate JIRA MCP tool.\nSAFETY & PERMISSIONS\n‚Ä¢ Never expose or mishandle credentials; API tokens, URLs, and email addresses must be securely stored in environment variables.\n‚Ä¢ Proceed with irreversible actions like issue creation or status transitions based solely on clear user commands without additional confirmation dialogs.\n‚Ä¢ Adhere strictly to JIRA‚Äôs privacy and security protocols to protect sensitive data.\nERROR HANDLING\n‚Ä¢ If a tool invocation fails or returns an error, apologize for the inconvenience and ask the user for clarification or corrected input.\n‚Ä¢ Clearly indicate when an input is unclear or missing necessary parameters, and request further details.\n‚Ä¢ If facing rate limiting or API errors, notify the user and suggest waiting or modifying the request.\nEXAMPLES (DO NOT OUTPUT VERBATIM)\n‚Ä¢ Example 1: ‚ÄúShow me all open bugs‚Äù triggers search_issues with an appropriate JQL query.\n‚Ä¢ Example 2: ‚ÄúLog a new bug report‚Äù prompts the create_issue tool with required fields like projectKey, issueType, and summary.\n‚Ä¢ Example 3: ‚ÄúMove ENG-101 to Done‚Äù causes the agent to first call get_transitions to list options, then use transition_issue with the chosen transition ID.\n‚Ä¢ Example 4: ‚ÄúRetrieve all children of epic ENG-123‚Äù leads to a call to get_epic_children, potentially followed by multiple calls to get_issue for further detail.\nNON-NEGOTIABLE RULES\n‚Ä¢ Always invoke the relevant tool(s) based on the user‚Äôs command rather than manually simulating functionality.\n‚Ä¢ Never expose or log sensitive information such as credentials.\n‚Ä¢ Confirm unclear requests before proceeding, but do not interject extra confirmation dialogs for irreversible actions if user input is clear.\n‚Ä¢ Always provide a follow-up instruction or next suggested action in your responses to guide the user through the process.",
                    "humanMessagePrompt": "The current URL is: {url}\nWeb Context (if any):\n{webContentText}\nOnly use the content or the URL if they are provided. otherwise ignore this section and only use the user input.\n\n###\nFile Uploaded (if any)\n{fileUpload}\nOnly use the content of the file if it is provided. otherwise ignore this section and follow the user input.\n\n###\n\nUser Input:\n{input}\n",
                    "promptValues": "{\"url\":\"No URL provided by the user\",\"webContentText\":\"{{file_attachment}}\",\"fileUpload\":\"No Web Content was provided by the user\",\"input\":\"{{question}}\"}",
                    "messageHistory": "messageHistoryCode"
                },
                "outputAnchors": [
                    {
                        "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
                        "name": "chatPromptTemplate",
                        "label": "ChatPromptTemplate",
                        "description": "Schema to represent a chat prompt",
                        "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 748,
            "selected": false,
            "positionAbsolute": {
                "x": 308.95311224250247,
                "y": 664.7281332633123
            },
            "dragging": false
        },
        {
            "id": "currentDateTime_0",
            "position": {
                "x": 786.6589970817336,
                "y": -7.1927104677048135
            },
            "type": "customNode",
            "data": {
                "id": "currentDateTime_0",
                "label": "CurrentDateTime",
                "version": 1,
                "name": "currentDateTime",
                "type": "CurrentDateTime",
                "baseClasses": ["CurrentDateTime", "Tool"],
                "tags": ["AAI"],
                "category": "Tools",
                "description": "Get todays day, date and time.",
                "inputParams": [],
                "inputAnchors": [],
                "inputs": {},
                "outputAnchors": [
                    {
                        "id": "currentDateTime_0-output-currentDateTime-CurrentDateTime|Tool",
                        "name": "currentDateTime",
                        "label": "CurrentDateTime",
                        "description": "Get todays day, date and time.",
                        "type": "CurrentDateTime | Tool"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 149,
            "selected": false,
            "positionAbsolute": {
                "x": 786.6589970817336,
                "y": -7.1927104677048135
            },
            "dragging": false
        },
        {
            "id": "jiraMCP_0",
            "position": {
                "x": -213.75093496567717,
                "y": 606.6247694827592
            },
            "type": "customNode",
            "data": {
                "id": "jiraMCP_0",
                "label": "Jira MCP",
                "version": 1,
                "name": "jiraMCP",
                "type": "Jira MCP Tool",
                "baseClasses": ["Tool"],
                "tags": ["AAI"],
                "category": "MCP Servers",
                "description": "MCP server that integrates the Jira API",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["JiraApi"],
                        "id": "jiraMCP_0-input-credential-credential",
                        "display": true
                    },
                    {
                        "label": "Available Actions",
                        "name": "mcpActions",
                        "type": "asyncMultiOptions",
                        "loadMethod": "listActions",
                        "refresh": true,
                        "id": "jiraMCP_0-input-mcpActions-asyncMultiOptions",
                        "display": true
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "mcpActions": ""
                },
                "outputAnchors": [
                    {
                        "id": "jiraMCP_0-output-jiraMCP-Tool",
                        "name": "jiraMCP",
                        "label": "Jira MCP Tool",
                        "description": "MCP server that integrates the Jira API",
                        "type": "Tool"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 378,
            "selected": false,
            "positionAbsolute": {
                "x": -213.75093496567717,
                "y": 606.6247694827592
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "AAIChatMemory_0",
            "sourceHandle": "AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-memory-BaseChatMemory",
            "type": "buttonedge",
            "id": "AAIChatMemory_0-AAIChatMemory_0-output-AAIChatMemory-AAIChatMemory|BaseChatMemory|BaseMemory-aaiToolAgent_0-aaiToolAgent_0-input-memory-BaseChatMemory"
        },
        {
            "source": "aaiChatOpenAI_0",
            "sourceHandle": "aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "aaiChatOpenAI_0-aaiChatOpenAI_0-output-aaiChatOpenAI-AAIChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-aaiToolAgent_0-aaiToolAgent_0-input-model-BaseChatModel"
        },
        {
            "source": "chatPromptTemplate_0",
            "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
            "type": "buttonedge",
            "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-aaiToolAgent_0-aaiToolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
        },
        {
            "source": "currentDateTime_0",
            "sourceHandle": "currentDateTime_0-output-currentDateTime-CurrentDateTime|Tool",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "currentDateTime_0-currentDateTime_0-output-currentDateTime-CurrentDateTime|Tool-aaiToolAgent_0-aaiToolAgent_0-input-tools-Tool"
        },
        {
            "source": "jiraMCP_0",
            "sourceHandle": "jiraMCP_0-output-jiraMCP-Tool",
            "target": "aaiToolAgent_0",
            "targetHandle": "aaiToolAgent_0-input-tools-Tool",
            "type": "buttonedge",
            "id": "jiraMCP_0-jiraMCP_0-output-jiraMCP-Tool-aaiToolAgent_0-aaiToolAgent_0-input-tools-Tool"
        }
    ]
}
