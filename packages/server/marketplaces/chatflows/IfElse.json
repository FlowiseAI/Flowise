{
    "description": "Split flows based on if else condition",
    "badge": "new",
    "nodes": [
        {
            "width": 300,
            "height": 511,
            "id": "promptTemplate_0",
            "position": {
                "x": 792.9464838535649,
                "y": 527.1718536712464
            },
            "type": "customNode",
            "data": {
                "id": "promptTemplate_0",
                "label": "Prompt Template",
                "version": 1,
                "name": "promptTemplate",
                "type": "PromptTemplate",
                "baseClasses": ["PromptTemplate", "BaseStringPromptTemplate", "BasePromptTemplate"],
                "category": "Prompts",
                "description": "Schema to represent a basic prompt for an LLM",
                "inputParams": [
                    {
                        "label": "Template",
                        "name": "template",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "What is a good name for a company that makes {product}?",
                        "id": "promptTemplate_0-input-template-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "promptTemplate_0-input-promptValues-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "template": "You are an AI who performs one task based on the following objective: {objective}.\nRespond with how you would complete this task:",
                    "promptValues": "{\"objective\":\"{{question}}\"}"
                },
                "outputAnchors": [
                    {
                        "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate",
                        "name": "promptTemplate",
                        "label": "PromptTemplate",
                        "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 792.9464838535649,
                "y": 527.1718536712464
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 511,
            "id": "promptTemplate_1",
            "position": {
                "x": 1995.1328578238122,
                "y": -14.648035759690174
            },
            "type": "customNode",
            "data": {
                "id": "promptTemplate_1",
                "label": "Prompt Template",
                "version": 1,
                "name": "promptTemplate",
                "type": "PromptTemplate",
                "baseClasses": ["PromptTemplate", "BaseStringPromptTemplate", "BasePromptTemplate"],
                "category": "Prompts",
                "description": "Schema to represent a basic prompt for an LLM",
                "inputParams": [
                    {
                        "label": "Template",
                        "name": "template",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "What is a good name for a company that makes {product}?",
                        "id": "promptTemplate_1-input-template-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "promptTemplate_1-input-promptValues-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "template": "You are a task creation AI that uses the result of an execution agent to create new tasks with the following objective: {objective}.\nThe last completed task has the result: {result}.\nBased on the result, create new tasks to be completed by the AI system that do not overlap with result.\nReturn the tasks as an array.",
                    "promptValues": "{\"objective\":\"{{question}}\",\"result\":\"{{ifElseFunction_0.data.instance}}\"}"
                },
                "outputAnchors": [
                    {
                        "id": "promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate",
                        "name": "promptTemplate",
                        "label": "PromptTemplate",
                        "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "positionAbsolute": {
                "x": 1995.1328578238122,
                "y": -14.648035759690174
            },
            "selected": false,
            "dragging": false
        },
        {
            "width": 300,
            "height": 574,
            "id": "openAI_1",
            "position": {
                "x": 791.6102007244282,
                "y": -83.71386876566092
            },
            "type": "customNode",
            "data": {
                "id": "openAI_1",
                "label": "OpenAI",
                "version": 3,
                "name": "openAI",
                "type": "OpenAI",
                "baseClasses": ["OpenAI", "BaseLLM", "BaseLanguageModel"],
                "category": "LLMs",
                "description": "Wrapper around OpenAI large language models",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAI_1-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "options",
                        "options": [
                            {
                                "label": "gpt-3.5-turbo-instruct",
                                "name": "gpt-3.5-turbo-instruct"
                            },
                            {
                                "label": "babbage-002",
                                "name": "babbage-002"
                            },
                            {
                                "label": "davinci-002",
                                "name": "davinci-002"
                            }
                        ],
                        "default": "gpt-3.5-turbo-instruct",
                        "optional": true,
                        "id": "openAI_1-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "default": 0.7,
                        "optional": true,
                        "id": "openAI_1-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-topP-number"
                    },
                    {
                        "label": "Best Of",
                        "name": "bestOf",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-bestOf-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-presencePenalty-number"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_1-input-basepath-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "openAI_1-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "modelName": "gpt-3.5-turbo-instruct",
                    "temperature": 0.7,
                    "maxTokens": "",
                    "topP": "",
                    "bestOf": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAI_1-output-openAI-OpenAI|BaseLLM|BaseLanguageModel",
                        "name": "openAI",
                        "label": "OpenAI",
                        "type": "OpenAI | BaseLLM | BaseLanguageModel"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 791.6102007244282,
                "y": -83.71386876566092
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 574,
            "id": "openAI_2",
            "position": {
                "x": 2340.5995455075863,
                "y": -310.7609446553905
            },
            "type": "customNode",
            "data": {
                "id": "openAI_2",
                "label": "OpenAI",
                "version": 3,
                "name": "openAI",
                "type": "OpenAI",
                "baseClasses": ["OpenAI", "BaseLLM", "BaseLanguageModel"],
                "category": "LLMs",
                "description": "Wrapper around OpenAI large language models",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAI_2-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "options",
                        "options": [
                            {
                                "label": "gpt-3.5-turbo-instruct",
                                "name": "gpt-3.5-turbo-instruct"
                            },
                            {
                                "label": "babbage-002",
                                "name": "babbage-002"
                            },
                            {
                                "label": "davinci-002",
                                "name": "davinci-002"
                            }
                        ],
                        "default": "gpt-3.5-turbo-instruct",
                        "optional": true,
                        "id": "openAI_2-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "default": 0.7,
                        "optional": true,
                        "id": "openAI_2-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-topP-number"
                    },
                    {
                        "label": "Best Of",
                        "name": "bestOf",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-bestOf-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-presencePenalty-number"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAI_2-input-basepath-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "openAI_2-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "modelName": "gpt-3.5-turbo-instruct",
                    "temperature": 0.7,
                    "maxTokens": "",
                    "topP": "",
                    "bestOf": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAI_2-output-openAI-OpenAI|BaseLLM|BaseLanguageModel",
                        "name": "openAI",
                        "label": "OpenAI",
                        "type": "OpenAI | BaseLLM | BaseLanguageModel"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 2340.5995455075863,
                "y": -310.7609446553905
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 456,
            "id": "llmChain_0",
            "position": {
                "x": 1183.0899727188096,
                "y": 385.0159960992951
            },
            "type": "customNode",
            "data": {
                "id": "llmChain_0",
                "label": "LLM Chain",
                "version": 3,
                "name": "llmChain",
                "type": "LLMChain",
                "baseClasses": ["LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chain to run queries against LLMs",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "chainName",
                        "type": "string",
                        "placeholder": "Name Your Chain",
                        "optional": true,
                        "id": "llmChain_0-input-chainName-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "llmChain_0-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Prompt",
                        "name": "prompt",
                        "type": "BasePromptTemplate",
                        "id": "llmChain_0-input-prompt-BasePromptTemplate"
                    },
                    {
                        "label": "Output Parser",
                        "name": "outputParser",
                        "type": "BaseLLMOutputParser",
                        "optional": true,
                        "id": "llmChain_0-input-outputParser-BaseLLMOutputParser"
                    }
                ],
                "inputs": {
                    "model": "{{openAI_1.data.instance}}",
                    "prompt": "{{promptTemplate_0.data.instance}}",
                    "outputParser": "",
                    "chainName": "FirstChain"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                                "name": "llmChain",
                                "label": "LLM Chain",
                                "type": "LLMChain | BaseChain | Runnable"
                            },
                            {
                                "id": "llmChain_0-output-outputPrediction-string|json",
                                "name": "outputPrediction",
                                "label": "Output Prediction",
                                "type": "string | json"
                            }
                        ],
                        "default": "llmChain"
                    }
                ],
                "outputs": {
                    "output": "outputPrediction"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 1183.0899727188096,
                "y": 385.0159960992951
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 456,
            "id": "llmChain_1",
            "position": {
                "x": 2773.675809586143,
                "y": 114.39482869328754
            },
            "type": "customNode",
            "data": {
                "id": "llmChain_1",
                "label": "LLM Chain",
                "version": 3,
                "name": "llmChain",
                "type": "LLMChain",
                "baseClasses": ["LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chain to run queries against LLMs",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "chainName",
                        "type": "string",
                        "placeholder": "Name Your Chain",
                        "optional": true,
                        "id": "llmChain_1-input-chainName-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "llmChain_1-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Prompt",
                        "name": "prompt",
                        "type": "BasePromptTemplate",
                        "id": "llmChain_1-input-prompt-BasePromptTemplate"
                    },
                    {
                        "label": "Output Parser",
                        "name": "outputParser",
                        "type": "BaseLLMOutputParser",
                        "optional": true,
                        "id": "llmChain_1-input-outputParser-BaseLLMOutputParser"
                    }
                ],
                "inputs": {
                    "model": "{{openAI_2.data.instance}}",
                    "prompt": "{{promptTemplate_1.data.instance}}",
                    "outputParser": "",
                    "chainName": "LastChain"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable",
                                "name": "llmChain",
                                "label": "LLM Chain",
                                "type": "LLMChain | BaseChain | Runnable"
                            },
                            {
                                "id": "llmChain_1-output-outputPrediction-string|json",
                                "name": "outputPrediction",
                                "label": "Output Prediction",
                                "type": "string | json"
                            }
                        ],
                        "default": "llmChain"
                    }
                ],
                "outputs": {
                    "output": "llmChain"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 2773.675809586143,
                "y": 114.39482869328754
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 511,
            "id": "promptTemplate_2",
            "position": {
                "x": 1992.5456174373144,
                "y": 675.5277193898106
            },
            "type": "customNode",
            "data": {
                "id": "promptTemplate_2",
                "label": "Prompt Template",
                "version": 1,
                "name": "promptTemplate",
                "type": "PromptTemplate",
                "baseClasses": ["PromptTemplate", "BaseStringPromptTemplate", "BasePromptTemplate"],
                "category": "Prompts",
                "description": "Schema to represent a basic prompt for an LLM",
                "inputParams": [
                    {
                        "label": "Template",
                        "name": "template",
                        "type": "string",
                        "rows": 4,
                        "placeholder": "What is a good name for a company that makes {product}?",
                        "id": "promptTemplate_2-input-template-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "promptTemplate_2-input-promptValues-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "template": "Politely say \"I'm not able to answer the query\"",
                    "promptValues": "{\"objective\":\"{{question}}\",\"result\":\"\"}"
                },
                "outputAnchors": [
                    {
                        "id": "promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate",
                        "name": "promptTemplate",
                        "label": "PromptTemplate",
                        "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "positionAbsolute": {
                "x": 1992.5456174373144,
                "y": 675.5277193898106
            },
            "selected": false,
            "dragging": false
        },
        {
            "width": 300,
            "height": 507,
            "id": "llmChain_2",
            "position": {
                "x": 2830.477603228176,
                "y": 907.9116984679802
            },
            "type": "customNode",
            "data": {
                "id": "llmChain_2",
                "label": "LLM Chain",
                "version": 3,
                "name": "llmChain",
                "type": "LLMChain",
                "baseClasses": ["LLMChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Chain to run queries against LLMs",
                "inputParams": [
                    {
                        "label": "Chain Name",
                        "name": "chainName",
                        "type": "string",
                        "placeholder": "Name Your Chain",
                        "optional": true,
                        "id": "llmChain_2-input-chainName-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Language Model",
                        "name": "model",
                        "type": "BaseLanguageModel",
                        "id": "llmChain_2-input-model-BaseLanguageModel"
                    },
                    {
                        "label": "Prompt",
                        "name": "prompt",
                        "type": "BasePromptTemplate",
                        "id": "llmChain_2-input-prompt-BasePromptTemplate"
                    },
                    {
                        "label": "Output Parser",
                        "name": "outputParser",
                        "type": "BaseLLMOutputParser",
                        "optional": true,
                        "id": "llmChain_2-input-outputParser-BaseLLMOutputParser"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "llmChain_2-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "prompt": "{{promptTemplate_2.data.instance}}",
                    "outputParser": "",
                    "inputModeration": "",
                    "chainName": "FallbackChain"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "llmChain_2-output-llmChain-LLMChain|BaseChain|Runnable",
                                "name": "llmChain",
                                "label": "LLM Chain",
                                "type": "LLMChain | BaseChain | Runnable"
                            },
                            {
                                "id": "llmChain_2-output-outputPrediction-string|json",
                                "name": "outputPrediction",
                                "label": "Output Prediction",
                                "type": "string | json"
                            }
                        ],
                        "default": "llmChain"
                    }
                ],
                "outputs": {
                    "output": "llmChain"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 2830.477603228176,
                "y": 907.9116984679802
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 755,
            "id": "ifElseFunction_0",
            "position": {
                "x": 1590.6560099561739,
                "y": 265.36655719326177
            },
            "type": "customNode",
            "data": {
                "id": "ifElseFunction_0",
                "label": "IfElse Function",
                "version": 1,
                "name": "ifElseFunction",
                "type": "IfElseFunction",
                "baseClasses": ["IfElseFunction", "Utilities"],
                "category": "Utilities",
                "description": "Split flows based on If Else javascript functions",
                "inputParams": [
                    {
                        "label": "Input Variables",
                        "name": "functionInputVariables",
                        "description": "Input variables can be used in the function with prefix $. For example: $var",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "ifElseFunction_0-input-functionInputVariables-json"
                    },
                    {
                        "label": "IfElse Name",
                        "name": "functionName",
                        "type": "string",
                        "optional": true,
                        "placeholder": "If Condition Match",
                        "id": "ifElseFunction_0-input-functionName-string"
                    },
                    {
                        "label": "If Function",
                        "name": "ifFunction",
                        "description": "Function must return a value",
                        "type": "code",
                        "rows": 2,
                        "default": "if (\"hello\" == \"hello\") {\n    return true;\n}",
                        "id": "ifElseFunction_0-input-ifFunction-code"
                    },
                    {
                        "label": "Else Function",
                        "name": "elseFunction",
                        "description": "Function must return a value",
                        "type": "code",
                        "rows": 2,
                        "default": "return false;",
                        "id": "ifElseFunction_0-input-elseFunction-code"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "functionInputVariables": "{\"task\":\"{{llmChain_0.data.instance}}\"}",
                    "functionName": "If Condition Match",
                    "ifFunction": "if (\"hello\" == \"21\") {\n    return $task;\n}",
                    "elseFunction": "return false;"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "ifElseFunction_0-output-returnTrue-string|number|boolean|json|array",
                                "name": "returnTrue",
                                "label": "True",
                                "type": "string | number | boolean | json | array"
                            },
                            {
                                "id": "ifElseFunction_0-output-returnFalse-string|number|boolean|json|array",
                                "name": "returnFalse",
                                "label": "False",
                                "type": "string | number | boolean | json | array"
                            }
                        ],
                        "default": "returnTrue"
                    }
                ],
                "outputs": {
                    "output": "returnTrue"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 1590.6560099561739,
                "y": 265.36655719326177
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 574,
            "id": "chatOpenAI_0",
            "position": {
                "x": 2373.5711587130127,
                "y": 487.8533802540226
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 2,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "options",
                        "options": [
                            {
                                "label": "gpt-4",
                                "name": "gpt-4"
                            },
                            {
                                "label": "gpt-4-1106-preview",
                                "name": "gpt-4-1106-preview"
                            },
                            {
                                "label": "gpt-4-vision-preview",
                                "name": "gpt-4-vision-preview"
                            },
                            {
                                "label": "gpt-4-0613",
                                "name": "gpt-4-0613"
                            },
                            {
                                "label": "gpt-4-32k",
                                "name": "gpt-4-32k"
                            },
                            {
                                "label": "gpt-4-32k-0613",
                                "name": "gpt-4-32k-0613"
                            },
                            {
                                "label": "gpt-3.5-turbo",
                                "name": "gpt-3.5-turbo"
                            },
                            {
                                "label": "gpt-3.5-turbo-1106",
                                "name": "gpt-3.5-turbo-1106"
                            },
                            {
                                "label": "gpt-3.5-turbo-0613",
                                "name": "gpt-3.5-turbo-0613"
                            },
                            {
                                "label": "gpt-3.5-turbo-16k",
                                "name": "gpt-3.5-turbo-16k"
                            },
                            {
                                "label": "gpt-3.5-turbo-16k-0613",
                                "name": "gpt-3.5-turbo-16k-0613"
                            }
                        ],
                        "default": "gpt-3.5-turbo",
                        "optional": true,
                        "id": "chatOpenAI_0-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-3.5-turbo",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": ""
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 2373.5711587130127,
                "y": 487.8533802540226
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "openAI_1",
            "sourceHandle": "openAI_1-output-openAI-OpenAI|BaseLLM|BaseLanguageModel",
            "target": "llmChain_0",
            "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "openAI_1-openAI_1-output-openAI-OpenAI|BaseLLM|BaseLanguageModel-llmChain_0-llmChain_0-input-model-BaseLanguageModel",
            "data": {
                "label": ""
            }
        },
        {
            "source": "promptTemplate_0",
            "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate",
            "target": "llmChain_0",
            "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
            "type": "buttonedge",
            "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate",
            "data": {
                "label": ""
            }
        },
        {
            "source": "promptTemplate_1",
            "sourceHandle": "promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate",
            "target": "llmChain_1",
            "targetHandle": "llmChain_1-input-prompt-BasePromptTemplate",
            "type": "buttonedge",
            "id": "promptTemplate_1-promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate-llmChain_1-llmChain_1-input-prompt-BasePromptTemplate",
            "data": {
                "label": ""
            }
        },
        {
            "source": "openAI_2",
            "sourceHandle": "openAI_2-output-openAI-OpenAI|BaseLLM|BaseLanguageModel",
            "target": "llmChain_1",
            "targetHandle": "llmChain_1-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "openAI_2-openAI_2-output-openAI-OpenAI|BaseLLM|BaseLanguageModel-llmChain_1-llmChain_1-input-model-BaseLanguageModel",
            "data": {
                "label": ""
            }
        },
        {
            "source": "promptTemplate_2",
            "sourceHandle": "promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate",
            "target": "llmChain_2",
            "targetHandle": "llmChain_2-input-prompt-BasePromptTemplate",
            "type": "buttonedge",
            "id": "promptTemplate_2-promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate-llmChain_2-llmChain_2-input-prompt-BasePromptTemplate"
        },
        {
            "source": "llmChain_0",
            "sourceHandle": "llmChain_0-output-outputPrediction-string|json",
            "target": "ifElseFunction_0",
            "targetHandle": "ifElseFunction_0-input-functionInputVariables-json",
            "type": "buttonedge",
            "id": "llmChain_0-llmChain_0-output-outputPrediction-string|json-ifElseFunction_0-ifElseFunction_0-input-functionInputVariables-json"
        },
        {
            "source": "ifElseFunction_0",
            "sourceHandle": "ifElseFunction_0-output-returnFalse-string|number|boolean|json|array",
            "target": "promptTemplate_2",
            "targetHandle": "promptTemplate_2-input-promptValues-json",
            "type": "buttonedge",
            "id": "ifElseFunction_0-ifElseFunction_0-output-returnFalse-string|number|boolean|json|array-promptTemplate_2-promptTemplate_2-input-promptValues-json"
        },
        {
            "source": "ifElseFunction_0",
            "sourceHandle": "ifElseFunction_0-output-returnTrue-string|number|boolean|json|array",
            "target": "promptTemplate_1",
            "targetHandle": "promptTemplate_1-input-promptValues-json",
            "type": "buttonedge",
            "id": "ifElseFunction_0-ifElseFunction_0-output-returnTrue-string|number|boolean|json|array-promptTemplate_1-promptTemplate_1-input-promptValues-json"
        },
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "llmChain_2",
            "targetHandle": "llmChain_2-input-model-BaseLanguageModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_2-llmChain_2-input-model-BaseLanguageModel"
        }
    ]
}
